{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff272a65",
   "metadata": {},
   "source": [
    "# Trinity Admission Data Preparation <br>\n",
    "\n",
    "\n",
    "The goal of this data preparation project is to ready the data for constructing a classification model to determine whether an accepted applicant will decide to attend the University, based on information collected regarding the University’s recently accepted applicants, ranging in entry term from Fall 2017, Fall 2018, Fall 2019, Fall 2020, and Fall 2021.  Your final data set should be ready for modeling. \n",
    "\n",
    "This script demonstrates how to clean some typical variables for the test dataset and the cleaning requiremens for all variables. \n",
    "\n",
    "The test dataset is a subset of the original dataset, which is used to test the model to understand the relationships between variables. Then the tested model will predict the target variable using predictors in the test dataset.\n",
    "\n",
    "You need to handle all the columns/variables that are not processed in this scirpt following the intrsuctions in the comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "931dad90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>train-test</th>\n",
       "      <th>Entry Term (Application)</th>\n",
       "      <th>Admit Type</th>\n",
       "      <th>Permanent Postal</th>\n",
       "      <th>Permanent Country</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Race</th>\n",
       "      <th>Religion</th>\n",
       "      <th>...</th>\n",
       "      <th>SAT Concordance Score (of SAT R)</th>\n",
       "      <th>ACT Concordance Score (of SAT R)</th>\n",
       "      <th>ACT Concordance Score (of SAT)</th>\n",
       "      <th>Test Optional</th>\n",
       "      <th>SAT I Critical Reading</th>\n",
       "      <th>SAT I Math</th>\n",
       "      <th>SAT I Writing</th>\n",
       "      <th>SAT R Evidence-Based Reading and Writing Section</th>\n",
       "      <th>SAT R Math Section</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Fall 2017</td>\n",
       "      <td>FY</td>\n",
       "      <td>87507-7944</td>\n",
       "      <td>United States</td>\n",
       "      <td>F</td>\n",
       "      <td>Non Hispanic/Latino</td>\n",
       "      <td>White</td>\n",
       "      <td>Roman Catholic</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID train-test Entry Term (Application) Admit Type Permanent Postal  \\\n",
       "0   1      train                Fall 2017         FY       87507-7944   \n",
       "\n",
       "  Permanent Country Sex            Ethnicity   Race        Religion  ...  \\\n",
       "0     United States   F  Non Hispanic/Latino  White  Roman Catholic  ...   \n",
       "\n",
       "  SAT Concordance Score (of SAT R) ACT Concordance Score (of SAT R)  \\\n",
       "0                              NaN                              NaN   \n",
       "\n",
       "  ACT Concordance Score (of SAT) Test Optional SAT I Critical Reading  \\\n",
       "0                            NaN           NaN                    NaN   \n",
       "\n",
       "  SAT I Math SAT I Writing SAT R Evidence-Based Reading and Writing Section  \\\n",
       "0        NaN           NaN                                              NaN   \n",
       "\n",
       "  SAT R Math Section Decision  \n",
       "0                NaN        1  \n",
       "\n",
       "[1 rows x 69 columns]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Read in TU.csv\n",
    "\n",
    "TU = pd.read_csv(\"TU.csv\")\n",
    "# pd.set_option('display.max_columns', None)\n",
    "TU.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "b691ef96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'train-test', 'Entry Term (Application)', 'Admit Type',\n",
       "       'Permanent Postal', 'Permanent Country', 'Sex', 'Ethnicity', 'Race',\n",
       "       'Religion', 'First_Source Origin First Source Date', 'Inquiry Date',\n",
       "       'Submitted', 'Application Source', 'Decision Plan',\n",
       "       'Staff Assigned Name', 'Legacy', 'Athlete', 'Sport 1 Sport',\n",
       "       'Sport 1 Rating', 'Sport 2 Sport', 'Sport 2 Rating', 'Sport 3 Sport',\n",
       "       'Sport 3 Rating', 'Academic Interest 1', 'Academic Interest 2',\n",
       "       'First_Source Origin First Source Summary', 'Total Event Participation',\n",
       "       'Count of Campus Visits', 'School #1 Organization Category',\n",
       "       'School 1 Code', 'School 1 Class Rank (Numeric)',\n",
       "       'School 1 Class Size (Numeric)', 'School 1 GPA', 'School 1 GPA Scale',\n",
       "       'School 1 GPA Recalculated', 'School 2 Class Rank (Numeric)',\n",
       "       'School 2 Class Size (Numeric)', 'School 2 GPA', 'School 2 GPA Scale',\n",
       "       'School 2 GPA Recalculated', 'School 3 Class Rank (Numeric)',\n",
       "       'School 3 Class Size (Numeric)', 'School 3 GPA', 'School 3 GPA Scale',\n",
       "       'School 3 GPA Recalculated', 'ACT Composite', 'ACT English',\n",
       "       'ACT Reading', 'ACT Math', 'ACT Science Reasoning', 'ACT Writing',\n",
       "       'SAT I CR + M',\n",
       "       'SAT R Evidence-Based Reading and Writing Section + Math Section',\n",
       "       'Permanent Geomarket', 'Citizenship Status', 'Academic Index',\n",
       "       'Intend to Apply for Financial Aid?', 'Merit Award',\n",
       "       'SAT Concordance Score (of SAT R)', 'ACT Concordance Score (of SAT R)',\n",
       "       'ACT Concordance Score (of SAT)', 'Test Optional',\n",
       "       'SAT I Critical Reading', 'SAT I Math', 'SAT I Writing',\n",
       "       'SAT R Evidence-Based Reading and Writing Section',\n",
       "       'SAT R Math Section', 'Decision'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all columns in one output\n",
    "TU.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "81c801ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataframe into training and test datasets\n",
    "# In this course, you will only work on the variables in the training set\n",
    "# You will need to clean the test set following the methods used in this script, when you work on modeling in later chapter.\n",
    "\n",
    "TUtrain=TU[TU['train-test']=='train']\n",
    "TUtest=TU[TU['train-test']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "65d33ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column1 - ID\n",
    "\n",
    "#Check NAs\n",
    "TUtest['ID'].isna().sum()\n",
    "#No NA,so no cleaning is required. But ID will be removed in the modeling stage. Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "a3777510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Fall 2019', 'Fall 2020', 'Fall 2021', 'Fall 2017', 'Fall 2018'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column2 - Entry Term Application\n",
    "\n",
    "#Check NAs\n",
    "print(TUtest['Entry Term (Application)'].isna().sum())\n",
    "#No NA.\n",
    "TUtest['Entry Term (Application)'].unique()\n",
    "#No irregular categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "02d9e5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['FY']\n"
     ]
    }
   ],
   "source": [
    "#Column 3 - Admit Type\n",
    "\n",
    "#Check NAs\n",
    "print(TUtest['Admit Type'].isna().sum())\n",
    "#No NA.\n",
    "print(TUtest['Admit Type'].unique())\n",
    "#No irregular categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "60363d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000    FY\n",
      "10001    FY\n",
      "10002    FY\n",
      "10003    FY\n",
      "10004    FY\n",
      "         ..\n",
      "15138    FY\n",
      "15139    FY\n",
      "15140    FY\n",
      "15141    FY\n",
      "15142    FY\n",
      "Name: Admit Type, Length: 5143, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'train-test', 'Entry Term (Application)', 'Permanent Postal',\n",
       "       'Permanent Country', 'Sex', 'Ethnicity', 'Race', 'Religion',\n",
       "       'First_Source Origin First Source Date', 'Inquiry Date', 'Submitted',\n",
       "       'Application Source', 'Decision Plan', 'Staff Assigned Name', 'Legacy',\n",
       "       'Athlete', 'Sport 1 Sport', 'Sport 1 Rating', 'Sport 2 Sport',\n",
       "       'Sport 2 Rating', 'Sport 3 Sport', 'Sport 3 Rating',\n",
       "       'Academic Interest 1', 'Academic Interest 2',\n",
       "       'First_Source Origin First Source Summary', 'Total Event Participation',\n",
       "       'Count of Campus Visits', 'School #1 Organization Category',\n",
       "       'School 1 Code', 'School 1 Class Rank (Numeric)',\n",
       "       'School 1 Class Size (Numeric)', 'School 1 GPA', 'School 1 GPA Scale',\n",
       "       'School 1 GPA Recalculated', 'School 2 Class Rank (Numeric)',\n",
       "       'School 2 Class Size (Numeric)', 'School 2 GPA', 'School 2 GPA Scale',\n",
       "       'School 2 GPA Recalculated', 'School 3 Class Rank (Numeric)',\n",
       "       'School 3 Class Size (Numeric)', 'School 3 GPA', 'School 3 GPA Scale',\n",
       "       'School 3 GPA Recalculated', 'ACT Composite', 'ACT English',\n",
       "       'ACT Reading', 'ACT Math', 'ACT Science Reasoning', 'ACT Writing',\n",
       "       'SAT I CR + M',\n",
       "       'SAT R Evidence-Based Reading and Writing Section + Math Section',\n",
       "       'Permanent Geomarket', 'Citizenship Status', 'Academic Index',\n",
       "       'Intend to Apply for Financial Aid?', 'Merit Award',\n",
       "       'SAT Concordance Score (of SAT R)', 'ACT Concordance Score (of SAT R)',\n",
       "       'ACT Concordance Score (of SAT)', 'Test Optional',\n",
       "       'SAT I Critical Reading', 'SAT I Math', 'SAT I Writing',\n",
       "       'SAT R Evidence-Based Reading and Writing Section',\n",
       "       'SAT R Math Section', 'Decision'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since the data set only has first years (i.e.,only one category), \n",
    "# Admit.Type should be removed.\n",
    "print(TUtest['Admit Type'])\n",
    "TUtest=TUtest.drop('Admit Type',axis='columns')\n",
    "TUtest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "066c3ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "10000    77573-3387\n",
      "10001    78731-1541\n",
      "10002    76710-7247\n",
      "10003    78589-4116\n",
      "10004    78751-3134\n",
      "            ...    \n",
      "15138    91006-1737\n",
      "15139    77494-5298\n",
      "15140    55443-1016\n",
      "15141    75024-2138\n",
      "15142    78624-6081\n",
      "Name: Permanent Postal, Length: 5143, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'train-test', 'Entry Term (Application)', 'Permanent Country',\n",
       "       'Sex', 'Ethnicity', 'Race', 'Religion',\n",
       "       'First_Source Origin First Source Date', 'Inquiry Date', 'Submitted',\n",
       "       'Application Source', 'Decision Plan', 'Staff Assigned Name', 'Legacy',\n",
       "       'Athlete', 'Sport 1 Sport', 'Sport 1 Rating', 'Sport 2 Sport',\n",
       "       'Sport 2 Rating', 'Sport 3 Sport', 'Sport 3 Rating',\n",
       "       'Academic Interest 1', 'Academic Interest 2',\n",
       "       'First_Source Origin First Source Summary', 'Total Event Participation',\n",
       "       'Count of Campus Visits', 'School #1 Organization Category',\n",
       "       'School 1 Code', 'School 1 Class Rank (Numeric)',\n",
       "       'School 1 Class Size (Numeric)', 'School 1 GPA', 'School 1 GPA Scale',\n",
       "       'School 1 GPA Recalculated', 'School 2 Class Rank (Numeric)',\n",
       "       'School 2 Class Size (Numeric)', 'School 2 GPA', 'School 2 GPA Scale',\n",
       "       'School 2 GPA Recalculated', 'School 3 Class Rank (Numeric)',\n",
       "       'School 3 Class Size (Numeric)', 'School 3 GPA', 'School 3 GPA Scale',\n",
       "       'School 3 GPA Recalculated', 'ACT Composite', 'ACT English',\n",
       "       'ACT Reading', 'ACT Math', 'ACT Science Reasoning', 'ACT Writing',\n",
       "       'SAT I CR + M',\n",
       "       'SAT R Evidence-Based Reading and Writing Section + Math Section',\n",
       "       'Permanent Geomarket', 'Citizenship Status', 'Academic Index',\n",
       "       'Intend to Apply for Financial Aid?', 'Merit Award',\n",
       "       'SAT Concordance Score (of SAT R)', 'ACT Concordance Score (of SAT R)',\n",
       "       'ACT Concordance Score (of SAT)', 'Test Optional',\n",
       "       'SAT I Critical Reading', 'SAT I Math', 'SAT I Writing',\n",
       "       'SAT R Evidence-Based Reading and Writing Section',\n",
       "       'SAT R Math Section', 'Decision'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column 4 - Permanent Postal\n",
    "print(TUtest['Permanent Postal'].isna().sum())\n",
    "#105 NAs.\n",
    "TUtest['Permanent Postal'].unique()\n",
    "#However, the column \"Permanent.Geomarket\" had already provided needed information\n",
    "#regarding the postal codes of different states. Therefore, this column might be\n",
    "#redundant, and we might just use \"Permanent.Geomarket\"\n",
    "#Therefore, let's remove this column and there is no need to handle the missing values\n",
    "print(TUtest['Permanent Postal'])\n",
    "TUtest=TUtest.drop('Permanent Postal',axis='columns')\n",
    "TUtest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "51345c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['United States', 'China', 'Vietnam', 'India', 'Iceland',\n",
       "       'Nicaragua', 'Mexico', 'Honduras', 'El Salvador', 'Taiwan', 'Peru',\n",
       "       'Japan', 'United Kingdom', 'Norway', 'Netherlands', 'Colombia',\n",
       "       'Ecuador', 'United Arab Emirates', 'Jordan', 'Ghana',\n",
       "       'South Africa', 'Spain', 'South Korea', 'Hong Kong S.A.R.',\n",
       "       'Guatemala', 'Egypt', 'Pakistan', 'Australia', 'Nepal',\n",
       "       'Kazakhstan', nan, 'Costa Rica', 'Saudi Arabia', 'Jamaica',\n",
       "       'Thailand', 'Uruguay', 'Canada', 'Singapore', 'Brazil', 'Ukraine',\n",
       "       'Belgium', 'Nigeria', 'Panama', 'Greece', 'Ethiopia', 'Romania',\n",
       "       'Uganda', 'Tanzania', 'Bolivia', 'Kuwait', 'France', 'Cambodia',\n",
       "       'Belize', 'Turkey', 'Portugal', 'Zimbabwe', 'Germany', 'Oman',\n",
       "       'Lebanon', 'Switzerland', 'Philippines', 'Indonesia', 'Mongolia',\n",
       "       'Russia', 'Morocco', 'Chile', 'Cyprus', 'Albania',\n",
       "       'Dominican Republic'], dtype=object)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column 5 - Permanent Country\n",
    "#0 NA.\n",
    "print(TUtest['Permanent Country'].isna().sum())\n",
    "#No irregular categories.\n",
    "TUtest['Permanent Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "55cc7975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States' 'China' 'Vietnam' 'India' 'UniqueCountry' 'Nicaragua'\n",
      " 'Mexico' 'Honduras' 'El Salvador' 'Taiwan' 'Peru' 'Japan'\n",
      " 'United Kingdom' 'Norway' 'Netherlands' 'Colombia' 'Ecuador'\n",
      " 'United Arab Emirates' 'Jordan' 'Ghana' 'South Africa' 'Spain'\n",
      " 'South Korea' 'Hong Kong S.A.R.' 'Guatemala' 'Pakistan' 'Nepal'\n",
      " 'Kazakhstan' nan 'Costa Rica' 'Saudi Arabia' 'Jamaica' 'Thailand'\n",
      " 'Uruguay' 'Canada' 'Singapore' 'Brazil' 'Belgium' 'Nigeria' 'Panama'\n",
      " 'Greece' 'Ethiopia' 'Tanzania' 'Bolivia' 'Kuwait' 'France' 'Cambodia'\n",
      " 'Belize' 'Turkey' 'Germany' 'Lebanon' 'Switzerland' 'Philippines'\n",
      " 'Indonesia' 'Russia' 'Morocco' 'Cyprus' 'Albania']\n"
     ]
    }
   ],
   "source": [
    "# List of countries that are unique to the test set\n",
    "MissingInTrain = ['Oman', 'Romania', 'Australia', 'Ukraine', 'Chile', 'Portugal', 'Dominican Republic', 'Zimbabwe', 'Uganda', 'Iceland', 'Egypt', 'Mongolia']\n",
    "\n",
    "# Make all missing coutries into one category\n",
    "TUtest['Permanent Country'] = TUtest['Permanent Country'].apply(\n",
    "    lambda x: 'UniqueCountry' if x in MissingInTrain else x\n",
    ")\n",
    "\n",
    "print(TUtest['Permanent Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "d39f4fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States' 'China' 'Vietnam' 'India' 'UniqueCountry' 'Nicaragua'\n",
      " 'Mexico' 'Honduras' 'El Salvador' 'Taiwan' 'Peru' 'Japan'\n",
      " 'United Kingdom' 'Norway' 'Netherlands' 'Colombia' 'Ecuador'\n",
      " 'United Arab Emirates' 'Jordan' 'Ghana' 'South Africa' 'Spain'\n",
      " 'South Korea' 'Hong Kong S.A.R.' 'Guatemala' 'Pakistan' 'Nepal'\n",
      " 'Kazakhstan' nan 'Costa Rica' 'Saudi Arabia' 'Jamaica' 'Thailand'\n",
      " 'Uruguay' 'Canada' 'Singapore' 'Brazil' 'Belgium' 'Nigeria' 'Panama'\n",
      " 'Greece' 'Ethiopia' 'Tanzania' 'Bolivia' 'Kuwait' 'France' 'Cambodia'\n",
      " 'Belize' 'Turkey' 'Germany' 'Lebanon' 'Switzerland' 'Philippines'\n",
      " 'Indonesia' 'Russia' 'Morocco' 'Cyprus' 'Albania']\n"
     ]
    }
   ],
   "source": [
    "# List of countries that are missing in the training data\n",
    "MissingInTrain = [\n",
    "    'Barbados', 'Dominica', 'Palestine', 'Poland', 'Georgia', 'Venezuela', 'Italy', \n",
    "    'Czech Republic', 'Ireland', 'Cayman Islands', 'Cameroon', 'Malaysia', 'Iran', \n",
    "    'The Bahamas', 'New Zealand', 'Bosnia and Herzegovina', 'Paraguay', 'Lithuania', \n",
    "    'Trinidad and Tobago', 'Bangladesh', 'Luxembourg', 'Montenegro', 'Kenya', \n",
    "    \"Cote D'Ivoire\", 'Uzbekistan', 'Mozambique'\n",
    "]\n",
    "\n",
    "# Apply the transformation to the 'Permanent Country' column in the TUtest dataframe\n",
    "TUtest['Permanent Country'] = TUtest['Permanent Country'].apply(\n",
    "    lambda x: 'UniqueCountry' if x in MissingInTrain else x\n",
    ")\n",
    "\n",
    "# Check the result (optional)\n",
    "print(TUtest['Permanent Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "53658fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United States', 'China', 'Vietnam', 'India', 'UniqueCountry',\n",
       "       'Nicaragua', 'Mexico', 'Honduras', 'El Salvador', 'Taiwan', 'Peru',\n",
       "       'Japan', 'United Kingdom', 'Norway', 'Netherlands', 'Colombia',\n",
       "       'Ecuador', 'United Arab Emirates', 'Jordan', 'Ghana',\n",
       "       'South Africa', 'Spain', 'South Korea', 'Hong Kong S.A.R.',\n",
       "       'Guatemala', 'Pakistan', 'Nepal', 'Kazakhstan', nan, 'Costa Rica',\n",
       "       'Saudi Arabia', 'Jamaica', 'Thailand', 'Uruguay', 'Canada',\n",
       "       'Singapore', 'Brazil', 'Belgium', 'Nigeria', 'Panama', 'Greece',\n",
       "       'Ethiopia', 'Tanzania', 'Bolivia', 'Kuwait', 'France', 'Cambodia',\n",
       "       'Belize', 'Turkey', 'Germany', 'Lebanon', 'Switzerland',\n",
       "       'Philippines', 'Indonesia', 'Russia', 'Morocco', 'Cyprus',\n",
       "       'Albania'], dtype=object)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TUtest['Permanent Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "7b97b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['M' 'F']\n"
     ]
    }
   ],
   "source": [
    "#Column6 - Sex\n",
    "print(TUtest['Sex'].isna().sum())\n",
    "#No NA.\n",
    "print(TUtest['Sex'].unique())\n",
    "#No irregular categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "bb0b2d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "['Hispanic/Latino' 'Non Hispanic/Latino' nan]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column7 - Ethnicity\n",
    "print(TUtest['Ethnicity'].isna().sum())\n",
    "#158 NAs.\n",
    "print(TUtest['Ethnicity'].unique())\n",
    "#No irregular categories.\n",
    "# It is fair to replace NAs with \"Not Specified\" as we do not have other columns for inter-field checking.\n",
    "\n",
    "TUtest['Ethnicity'].fillna(\"Not specified\",inplace=True)\n",
    "TUtest['Ethnicity'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "feeb5a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "['White' nan 'Asian'\n",
      " 'American Indian or Alaska Native, Black or African American, White'\n",
      " 'Black or African American' 'Asian, White'\n",
      " 'Native Hawaiian or Other Pacific' 'Black or African American, White'\n",
      " 'American Indian or Alaska Native, White'\n",
      " 'American Indian or Alaska Native'\n",
      " 'Asian, Native Hawaiian or Other Pacific'\n",
      " 'Asian, Native Hawaiian or Other Pacific, White'\n",
      " 'Asian, Black or African American, White'\n",
      " 'Asian, Black or African American'\n",
      " 'American Indian or Alaska Native, Asian, White'\n",
      " 'Native Hawaiian or Other Pacific, White'\n",
      " 'American Indian or Alaska Native, Asian'\n",
      " 'Asian, Black or African American, Native Hawaiian or Other Pacific, White'\n",
      " 'American Indian or Alaska Native, Asian, Black or African American, Native Hawaiian or Other Pacific, White'\n",
      " 'American Indian or Alaska Native, Asian, Black or African American, White'\n",
      " 'American Indian or Alaska Native, Black or African American'\n",
      " 'Black or African American, Native Hawaiian or Other Pacific, White']\n"
     ]
    }
   ],
   "source": [
    "#Column8 - Race\n",
    "print(TUtest['Race'].isna().sum())\n",
    "#389 NAs.\n",
    "print(TUtest['Race'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "db39e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No irregular categories.\n",
    "#Impute NAs with \"Not specified\", similar to what we do for Ethnicity.\n",
    "TUtest['Race'].fillna(\"Not specified\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "ebe52f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Race\n",
       "White                                                                                                          3530\n",
       "Asian                                                                                                           843\n",
       "Black or African American                                                                                       255\n",
       "Not specified                                                                                                   166\n",
       "Asian, White                                                                                                    158\n",
       "American Indian or Alaska Native, White                                                                          59\n",
       "Black or African American, White                                                                                 45\n",
       "American Indian or Alaska Native                                                                                 37\n",
       "Asian, Black or African American, White                                                                           8\n",
       "Asian, Black or African American                                                                                  7\n",
       "Asian, Native Hawaiian or Other Pacific, White                                                                    7\n",
       "Asian, Native Hawaiian or Other Pacific                                                                           6\n",
       "Native Hawaiian or Other Pacific                                                                                  6\n",
       "American Indian or Alaska Native, Black or African American, White                                                3\n",
       "Native Hawaiian or Other Pacific, White                                                                           3\n",
       "American Indian or Alaska Native, Asian, White                                                                    2\n",
       "American Indian or Alaska Native, Asian                                                                           2\n",
       "American Indian or Alaska Native, Black or African American                                                       2\n",
       "Asian, Black or African American, Native Hawaiian or Other Pacific, White                                         1\n",
       "American Indian or Alaska Native, Asian, Black or African American, Native Hawaiian or Other Pacific, White       1\n",
       "American Indian or Alaska Native, Asian, Black or African American, White                                         1\n",
       "Black or African American, Native Hawaiian or Other Pacific, White                                                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The current classification of Race is too detailed, which leads to very \n",
    "#low frequencies for some categories.Let's take a look at the value frequencies.\n",
    "TUtest['Race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "2b78adff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['White',\n",
       " 'Asian',\n",
       " 'Black or African American',\n",
       " 'Not specified',\n",
       " 'Asian, White',\n",
       " 'American Indian or Alaska Native, White',\n",
       " 'Black or African American, White']"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So let's combine some of the categories because a category with a small number of cases won't have \n",
    "#a significant effect on the target variable in the modeling stage.\n",
    "\n",
    "#Generate a race list that would be kept, the rest will be classified as 'others'\n",
    "RaceList = list(TUtest['Race'].value_counts()[:7].index)\n",
    "RaceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "19621838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Race\n",
       "White                                      3530\n",
       "Asian                                       843\n",
       "Black or African American                   255\n",
       "Not specified                               166\n",
       "Asian, White                                158\n",
       "Others                                       87\n",
       "American Indian or Alaska Native, White      59\n",
       "Black or African American, White             45\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TUtest['Race'] = \\\n",
    "TUtest['Race'].apply(lambda x: 'Others' if x not in RaceList else x)\n",
    "TUtest['Race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "1144ea8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2145\n",
      "['Christian' 'Methodist' 'Episcopal' nan 'Roman Catholic' 'Other'\n",
      " 'Buddhism' 'Unitarian' 'Church of Christ' 'Baptist' 'Anglican'\n",
      " 'Presbyterian' 'Hindu' 'Lutheran' 'Non-Denominational' 'Eastern Orthodox'\n",
      " 'Islam/Muslim' 'Jewish' 'Pentecostal' 'Protestant'\n",
      " 'United Church of Christ' 'Mormon-Latter Day Saints'\n",
      " \"Jehovah's Witnesses\" 'Southern Baptist' 'Jain' \"Baha'I\"\n",
      " 'Christian Scientist' 'Presbyterian Church of America' 'Evangelical'\n",
      " 'Assembly of God' 'Bible Churches' 'Society of Friends (Quaker)'\n",
      " 'United Methodist' 'Sikh' 'Church of God' 'Coptic Church (Egypt)'\n",
      " 'Lutheran-Missouri Synod' 'Christian Reformed' 'Independent'\n",
      " 'Church of the Nazarene']\n",
      "Religion\n",
      "Not specified                     2145\n",
      "Roman Catholic                     934\n",
      "Christian                          551\n",
      "Methodist                          264\n",
      "Baptist                            213\n",
      "Presbyterian                       147\n",
      "Hindu                              136\n",
      "Other                              116\n",
      "Anglican                           104\n",
      "Jewish                              82\n",
      "Lutheran                            82\n",
      "Islam/Muslim                        79\n",
      "Non-Denominational                  48\n",
      "Church of Christ                    48\n",
      "Buddhism                            36\n",
      "Eastern Orthodox                    30\n",
      "Episcopal                           27\n",
      "Unitarian                           16\n",
      "Pentecostal                         14\n",
      "Protestant                           8\n",
      "Mormon-Latter Day Saints             8\n",
      "Evangelical                          6\n",
      "Assembly of God                      5\n",
      "Jain                                 5\n",
      "Sikh                                 5\n",
      "Southern Baptist                     4\n",
      "Coptic Church (Egypt)                3\n",
      "United Methodist                     3\n",
      "Bible Churches                       3\n",
      "United Church of Christ              3\n",
      "Presbyterian Church of America       3\n",
      "Society of Friends (Quaker)          2\n",
      "Christian Scientist                  2\n",
      "Baha'I                               2\n",
      "Church of God                        2\n",
      "Jehovah's Witnesses                  2\n",
      "Christian Reformed                   2\n",
      "Lutheran-Missouri Synod              1\n",
      "Independent                          1\n",
      "Church of the Nazarene               1\n",
      "Name: count, dtype: int64\n",
      "Religion\n",
      "Not specified               2145\n",
      "Roman Catholic               934\n",
      "Christian                    551\n",
      "OtherRelgiousAffiliation     358\n",
      "Methodist                    264\n",
      "Baptist                      213\n",
      "Presbyterian                 147\n",
      "Hindu                        136\n",
      "Anglican                     104\n",
      "Lutheran                      82\n",
      "Jewish                        82\n",
      "Islam/Muslim                  79\n",
      "Non-Denominational            48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column 9 - Religion\n",
    "# print # of NAs\n",
    "print(TUtest['Religion'].isnull().sum()) # 4177 null values\n",
    "\n",
    "# print unique values for Religion\n",
    "print(TUtest.Religion.unique())\n",
    "\n",
    "#Impute NAs with \"Not specified\", similar to what we do for Race.\n",
    "TUtest[\"Religion\"] = TUtest['Religion'].apply(lambda x: \"Not specified\" if pd.isnull(x) else x) #.apply iterates thru the dataframe, in this case replacing the nulls with \"Not Specified\"\n",
    "\n",
    "#The current classification of Race is too detailed, which leads to very \n",
    "#low frequencies for some categories.Print the value frequencies.\n",
    "print(TUtest[\"Religion\"].value_counts())\n",
    "\n",
    "#Religion has lots of categories, with some categories having a very small number of cases. \n",
    "#Let's combine similar levels into one level( for example:['Bible Churches','Christian Reformed','Christian Scientist','Church of Christ','Church of God'] )\n",
    "TUtest['Religion'] = TUtest.Religion.apply(lambda x: \"OtherRelgiousAffiliation\" if x in ['Pentecostal',\n",
    "                                                      'Unitarian','Protestant','Mormon-Latter Day Saints',\n",
    "                                                      'Evangelical','Assembly of God','Bible Churches',\n",
    "                                                      'Christian Reformed', 'Christian Scientist',\n",
    "                                                      'Church of Christ','Church of God', 'Southern Baptist', \n",
    "                                                      'United Methodist', 'United Church of Christ',\n",
    "                                                      'Society of Friends (Quaker)',\n",
    "                                                      'Presbyterian Church of America',\n",
    "                                                      'Lutheran-Missourie Synod',\"Jehovah's Witnesses\",\n",
    "                                                      'Coptic Church (Egypt)','Mennonite','Episcopal',\n",
    "                                                      'Eastern Orthodox','Lutheran-Missouri Synod','Baha',\n",
    "                                                      'Jewish Messianic','Zoroastrian',\"Baha'I\",'Jain','Sikh',\n",
    "                                                      'Buddhism','Other','Church of the Nazarene','Independent'\n",
    "                                                                                        \n",
    "                                                                                        \n",
    "                                                                                        ] else x)\n",
    "#I combined all small christian denominations below   100 \n",
    "\n",
    "\n",
    "#then combine levels with less than 100 cases into \"Other\" because a level accounting for lower than 1% \n",
    "#of testing set is very unlikely to have a significant effect on the target variable.\n",
    "\n",
    "print(TUtest.Religion.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "86a7ac4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000   2018-02-19 11:11:00\n",
      "10001   2018-02-19 11:11:00\n",
      "10002   2019-10-10 12:03:00\n",
      "10003   2016-11-02 06:00:00\n",
      "10004   2018-10-08 21:59:00\n",
      "                ...        \n",
      "15138   2018-02-19 11:11:00\n",
      "15139   2018-02-16 16:31:00\n",
      "15140   2019-06-25 12:50:00\n",
      "15141   1900-01-01 00:00:00\n",
      "15142   2017-01-30 17:24:00\n",
      "Name: First_Source Origin First Source Date, Length: 5143, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#Column 10 - First_Source Origin First Source Date\n",
    "print(TUtest['First_Source Origin First Source Date'].isna().sum())\n",
    "#No NAs.\n",
    "\n",
    "#convert to date format\n",
    "TUtest['First_Source Origin First Source Date'] = pd.to_datetime(\n",
    "    TUtest['First_Source Origin First Source Date'], errors='coerce').fillna(pd.to_datetime('1900-01-01'))\n",
    "# Display the converted column\n",
    "print(TUtest['First_Source Origin First Source Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "6c1a2cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000    2018-09-18 22:16:00\n",
       "10001    2018-04-25 10:59:00\n",
       "10002    2019-10-10 11:52:00\n",
       "10003        Did not Inquire\n",
       "10004    2018-10-08 22:06:00\n",
       "                ...         \n",
       "15138        Did not Inquire\n",
       "15139    2018-08-28 09:26:00\n",
       "15140        Did not Inquire\n",
       "15141    2017-09-10 10:24:00\n",
       "15142    2018-02-19 11:19:00\n",
       "Name: Inquiry Date, Length: 5143, dtype: object"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column11 - Inquiry Date\n",
    "print(TUtest['Inquiry Date'].isna().sum())\n",
    "#3181 NAs.\n",
    "\n",
    "#convert to date format\n",
    "TUtest['Inquiry Date']= pd.to_datetime(TUtest['Inquiry Date'], errors='coerce')\n",
    "\n",
    "# Filling NaNs with a statement saying they did not inquire abount trinity admissions\n",
    "TUtest['Inquiry Date'].fillna(\"Did not Inquire\", inplace=True)\n",
    "TUtest['Inquiry Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "82ed9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Column 12 - Submitted\n",
    "print(TUtest['Submitted'].isna().sum())\n",
    "#No NAs.\n",
    "\n",
    "#convert to date format\n",
    "TUtest['Submitted'] = pd.to_datetime(TUtest['Submitted'], errors='ignore').fillna(pd.to_datetime('1900-01-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "94bfef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column10-12\n",
    "# After viewing Column10-12, it would be interesting to see\n",
    "# whether the differences between submission date and First_Source date,\n",
    "# and the differences between submission date and inquiry date, affect the response.\n",
    "# So let's calculate the time difference between submission date and first_source date.\n",
    "\n",
    "# Convert 'Submitted' and 'First_Source Origin First Source Date' to datetime, setting any missing values to '1900-01-01'\n",
    "TUtest['Submitted'] = pd.to_datetime(TUtest['Submitted'], errors='coerce').fillna(pd.to_datetime('1900-01-01'))\n",
    "TUtest['First_Source Origin First Source Date'] = pd.to_datetime(TUtest['First_Source Origin First Source Date'], errors='coerce').fillna(pd.to_datetime('1900-01-01'))\n",
    "\n",
    "# Convert 'Inquiry Date' to datetime, setting any missing values to a placeholder date\n",
    "# Add an indicator column to mark rows with no inquiry\n",
    "TUtest['Inquiry Date'] = pd.to_datetime(TUtest['Inquiry Date'], errors='coerce').fillna(pd.to_datetime('1900-01-01'))\n",
    "TUtest['Inquiry Status'] = TUtest['Inquiry Date'].apply(lambda x: \"Did not Inquire\" if x == pd.to_datetime('1900-01-01') else \"Inquired\")\n",
    "\n",
    "# Calculate the time difference in weeks between 'Submitted' and 'First_Source Origin First Source Date'\n",
    "TUtest['Submit_FirstSource'] = (TUtest['Submitted'] - TUtest['First_Source Origin First Source Date']).dt.days / 7\n",
    "\n",
    "# Calculate the time difference in weeks between 'Submitted' and 'Inquiry Date'\n",
    "TUtest['Submit_Inquiry'] = (TUtest['Submitted'] - TUtest['Inquiry Date']).dt.days / 7\n",
    "\n",
    "# Optionally, round the calculated week differences to whole numbers\n",
    "TUtest['Submit_FirstSource'] = TUtest['Submit_FirstSource'].round(0)\n",
    "TUtest['Submit_Inquiry'] = TUtest['Submit_Inquiry'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "051af5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are NAs in Inquiry.Date,\n",
    "#thus leading to NAs in Submit_Inquiry.\n",
    "#Impute NAs in Submit_Inquiry with median values.\n",
    "\n",
    "TUtest['Submit_Inquiry'].fillna(TUtest['Submit_Inquiry'].median(),inplace=True)\n",
    "TUtest['Submit_Inquiry'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "9141f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Column10-12 after you created new variables above.  \n",
    "TUtest.drop('First_Source Origin First Source Date', axis='columns', inplace=True)\n",
    "TUtest.drop('Inquiry Date', axis='columns', inplace=True)\n",
    "TUtest.drop('Submitted', axis='columns', inplace=True)\n",
    "TUtest.drop(\"Inquiry Status\", axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "04e423d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['ApplyTexas' 'CommonApp' 'Coalition' 'Select Scholar']\n"
     ]
    }
   ],
   "source": [
    "#Column13 - Application.Source\n",
    "print( TUtest['Application Source'].isna().sum())\n",
    "#No NAs.\n",
    "print(TUtest['Application Source'].unique())\n",
    "#No irregular categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "6208e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['Early Action I' 'Early Action' 'Regular Decision' 'Early Action II'\n",
      " 'Early Decision II' 'Early Decision I']\n"
     ]
    }
   ],
   "source": [
    "#Column14 - Decision.Plan\n",
    "print(TUtest['Decision Plan'].isna().sum())\n",
    "#No NAs.\n",
    "print(TUtest['Decision Plan'].unique())\n",
    "#No irregular categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "98e91db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column15 - Staff.Assigned.Name\n",
    "#Based on variable description, this variable might not be useful and provide\n",
    "#insightful information in the modeling.\n",
    "#Also, some staffs already left Trinity.\n",
    "#So remove this variable\n",
    "TUtest.drop(['Staff Assigned Name'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "96375269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4659\n",
      "[nan 'Legacy' 'Legacy, Opt Out' 'Legacy, VIP' 'Athlete, Legacy, Opt Out'\n",
      " 'Athlete, Legacy' 'Legacy, Opt Out, VIP' 'Fine Arts, Legacy, VIP'\n",
      " 'Athlete, Legacy, VIP' 'Fine Arts, Legacy, Opt Out' 'Fine Arts, Legacy'\n",
      " 'Athlete, Fine Arts, Legacy, Opt Out, VIP'\n",
      " 'Fine Arts, Legacy, Opt Out, VIP' 'Athlete, Legacy, Opt Out, VIP'\n",
      " 'Athlete, Fine Arts, Legacy, VIP']\n"
     ]
    }
   ],
   "source": [
    "#Column16 - Legacy\n",
    "print(TUtest['Legacy'].isna().sum())\n",
    "#No NAs.\n",
    "print(TUtest['Legacy'].unique())\n",
    "#No irregular categories.\n",
    "#Impute NAs with \"No Legacy\"\n",
    "TUtest['Legacy'].fillna(\"No Legacy\",inplace=True)\n",
    "TUtest['Legacy'].isna().sum()\n",
    "\n",
    "#Legacy has many options, leading some options to having only a small number of cases.\n",
    "#Let's group all the options into 3 categories ('Legacy',\"No Legacy\", \"Legacy, Opt Out\") \n",
    "#so that each category has the chance to affect the response variable.\n",
    "TUtest['Legacy']=\\\n",
    "TUtest['Legacy'].apply(lambda x: 'Legacy, Opt Out' if x not in ['Legacy','No Legacy'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "33a7f854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4437\n",
      "Athlete\n",
      "Athlete                                     460\n",
      "Athlete, Opt Out                            161\n",
      "Athlete, Legacy                              34\n",
      "Athlete, Legacy, Opt Out                     16\n",
      "Athlete, Fine Arts                           10\n",
      "Athlete, Legacy, VIP                          9\n",
      "Athlete, VIP                                  7\n",
      "Athlete, Opt Out, VIP                         3\n",
      "Athlete, Fine Arts, Opt Out                   2\n",
      "Athlete, Legacy, Opt Out, VIP                 2\n",
      "Athlete, Fine Arts, Legacy, Opt Out, VIP      1\n",
      "Athlete, Fine Arts, Legacy, VIP               1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column17 - Athlete\n",
    "# print # NAs.\n",
    "print(TUtest['Athlete'].isnull().sum()) #checking for NAs / sum, 8683 null values\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtest['Athlete'].value_counts()) #unique value counts returning amount of groups\n",
    "\n",
    "#Impute NAs with \"Non-Athlete\"\n",
    "TUtest['Athlete'] = TUtest.Athlete.apply(lambda x: \"Non-Athlete\" if pd.isnull(x) else x) \n",
    "#.apply() lambda x returning \"Non-Athlete\" for any null value \n",
    "\n",
    "#Similar to Legacy, Athlete has many categories with a few cases.\n",
    "#Group all options into three categories: \n",
    "#Athlete, Non-Athlete, and Athlete, Opt Out.\n",
    "\n",
    "TUtest['Athlete'] = \\\n",
    "TUtest.Athlete.apply(lambda x: \"Athlete, Opt Out\" if x in [\"Athlete, Opt Out\", \"Athlete, Legacy, Opt Out\", \"Athlete, Legacy, Opt Out, VIP\",\"Athlete, Opt Out, VIP\",\"Athlete, Fine Arts, Opt Out\",\"Athlete, Fine Arts, Legacy, Opt Out, VIP\"] else x) \n",
    "#grouping variables into one group called Athlete Opt Out\n",
    "# Done by checking if x is in the specified list\n",
    "\n",
    "TUtest['Athlete'] = \\\n",
    "TUtest.Athlete.apply(lambda x: \"Athlete\" if x not in [\"Non-Athlete\",\"Athlete, Opt Out\"] else x) \n",
    "#this is grouping items into an Athlete group if they are NOT in these non athlete or opt out groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "b041e579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athlete\n",
      "Non-Athlete         4437\n",
      "Athlete              521\n",
      "Athlete, Opt Out     185\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtest['Athlete'].value_counts()) \n",
    "# Just checking to see the cleaning was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "566b804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4437\n",
      "Sport 1 Sport\n",
      "Football               169\n",
      "Soccer Men              75\n",
      "Baseball                63\n",
      "Cross Country Men       45\n",
      "Basketball Men          39\n",
      "Cross Country Women     38\n",
      "Soccer Women            35\n",
      "Track Women             35\n",
      "Swimming Men            30\n",
      "Tennis Women            30\n",
      "Track Men               29\n",
      "Swimming Women          26\n",
      "Softball                25\n",
      "Volleyball              21\n",
      "Basketball Women        16\n",
      "Tennis Men              11\n",
      "Golf Men                 8\n",
      "Diving Women             6\n",
      "Golf Women               5\n",
      "Name: count, dtype: int64\n",
      "Sport 1 Sport\n",
      "No Sport         4437\n",
      "Football          169\n",
      "Soccer            110\n",
      "Cross Country      83\n",
      "Track              64\n",
      "Baseball           63\n",
      "Swimming           56\n",
      "Basketball         55\n",
      "Tennis             41\n",
      "Softball           25\n",
      "Volleyball         21\n",
      "Golf               13\n",
      "Diving              6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print NAs\n",
    "print(TUtest['Sport 1 Sport'].isnull().sum())  # 8683 null values\n",
    "\n",
    "# Print unique value counts\n",
    "print(TUtest['Sport 1 Sport'].value_counts())  # Displays the unique sport counts\n",
    "\n",
    "# Impute NAs with \"No Sport\"\n",
    "TUtest['Sport 1 Sport'] = TUtest['Sport 1 Sport'].fillna(\"No Sport\")\n",
    "\n",
    "# Remove gender-specific suffixes from sport names (e.g., \"Men\", \"Women\")\n",
    "# Create a mapping to remove gender-based distinctions\n",
    "gender_removal_map = {\n",
    "    \"Football Men\": \"Football\", \n",
    "    \"Football Women\": \"Football\",\n",
    "    \"Baseball Men\": \"Baseball\", \n",
    "    \"Baseball Women\": \"Baseball\",\n",
    "    \"Cross Country Men\": \"Cross Country\", \n",
    "    \"Cross Country Women\": \"Cross Country\",\n",
    "    \"Soccer Men\": \"Soccer\", \n",
    "    \"Soccer Women\": \"Soccer\",\n",
    "    \"Track Men\": \"Track\", \n",
    "    \"Track Women\": \"Track\",\n",
    "    \"Basketball Men\": \"Basketball\", \n",
    "    \"Basketball Women\": \"Basketball\",\n",
    "    \"Swimming Men\": \"Swimming\", \n",
    "    \"Swimming Women\": \"Swimming\",\n",
    "    \"Tennis Men\": \"Tennis\", \n",
    "    \"Tennis Women\": \"Tennis\",\n",
    "    \"Golf Men\": \"Golf\", \n",
    "    \"Golf Women\": \"Golf\",\n",
    "    \"Diving Men\": \"Diving\", \n",
    "    \"Diving Women\": \"Diving\",\n",
    "    \"Softball\": \"Softball\",\n",
    "    \"Volleyball\": \"Volleyball\"\n",
    "}\n",
    "\n",
    "# Apply the gender_removal_map to group the sports\n",
    "TUtest['Sport 1 Sport'] = TUtest['Sport 1 Sport'].map(gender_removal_map).fillna(TUtest['Sport 1 Sport'])\n",
    "\n",
    "# Now the 'Sport 1 Sport' column should only contain the sport names without gender distinctions\n",
    "print(TUtest['Sport 1 Sport'].value_counts())  # Check updated value counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "d0eed270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sport 1 Sport\n",
      "No Sport         4437\n",
      "Football          169\n",
      "Soccer            110\n",
      "Cross Country      83\n",
      "Track              64\n",
      "Baseball           63\n",
      "Swimming           56\n",
      "Basketball         55\n",
      "Tennis             41\n",
      "Softball           25\n",
      "Volleyball         21\n",
      "Golf               13\n",
      "Diving              6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column18 - Sport 1 Sport\n",
    "\n",
    "# print # NAs.\n",
    "print(TUtest['Sport 1 Sport'].isnull().sum()) #8683 null values\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtest['Sport 1 Sport'].value_counts()) \n",
    "# value counts shows there are 20 different groups, 2 of which have over 100 observations\n",
    "\n",
    "#Impute NAs with \"No Sport\"\n",
    "TUtest['Sport 1 Sport'] = TUtest['Sport 1 Sport'].apply(lambda x: \"No Sport\" if pd.isnull(x) else x) \n",
    "\n",
    "#Group sport men and sport women into one group\n",
    "#so that each group has sufficient cases to have an impact on the response.\n",
    "TUtest['Sport 1 Sport'] = TUtest['Sport 1 Sport'].apply(lambda x: \"Sport\" if x in \n",
    "                                                          [\"Football\", \"Baseball\", \"Cross Country Men\", \n",
    "                                                           \"Soccer Men\", \"Track Men\", \"Basketball Men\", \n",
    "                                                           \"Swimming Men\", \"Tennis Men\", \"Golf Men\", \n",
    "                                                           \"Diving Men\", \"Track Women\",\"Cross Country Women\",\n",
    "                                                           \"Soccer Women\",\"Swimming Women\",\"Tennis Women\",\n",
    "                                                           \"Softball\",\"Volleyball\",\"Basketball Women\",\n",
    "                                                           \"Golf Women\",\"Diving Women\"] else x ) \n",
    "# Making it into two easily defined groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "54f34353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sport 1 Sport\n",
      "No Sport         4437\n",
      "Sport             278\n",
      "Soccer            110\n",
      "Cross Country      83\n",
      "Track              64\n",
      "Swimming           56\n",
      "Basketball         55\n",
      "Tennis             41\n",
      "Golf               13\n",
      "Diving              6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtest['Sport 1 Sport'].value_counts()) \n",
    "# Checking to see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "db573d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4437\n",
      "Sport 1 Rating\n",
      "Blue Chip    316\n",
      "Varsity      210\n",
      "Franchise    180\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column19 - Sport 1 Rating\n",
    "# print # NAs.\n",
    "print(TUtest['Sport 1 Rating'].isnull().sum()) # 8683 null values\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtest['Sport 1 Rating'].value_counts()) # found 3 different groups all 250 observations of each other\n",
    "\n",
    "#Impute NAs with \"No Sport\"\n",
    "TUtest['Sport 1 Rating'] = TUtest[\"Sport 1 Rating\"].apply(lambda x: \"No Sport\" if pd.isna(x) else x)\n",
    "# Just as before, I used the .apply function to replace any null values found thru pd.isna() function, \n",
    "# in this case with the value \"No Sport\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "824122a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4930\n",
      "Sport 2 Sport\n",
      "Track & Field          65\n",
      "Basketball             27\n",
      "Football               20\n",
      "Soccer                 20\n",
      "Baseball               19\n",
      "Cross Country          14\n",
      "Swimming               14\n",
      "Tennis                 12\n",
      "Golf                    6\n",
      "Volleyball              5\n",
      "Track Men               4\n",
      "Track Women             2\n",
      "Cross Country Women     1\n",
      "Cross Country Men       1\n",
      "Softball                1\n",
      "Tennis Men              1\n",
      "Diving                  1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column20 - Sport 2 Sport\n",
    "\n",
    "# print # NAs.\n",
    "print(TUtest['Sport 2 Sport'].isnull().sum()) #found 9583 null values using .isnull().sum()\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtest['Sport 2 Sport'].value_counts()) \n",
    "# value counts shows 20 different unique groups where only 1 group has over 125 observations\n",
    "\n",
    "#impute NAs with \"No 2ndSport\".\n",
    "TUtest['Sport 2 Sport'] = TUtest[\"Sport 2 Sport\"].apply(lambda x: \"No 2ndSport\" if pd.isna(x) else x) \n",
    "#used the .apply function to replace any null values found thru pd.isna() function with the string \"No 2ndSport\"\n",
    "\n",
    "#The number of cases for each sport type is very small (< about 1% of the data set).\n",
    "#It's better to group all options into 2 categories: 2ndSport vs. No 2ndSport.\n",
    "TUtest['Sport 2 Sport'] = TUtest[\"Sport 2 Sport\"].apply(lambda x: \"2nd Sport\" if x not in [\"No 2ndSport\"] else x) \n",
    "#grouped  anything that was not found in \"No 2ndSport\" into a new group called \"2nd Sport\" using .apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "e23d474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sport 2 Sport\n",
      "No 2ndSport    4930\n",
      "2nd Sport       213\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtest['Sport 2 Sport'].value_counts()) \n",
    "# Verifying code worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "6f6f7bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5128\n",
      "[nan 'Varsity' 'Blue Chip' 'Franchise']\n"
     ]
    }
   ],
   "source": [
    "#Column21 - Sport 2 Rating\n",
    "print(TUtest['Sport 2 Rating'].isna().sum())\n",
    "#9957 NAs.\n",
    "print(TUtest['Sport 2 Rating'].unique())\n",
    "#Only 43 out of 10000 observations are rated, which is less than 0.5% of the data set!\n",
    "#Sport.2.Rating will not have much impact on the target.\n",
    "#Remove it in the modeling stage.\n",
    "\n",
    "TUtest.drop('Sport 2 Rating',axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "0445306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5069\n",
      "Sport 3 Sport\n",
      "Basketball           17\n",
      "Track & Field        14\n",
      "Cross Country         8\n",
      "Soccer                6\n",
      "Volleyball            6\n",
      "Swimming              5\n",
      "Baseball              5\n",
      "Football              4\n",
      "Golf                  4\n",
      "Diving                2\n",
      "Softball              1\n",
      "Tennis                1\n",
      "Cross Country Men     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column22 - Sport 3 Sport\n",
    "\n",
    "# print # NAs.\n",
    "print(TUtest['Sport 3 Sport'].isna().sum()) #9838 null values found with .isna().sum()\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtest['Sport 3 Sport'].value_counts())#value counts found 12 different unique values all having under 41 observations\n",
    "\n",
    "#impute NAs with \"No 3rdSport\".\n",
    "TUtest['Sport 3 Sport'] = TUtest[\"Sport 3 Sport\"].apply(lambda x: \"No 3rdSport\" if pd.isna(x) else x) \n",
    "#used the .apply function to replace any null values found thru pd.isna() function with the string \"No 3rdSport\"\n",
    "\n",
    "#The number of cases for each sport type is very small (< 0.5% of the data set).\n",
    "#It's better to group all options into 2 categories: 3rdSport vs. No 3rdSport.\n",
    "TUtest['Sport 3 Sport'] = TUtest[\"Sport 3 Sport\"].apply(lambda x: \"3rdSport\" if x not in [\"No 3rdSport\"] else x) \n",
    "# Same technique as before but the replacing value is 3rdSport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "7e4d75fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sport 3 Sport\n",
      "No 3rdSport    5069\n",
      "3rdSport         74\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtest['Sport 3 Sport'].value_counts())#value counts found 12 different unique values all having under 41 observations\n",
    "# Verifying the code worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "e33827cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5142\n",
      "[nan 'Varsity']\n"
     ]
    }
   ],
   "source": [
    "#Column23 - Sport.3.Rating\n",
    "\n",
    "print(TUtest['Sport 3 Rating'].isna().sum())\n",
    "#9998 NAs.\n",
    "print(TUtest['Sport 3 Rating'].unique())\n",
    "#No questionable category.\n",
    "#Only 2 out of 10000 observations are rated, which will not provide much insightful\n",
    "#information. Therefore,remove this column\n",
    "TUtest.drop('Sport 3 Rating',axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "764e9f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['Engineering Science' 'English' 'Psychology' 'Pre-Medical' 'Biochemistry'\n",
      " 'Business - Communication Management' 'Biology' 'International Studies'\n",
      " 'Physics' 'Political Science' 'Business - Accounting'\n",
      " 'Business Legal Studies' 'History' 'Mathematics' 'Pre-Law' 'Finance'\n",
      " 'Business Analytics & Technology' 'Computer Science' 'Theatre'\n",
      " 'Neuroscience' 'Business - Management' 'Chemistry' 'Undecided' 'Music'\n",
      " 'Business' 'Art' 'Biochemistry & Molecular Biology'\n",
      " 'Business - Marketing' 'Economics' 'German' 'Environmental Studies'\n",
      " 'Business - International Business' 'Creative Writing' 'Sociology'\n",
      " 'Geosciences' 'Pharmacy' 'Art History' 'Architecture' 'Entrepreneurship'\n",
      " 'Communication' 'Nursing' 'Anthropology' 'Classical Languages'\n",
      " 'Education' 'Mathematical Finance' 'Latin' 'Business - Sport Management'\n",
      " 'Chinese' 'Urban Studies' 'Philosophy' 'New Media' 'Religion'\n",
      " 'Architectural Studies' 'Spanish' 'East Asian Studies' 'Music Education'\n",
      " 'Agriculture' 'French' 'Human Communication' 'Russian'\n",
      " 'Business - Management Information Systems' 'Italian'\n",
      " 'Global Latinx Studies' 'Astronomy' nan 'Cognitive Science'\n",
      " 'Ancient Mediterranean Studies' 'Pre-Dental' \"Women's & Gender Studies\"\n",
      " 'Film Studies' 'Arts, Letters & Enterprise' 'Biomathematics'\n",
      " 'Applied Chemistry' 'Linguistics' 'Pre-Veterinary']\n"
     ]
    }
   ],
   "source": [
    "#Column24 - Academic Interest 1\n",
    "print(TUtest['Academic Interest 1'].isna().sum())\n",
    "#1 NAs.\n",
    "print(TUtest['Academic Interest 1'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "a7c98fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11756 nan Business - Management\n",
      "13813 nan nan\n"
     ]
    }
   ],
   "source": [
    "# Step1: Most of the NAs for Academic.Interest.1 have a value for Academic.Interest.2\n",
    "#We may assign the corresponding values in Academic.Interest.2 \n",
    "#to NAs in Academic.Interest.1 if Academic.Interest.2 has a value.\n",
    "\n",
    "# When update values in a subset of dataframes, \n",
    "# Try using .loc[row_indexer,col_indexer] = value instead to avoid chained indexing issue\n",
    "\n",
    "for i,row in TUtest.iterrows():\n",
    "    if pd.isna(row['Academic Interest 1']):\n",
    "        print(i,row['Academic Interest 1'],row['Academic Interest 2'])\n",
    "        TUtest.loc[i,'Academic Interest 1']=TUtest.loc[i,'Academic Interest 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "21559154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Engineering Science', 'English', 'Psychology', 'Pre-Medical',\n",
       "       'Biochemistry', 'Business - Communication Management', 'Biology',\n",
       "       'International Studies', 'Physics', 'Political Science',\n",
       "       'Business - Accounting', 'Business Legal Studies', 'History',\n",
       "       'Mathematics', 'Pre-Law', 'Finance',\n",
       "       'Business Analytics & Technology', 'Computer Science', 'Theatre',\n",
       "       'Neuroscience', 'Business - Management', 'Chemistry', 'Undecided',\n",
       "       'Music', 'Business', 'Art', 'Biochemistry & Molecular Biology',\n",
       "       'Business - Marketing', 'Economics', 'German',\n",
       "       'Environmental Studies', 'Business - International Business',\n",
       "       'Creative Writing', 'Sociology', 'Geosciences', 'Pharmacy',\n",
       "       'Art History', 'Architecture', 'Entrepreneurship', 'Communication',\n",
       "       'Nursing', 'Anthropology', 'Classical Languages', 'Education',\n",
       "       'Mathematical Finance', 'Latin', 'Business - Sport Management',\n",
       "       'Chinese', 'Urban Studies', 'Philosophy', 'New Media', 'Religion',\n",
       "       'Architectural Studies', 'Spanish', 'East Asian Studies',\n",
       "       'Music Education', 'Agriculture', 'French', 'Human Communication',\n",
       "       'Russian', 'Business - Management Information Systems', 'Italian',\n",
       "       'Global Latinx Studies', 'Astronomy', 'Cognitive Science',\n",
       "       'Ancient Mediterranean Studies', 'Pre-Dental',\n",
       "       \"Women's & Gender Studies\", 'Film Studies',\n",
       "       'Arts, Letters & Enterprise', 'Biomathematics',\n",
       "       'Applied Chemistry', 'Linguistics', 'Pre-Veterinary'], dtype=object)"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step2:For the remaining NAs in Academic.Interest.1, assign Undecided.\n",
    "TUtest['Academic Interest 1'].fillna('Undecided',inplace=True)\n",
    "TUtest['Academic Interest 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "f073f308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Academic Interest 1\n",
       "Pre-Medical                            517\n",
       "Biology                                455\n",
       "Engineering Science                    435\n",
       "Business                               410\n",
       "Others                                 406\n",
       "Psychology                             310\n",
       "Computer Science                       297\n",
       "Undecided                              235\n",
       "Political Science                      199\n",
       "Neuroscience                           196\n",
       "Biochemistry & Molecular Biology       147\n",
       "Biochemistry                           131\n",
       "International Studies                  125\n",
       "Business - Management                  115\n",
       "English                                111\n",
       "Mathematics                            109\n",
       "Economics                              103\n",
       "Business - International Business       96\n",
       "Business - Marketing                    93\n",
       "Pre-Law                                 92\n",
       "Business - Accounting                   88\n",
       "Chemistry                               82\n",
       "Environmental Studies                   82\n",
       "History                                 75\n",
       "Physics                                 72\n",
       "Communication                           62\n",
       "Business - Communication Management     51\n",
       "Education                               49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Step3:Group Business related options into \"Business\".\n",
    "TUtest['Academic Interest 1'] = \\\n",
    "TUtest['Academic Interest 1'].apply(lambda x: 'Business' if x in['Finance','Entrepreneurship'] else x)\n",
    "\n",
    "#Group options with a low number of cases (< 100 cases) into \"Others\".\n",
    "Majorlist=list(TUtest['Academic Interest 1'].value_counts()[:27].index)\n",
    "TUtest['Academic Interest 1'] = \\\n",
    "TUtest['Academic Interest 1'].apply(lambda x: 'Others' if x not in Majorlist else x)\n",
    "TUtest['Academic Interest 1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "901ebb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "#Column25 - Academic.Interest.2#Column25 - Academic.Interest.2\n",
    "\n",
    "#Check NAs\n",
    "print(  TUtest['Academic Interest 2'].isna().sum())\n",
    "#94 NAs.\n",
    "\n",
    "#Replace repeated academic interests with Undecided, \n",
    "#then make NAs Undecided\n",
    "TUtest['Academic Interest 2'].fillna('Undecided')\n",
    "\n",
    "#Group Business related options into \"Business\".\n",
    "TUtest['Academic Interest 2'] = \\\n",
    "TUtest['Academic Interest 2'].apply(lambda x: 'Business' if x in['Finance','Entrepreneurship'\n",
    "                                                                ,'Business Analytics & Technology'] else x)\n",
    "\n",
    "\n",
    "#Group options with a low number of cases (< 100 cases) into \"Others\".\n",
    "Majorlist=list(TUtest['Academic Interest 2'].value_counts()[:27].index)\n",
    "TUtest['Academic Interest 2']= \\\n",
    "TUtest['Academic Interest 2'].apply(lambda x: 'Others' if x not in Majorlist else x)\n",
    "TUtest['Academic Interest 2'].value_counts()\n",
    "\n",
    "\n",
    "# Additional line to replace 'Music' with 'Others' \n",
    "# (this is because Music is missing in the other dataframe, necessary step for modeling)\n",
    "TUtest['Academic Interest 2'] = TUtest['Academic Interest 2'].apply(\n",
    "    lambda x: 'Others' if x == 'Music' else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "59e65fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Academic Interest 2\n",
       "Others                               873\n",
       "Business                             455\n",
       "Biology                              389\n",
       "Pre-Medical                          295\n",
       "Psychology                           254\n",
       "Engineering Science                  235\n",
       "Biochemistry & Molecular Biology     210\n",
       "Computer Science                     180\n",
       "Political Science                    180\n",
       "Undecided                            167\n",
       "Biochemistry                         162\n",
       "Business - Management                160\n",
       "Neuroscience                         159\n",
       "Economics                            149\n",
       "Pre-Law                              135\n",
       "Mathematics                          120\n",
       "Business - Marketing                 118\n",
       "Chemistry                            118\n",
       "Environmental Studies                115\n",
       "Business - International Business    101\n",
       "International Studies                 97\n",
       "English                               88\n",
       "Physics                               84\n",
       "History                               84\n",
       "Business - Accounting                 75\n",
       "Sociology                             72\n",
       "Education                             68\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TUtest['Academic Interest 2'].value_counts()\n",
    "# Checking code worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "f511ade0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "First_Source Origin First Source Summary\n",
      "CBINQ    2406\n",
      "OAPP      507\n",
      "SRCH      280\n",
      "PSAT      249\n",
      "VST       238\n",
      "CF        186\n",
      "WEBTU     180\n",
      "CAPIQ     156\n",
      "CAP       146\n",
      "HSV        91\n",
      "ACT        87\n",
      "ATH        70\n",
      "SATR       66\n",
      "SIB        60\n",
      "YUVST      59\n",
      "TIF        59\n",
      "OEVNT      54\n",
      "HOBS       33\n",
      "NHI        31\n",
      "DOC        24\n",
      "ATHWB      21\n",
      "GRP        19\n",
      "APPTX      14\n",
      "OTH        14\n",
      "EM         13\n",
      "ACTPL      10\n",
      "NICHE      10\n",
      "CHEGG      10\n",
      "ALUM        7\n",
      "SAT         7\n",
      "TVINT       7\n",
      "WEBCA       6\n",
      "TFL         5\n",
      "TVOTH       4\n",
      "AP          3\n",
      "CLNIQ       3\n",
      "DBT         2\n",
      "MPC         1\n",
      "DUOL        1\n",
      "WEBOT       1\n",
      "APCU        1\n",
      "TEL         1\n",
      "ATS         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column26 - First_Source Origin First Source Summary\n",
    "\n",
    "# print # NAs.\n",
    "print(TUtest[\"First_Source Origin First Source Summary\"].isnull().sum()) \n",
    "# No nulls\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtest[\"First_Source Origin First Source Summary\"].value_counts()) \n",
    "\n",
    "#Similar to Academic.Interest.2, group options with a low number of cases (< 100) into \"Other Sources\".\n",
    "TUtest['First_Source Origin First Source Summary']= \\\n",
    "TUtest['First_Source Origin First Source Summary'].apply(lambda x: 'Other Sources' if x not in [\"CBINQ\",\"OAPP\",\"PSAT\",\"SRCH\",\"VST\",\"CF\",\"WEBTU\",\"CAPIQ\",\"CAP\",\"ACT\",\"HSV\",\"ATH\",\"TIF\",\"SIB\",\"SATR\",\"YUVST\"] else x) \n",
    "# Same as before but for other sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "db049471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First_Source Origin First Source Summary\n",
      "CBINQ            2406\n",
      "OAPP              507\n",
      "Other Sources     303\n",
      "SRCH              280\n",
      "PSAT              249\n",
      "VST               238\n",
      "CF                186\n",
      "WEBTU             180\n",
      "CAPIQ             156\n",
      "CAP               146\n",
      "HSV                91\n",
      "ACT                87\n",
      "ATH                70\n",
      "SATR               66\n",
      "SIB                60\n",
      "YUVST              59\n",
      "TIF                59\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtest[\"First_Source Origin First Source Summary\"].value_counts()) \n",
    "# Seeing code worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "cf8a618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1 2 0 3 4 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, '2 or more'], dtype=object)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column27 - Total Event Participation\n",
    "print(TUtest['Total Event Participation'].isna().sum())\n",
    "#No NAs.\n",
    "print(TUtest['Total Event Participation'].unique())\n",
    "\n",
    "#3, 4, 5 combined accounts for < 1% of the data set.\n",
    "#Compared to the number of cases in 0, 1, and 2, the number of cases\n",
    "#in 3, 4, and 5 won't be very useful in predicting the response.\n",
    "#So group 3, 4, and 5 into \"2 or more\".\n",
    "\n",
    "TUtest['Total Event Participation']=\\\n",
    "TUtest['Total Event Participation'].apply(lambda x: '2 or more' if x in[3,4,5] else x)\n",
    "TUtest['Total Event Participation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "b9c9461c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Count of Campus Visits\n",
      "0    3677\n",
      "1    1156\n",
      "2     216\n",
      "3      66\n",
      "4      18\n",
      "5      10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column28 - Count of Campus Visits\n",
    "TUtest[\"Count of Campus Visits\"] = TUtest[\"Count of Campus Visits\"].astype(str) \n",
    "# I turned the column into string values considering there were a low amount of groups in the column \n",
    "# and the grouping instructions in the next few lines. \n",
    "\n",
    "# print # NAs.\n",
    "print(TUtest[\"Count of Campus Visits\"].isnull().sum()) \n",
    "# No nulls\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtest[\"Count of Campus Visits\"].value_counts()) \n",
    "\n",
    "# group 5, 6, and 8 into '4 or more'.\n",
    "TUtest[\"Count of Campus Visits\"] = \\\n",
    "TUtest[\"Count of Campus Visits\"].apply(lambda x: '4 or more' if x in [\"4\",\"5\", \"6\", \"8\"] else x) \n",
    "#combined groups 4 - 8 into one group called \"4 or more\" using .apply function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "f930178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Campus Visits\n",
      "0            3677\n",
      "1            1156\n",
      "2             216\n",
      "3              66\n",
      "4 or more      28\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtest[\"Count of Campus Visits\"].value_counts()) \n",
    "# Checking code ran correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "bfccb1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "School #1 Organization Category\n",
      "High School    5122\n",
      "College           8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column29 - School #1 Organization Category\n",
    "print(TUtest['School #1 Organization Category'].isna().sum())\n",
    "#25  NAs.\n",
    "print(TUtest['School #1 Organization Category'].value_counts())\n",
    "#Only 8 cases belong to College but 9967 cases belong to High School.\n",
    "#Remove this variable.\n",
    "TUtest.drop('School #1 Organization Category', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "441ec81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4055\n",
      "[    nan 447321. 140187. 443668. 481115. 443425. 446025.  52225. 440186.\n",
      " 446785. 446365.  52347. 242277. 440294. 241635. 442958. 220595. 343880.\n",
      " 999999. 445570. 442434. 441761. 444980. 443624. 440393. 442230. 443747.\n",
      " 440914. 431615. 446203. 300180. 446220.  53197. 444632. 441758. 446782.\n",
      "  52618. 446088. 444836. 340088. 440324. 443191. 440416. 446148. 440125.\n",
      "  60414. 444599. 261590. 445052. 444368. 440310.  51106. 444596. 445056.\n",
      " 443435. 617001. 501157. 332903. 445980. 100432. 440382. 444833. 440748.\n",
      " 440010.  60275. 310904.  51267. 332360. 440730. 442602. 443541. 440331.\n",
      " 130042. 431045. 446122. 440557. 724717. 443447. 440900.  54851. 471845.\n",
      " 442572. 446207. 281315. 447586. 442047. 192601. 443644. 445499. 443361.\n",
      " 311078. 440343. 444360. 300185. 441755. 443405.  10109. 442558. 999998.\n",
      " 480145. 446784. 161215. 440326. 430001. 192045. 447481. 441471. 443291.\n",
      " 112534. 442624. 171680. 220940. 445715. 380678. 430894. 390535. 380011.\n",
      " 220950.  50485. 444865. 445412. 444209. 446515. 441750. 172777. 320037.\n",
      " 445505. 446158. 392375. 171895. 391148. 447042.  60926. 440990. 472505.\n",
      " 443374. 371109. 445030. 443534. 334985. 320003. 431435. 443420. 442625.\n",
      " 440069. 440155. 443204. 442670. 442519. 445305. 443334. 443509. 100179.\n",
      " 796730. 447138. 443665. 311320. 443209. 443923. 442143. 690140. 181430.\n",
      "  50659. 440525. 445862. 320252. 443925. 262970. 372470. 481245. 210273.\n",
      " 443485.  60118. 441174. 440077. 697050. 444595. 443727. 446277. 442626.\n",
      " 372717.  51058. 380880. 447565. 102335. 862150. 380326. 443726. 689010.\n",
      " 441408. 442730. 443736. 444095. 300400.  53004. 443381. 440561. 440081.\n",
      " 930250. 443605. 562033. 501056. 446430. 441155. 444633. 440354. 443409.\n",
      " 444132. 446144. 150695. 445581. 446273. 441485. 445053.  40175. 443617.\n",
      " 441185.  70751. 480008.  51273. 694241. 263300. 440334. 443332. 441610.\n",
      " 191782. 241865. 390371. 192103. 442627. 446120. 820190. 100577. 442322.\n",
      " 372697.  50170. 220695. 446255.  30444.  52075. 334605. 444042. 442965.\n",
      " 444744. 446314. 172776.  60867. 440915. 431130.  53680. 441825. 443402.\n",
      " 441718. 443608. 441954. 380795. 444425. 442963. 100228. 446254. 681060.\n",
      " 441805. 441144. 440906. 440562. 443395. 446286. 440344. 444374. 444342.\n",
      "  50730. 442243. 440059. 446293. 442498.  53142. 444463. 446261. 447441.\n",
      " 441811. 112862. 442194. 440375. 930150.  53410.  60249. 373590. 471067.\n",
      " 191659. 441814. 100249. 443502. 447278. 445573.  60252. 310680. 443735.\n",
      " 447468. 233472. 363300. 440367. 441525. 672090. 440295.  51514. 443383.\n",
      " 446147.  30392. 443303.  50972. 101003. 443649. 444630. 443199. 854200.\n",
      " 442770. 445414. 190179.  53522. 446204. 442549. 444286. 442215. 431417.\n",
      " 446991. 690258.  52950. 470423. 443378. 240266. 440300. 446027. 443524.\n",
      "  54683. 481085. 442633. 332575. 441946. 441894. 450400. 442560. 447395.\n",
      " 320534. 442551. 854270. 854401. 443433. 619187. 446690.  50970. 445565.\n",
      " 241592. 443312.  61055. 442611. 870480. 480545. 447364. 260948. 440731.\n",
      "  40051. 446175. 446283.  52648. 444058. 310350. 442065. 141083. 394752.\n",
      "  60148. 445046. 732965. 440007. 340645. 440116.  60082. 441740.  53466.\n",
      " 446132. 442436. 395270. 446265. 447117. 333522. 446021.  40120. 440311.\n",
      " 440338. 192041. 671634. 371185. 443385. 446235. 111110. 111152. 441739.\n",
      " 445055. 445841. 444682. 480758. 342532. 999996. 142078. 440179. 910066.\n",
      " 442635. 310100.  50600. 930020. 320105. 480920. 440315. 446084. 441690.\n",
      " 392122. 443367. 443454. 680655. 443522.  51010. 444357. 261650. 152343.\n",
      " 430300. 320008.  50466.  52395.  50666. 431118. 210610. 442610. 340420.\n",
      "  50173.  52350. 120197. 655000. 444082. 191793. 261605. 373620. 443885.\n",
      " 446093. 443597. 446238. 472125. 470500. 445860.  41148.  52282. 441850.\n",
      " 525101.  51088. 181440. 481169. 447382.  60894.  61041. 444916. 442742.\n",
      " 441803. 694240. 445840. 190244.  51895. 446701. 191917. 470103. 447282.\n",
      " 633102. 694515. 101422. 442220.  51009. 444087. 870910. 443755. 392575.\n",
      " 481112. 446783. 480114. 440363. 440303. 447116. 446105. 444628. 440048.\n",
      "  51603.  52115. 446657. 446165. 190031. 191425. 120025.  30377.  53234.\n",
      " 333500. 240256. 870087. 320032. 480750. 221190. 335540. 671209. 698101.\n",
      " 251424. 440903. 685489. 445509. 443330. 445848. 443746. 443760. 445061.\n",
      " 441835. 446200. 440313. 241625. 796612.  50035.  60057.  51510. 111730.\n",
      " 320408. 826894. 443950. 444135. 471066. 442368. 480935.  30153. 380897.\n",
      " 443305. 440281. 432315. 443535. 481117. 440336. 442634. 826019. 110177.\n",
      " 142300. 440320. 100023. 444835. 261715. 440339.  51476.  53462. 260593.\n",
      " 945260. 391366.  51213. 431690. 442597. 380205. 222415. 120028. 441785.\n",
      " 440202. 380581. 930200. 372651. 130119. 442325. 450375. 870670. 261685.\n",
      " 221198. 341046. 220667. 444831. 110216. 142301. 443639. 671630. 221475.\n",
      " 446152.  30397.  52185. 445579. 370475. 442732. 443376. 445582. 445569.\n",
      " 697111. 470020. 443742. 102381. 446788. 443394.  90226. 340735. 240635.\n",
      " 724660.  50865. 392363. 140765.  61135. 442774. 101801. 342620. 393480.\n",
      " 431710. 432035. 441836. 444671. 442594. 431510. 443815. 221555. 391250.\n",
      "  50729. 445410.  53801. 441732. 441530.  30601. 470032. 442010. 140536.\n",
      " 443363. 392100. 340687. 440732. 501370. 446989.  10355. 320040. 440907.\n",
      " 442565. 447675. 692156. 281505. 370310. 110167. 444315. 443414. 480698.\n",
      "  51958. 190965. 320038. 444600. 446130. 440201. 290097. 440431.  60268.\n",
      "  51855. 372684. 372645. 340900.  30396. 440575.  50165. 141342. 440236.\n",
      " 445185. 430893. 200875. 447335. 263055.  52130.  52117.]\n"
     ]
    }
   ],
   "source": [
    "#Column30 - School 1 Code\n",
    "print(TUtest['School 1 Code'].isna().sum())\n",
    "#7842 NAs.\n",
    "print(TUtest['School 1 Code'].unique())\n",
    "#School Code will not matter much to produce insightful information.\n",
    "#Additionally, there are 7842 missing values.\n",
    "#so remove this column in the modeling stage.\n",
    "TUtest.drop('School 1 Code', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "6e22796a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2779\n"
     ]
    }
   ],
   "source": [
    "#Column31 - School 1 Class Rank (Numeric)\n",
    "print(TU.loc[TU['train-test']=='test','School 1 Class Rank (Numeric)'].isna().sum())\n",
    "#2779 NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "f88edcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2779"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column32 - School 1 Class Size (Numeric)\n",
    "\n",
    "print(TUtest['School 1 Class Size (Numeric)'].isna().sum())\n",
    "\n",
    "#5357 NAs.\n",
    "#Percentage rank can more accurately reflect a student's academic performance than numeric rank. \n",
    "\n",
    "#Create a New Column - School 1 Top Percent in Class\n",
    "\n",
    "TUtest['School 1 Top Percent in Class'] =\\\n",
    "100 *(TUtest['School 1 Class Rank (Numeric)']/TUtest['School 1 Class Size (Numeric)'])\n",
    "\n",
    "TUtest['School 1 Top Percent in Class'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "921d447f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302\n",
      "Academic Index\n",
      "3.0    1642\n",
      "1.0    1284\n",
      "2.0    1206\n",
      "4.0     608\n",
      "5.0     101\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4., 2., 3., 1., 5.])"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Impute the 5357 NAs based on Academic.Index column. \n",
    "\n",
    "# #Since we need to handle NAs in School 1 Top Percent in Class\n",
    "# according to Academic.Index, first let's see whether Academic Index needs to be cleaned.\n",
    "print(TUtest['Academic Index'].isna().sum())\n",
    "#829 NAs.\n",
    "print(TUtest['Academic Index'].value_counts())\n",
    "#No questionable level.\n",
    "#Impute 829 NAs with the most common level.\n",
    "TUtest['Academic Index'].fillna(3,inplace=True)\n",
    "TUtest['Academic Index'].unique()\n",
    "#No missing values in Academic Index now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "5e43fb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Academic Index\n",
       "1.0     4.451811\n",
       "2.0     8.451642\n",
       "3.0    16.449033\n",
       "4.0    29.870245\n",
       "5.0    39.644202\n",
       "Name: School 1 Top Percent in Class, dtype: float64"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate school 1 top percent in class for each academic index group\n",
    "grouped=TUtest.groupby('Academic Index')\n",
    "grouped\n",
    "average=grouped.mean('School 1 Top Percent in Class')\n",
    "average['School 1 Top Percent in Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "b13c651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Impute missing values in 'School 1 Top Percent in Class' based on Academic Index group average\n",
    "for i,row in TUtest.iterrows():\n",
    "\n",
    "    if (row['Academic Index']== 1.0) & (pd.isna(row['School 1 Top Percent in Class'])):\n",
    "        TUtest.loc[i,'School 1 Top Percent in Class']= average['School 1 Top Percent in Class'][1.0]\n",
    "    elif (row['Academic Index']== 2.0) & (pd.isna(row['School 1 Top Percent in Class'])):\n",
    "            TUtest.loc[i,'School 1 Top Percent in Class']= average['School 1 Top Percent in Class'][2.0]\n",
    "    elif (row['Academic Index']== 3.0) & (pd.isna(row['School 1 Top Percent in Class'])):\n",
    "            TUtest.loc[i,'School 1 Top Percent in Class']= average['School 1 Top Percent in Class'][3.0]\n",
    "    elif (row['Academic Index']== 4.0) & (pd.isna(row['School 1 Top Percent in Class'])):\n",
    "            TUtest.loc[i,'School 1 Top Percent in Class']= average['School 1 Top Percent in Class'][4.0]\n",
    "    elif (row['Academic Index']== 5.0) & (pd.isna(row['School 1 Top Percent in Class'])):\n",
    "            TUtest.loc[i,'School 1 Top Percent in Class']= average['School 1 Top Percent in Class'][5.0]\n",
    "print(TUtest['Academic Index'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "7a14532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column33 - School 1 GPA\n",
    "\n",
    "#Remove this variable in the modeling stage\n",
    "#because School.1.GPA.Recalculated is more accurate.\n",
    "\n",
    "TUtest.drop('School 1 GPA', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "2e4cb558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column34 - School 1 GPA Scale\n",
    "#Remove this variable in the modeling stage as it is irrelevant.\n",
    "\n",
    "TUtest.drop('School 1 GPA Scale', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "cd01551f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.9345840107494408"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column35 - School 1 GPA Recalculated\n",
    "\n",
    "#Check NAs\n",
    "\n",
    "print(TUtest['School 1 GPA Recalculated'].isna().sum())\n",
    "#0 NAs.\n",
    "\n",
    "TUtest['School 1 GPA Recalculated'].skew()\n",
    "#Check skewness\n",
    "\n",
    "# if the skewness score is below -1 or above 1, the variable is high skewed\n",
    "#if the skewness score is positive, it means it is right tail skew\n",
    "# if the skewness score is negative, it means it is left tail skew\n",
    "#Since it is moderately skewed, and it is understandable for the left skewness as \n",
    "#a lot of students got into Trinity with a high GPA (almost 4.0), it is unnecessary to do transformation.\n",
    "# Some modeling methods requires variables following a normal distribution, therefore you need to transform the skewed data\n",
    "# before inputting it into the model, such as liner regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "09eed342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n"
     ]
    }
   ],
   "source": [
    "#Column36 - School 2 Class Rank (Numeric)\n",
    "#Check NAs\n",
    "print(TUtest['School 2 Class Rank (Numeric)'].isna().sum()) # 10000 null values \n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtest.drop('School 2 Class Rank (Numeric)', axis='columns', inplace=True) \n",
    "#Dropping column as all cases are blank so we do not need the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "3e8109eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n"
     ]
    }
   ],
   "source": [
    "#Column37 - School 2 Class Size (Numeric)\n",
    "\n",
    "#Check NAs\n",
    "print(TUtest['School 2 Class Size (Numeric)'].isna().sum())# 10000 null values \n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtest.drop('School 2 Class Size (Numeric)', axis='columns', inplace=True)\n",
    "# Same as the last one, all cases are blank. We do not need this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "5ef2076d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n"
     ]
    }
   ],
   "source": [
    "#Column38 - School 2 GPA\n",
    "\n",
    "#Check NAs\n",
    "print(TUtest['School 2 GPA'].isna().sum())# 10000 null values \n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtest.drop('School 2 GPA', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "a137c564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n"
     ]
    }
   ],
   "source": [
    "#Column39 - School 2 GPA Scale\n",
    "#Check NAs\n",
    "print(TUtest['School 2 GPA Scale'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtest.drop('School 2 GPA Scale', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "7f9c4d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n"
     ]
    }
   ],
   "source": [
    "#Column40 - School 2 GPA Recalculated\n",
    "#Check NAs\n",
    "print(TUtest['School 2 GPA Recalculated'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtest.drop('School 2 GPA Recalculated', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "bdcf139a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n"
     ]
    }
   ],
   "source": [
    "#Column41 - School 3 Class Rank (Numeric)\n",
    "#Check NAs\n",
    "print(TUtest['School 3 Class Rank (Numeric)'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtest.drop('School 3 Class Rank (Numeric)', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "3a0a8b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n"
     ]
    }
   ],
   "source": [
    "#Column42 - School 3 Class Size (Numeric)\n",
    "#Check NAs\n",
    "print(TUtest['School 3 Class Size (Numeric)'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtest.drop('School 3 Class Size (Numeric)', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "770238e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n"
     ]
    }
   ],
   "source": [
    "#Column43 - School 3 GPA\n",
    "#Check NAs\n",
    "print(TUtest['School 3 GPA'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtest.drop('School 3 GPA', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "02ea2d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n"
     ]
    }
   ],
   "source": [
    "#Column44 - School 3 GPA Scale\n",
    "#Check NAs\n",
    "print(TUtest['School 3 GPA Scale'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtest.drop('School 3 GPA Scale', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "db9d99cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n"
     ]
    }
   ],
   "source": [
    "#Column45 - School 3 GPA Recalculated\n",
    "#Check NAs\n",
    "print(TUtest['School 3 GPA Recalculated'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtest.drop('School 3 GPA Recalculated', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "19cf864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2557\n",
      "ACT Composite\n",
      "32.0    316\n",
      "31.0    312\n",
      "30.0    304\n",
      "33.0    298\n",
      "34.0    281\n",
      "29.0    218\n",
      "28.0    212\n",
      "35.0    180\n",
      "27.0    170\n",
      "26.0    119\n",
      "25.0     77\n",
      "24.0     34\n",
      "36.0     30\n",
      "23.0     20\n",
      "22.0     11\n",
      "21.0      3\n",
      "20.0      1\n",
      "Name: count, dtype: int64\n",
      "555\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Column46 ACT Composite\n",
    "\n",
    "# print # NAs.\n",
    "print(TUtest[\"ACT Composite\"].isna().sum())  # 4945 null values \n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtest[\"ACT Composite\"].value_counts()) \n",
    "\n",
    "# Replace missing ACT scores with SAT Concordance scores. \n",
    "# Convert 'SAT R Evidence-Based Reading and Writing Section + Math Section scores' into ACT based on the ACT-SAT concordance table pdf;\n",
    "\n",
    "sat_to_act = {\n",
    "    range(1570, 1601): 36,  # dictionary which corresponds to ACT concordance table\n",
    "    range(1530, 1561): 35,\n",
    "    range(1490, 1521): 34,\n",
    "    range(1450, 1481): 33,\n",
    "    range(1420, 1441): 32,\n",
    "    range(1390, 1411): 31,\n",
    "    range(1360, 1381): 30,\n",
    "    range(1330, 1351): 29,\n",
    "    range(1300, 1321): 28,\n",
    "    range(1260, 1291): 27, \n",
    "    range(1230, 1251): 26,\n",
    "    range(1200, 1221): 25,\n",
    "    range(1160, 1191): 24,\n",
    "    range(1130, 1151): 23,\n",
    "    range(1100, 1121): 22,\n",
    "    range(1060, 1091): 21,\n",
    "    range(1030, 1051): 20,\n",
    "    range(990, 1021): 19,\n",
    "    range(960, 981): 18,\n",
    "    range(920, 951): 17,\n",
    "    range(880, 911): 16,\n",
    "    range(830, 871): 15,\n",
    "    range(780, 821): 14,\n",
    "    range(730, 771): 13,\n",
    "    range(690, 721): 12,\n",
    "    range(650, 681): 11,\n",
    "    range(620, 641): 10,\n",
    "    range(590, 611): 9\n",
    "}\n",
    "\n",
    "def calcACT(sat): \n",
    "    if pd.isna(sat):  # Ensure no error for missing SAT values\n",
    "        return None\n",
    "    for score_range in sat_to_act.keys(): #Loops over SAT ranges dictionary, checks if score is in range. \n",
    "        if sat in score_range: # If score in range, \n",
    "            return sat_to_act[score_range] #return corresponding ACT score.\n",
    "    return None  # If SAT score doesn't fit in any range, return None\n",
    "\n",
    "# Apply the function to fill missing ACT scores using SAT values\n",
    "TUtest[\"ACT Composite\"] = TUtest.apply(\n",
    "    lambda row: calcACT(row['SAT R Evidence-Based Reading and Writing Section + Math Section']) \n",
    "    if pd.isnull(row['ACT Composite']) else row['ACT Composite'], axis=1\n",
    ")\n",
    "\n",
    "# Check again for any missing ACT scores\n",
    "print(TUtest[\"ACT Composite\"].isna().sum())  # Check how many NAs are left\n",
    "\n",
    "# Replace any remaining missing ACT scores with the mean of the ACT Composite\n",
    "TUtest[\"ACT Composite\"] = TUtest[\"ACT Composite\"].apply(\n",
    "    lambda x: TUtest[\"ACT Composite\"].mean() if pd.isnull(x) else x\n",
    ").round()\n",
    "\n",
    "# Final check\n",
    "print(TUtest[\"ACT Composite\"].isna().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "dbb66ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT Composite Grouped\n",
      "30.0          1055\n",
      "31.0           528\n",
      "33.0           510\n",
      "34.0           485\n",
      "32.0           482\n",
      "29.0           432\n",
      "28.0           428\n",
      "27.0           350\n",
      "35.0           293\n",
      "26.0           216\n",
      "25.0           158\n",
      "24.0            86\n",
      "36.0            63\n",
      "23.0            33\n",
      "22.0            17\n",
      "ACTBelow21       7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group ACT scores with fewer than 10 occurrences into one category, \n",
    "# I can see that all the values below 21 ACT score have less than 10 observations so that is what I will\n",
    "# call the category\n",
    "\n",
    "# Check the current value counts for ACT Composite\n",
    "act_counts = TUtest[\"ACT Composite\"].value_counts()\n",
    "\n",
    "# Create a new column to categorize ACT scores\n",
    "def group_rare_scores(act_score):\n",
    "    if act_counts.get(act_score, 0) < 10:  # If the score appears fewer than 10 times\n",
    "        return 'ACTBelow21'  # Group them into Below 21\n",
    "    else:\n",
    "        return act_score  # Otherwise, keep the original score\n",
    "\n",
    "# Apply the function to create the new grouped categories\n",
    "TUtest[\"ACT Composite Grouped\"] = TUtest[\"ACT Composite\"].apply(group_rare_scores)\n",
    "\n",
    "# Check the distribution of the new categories\n",
    "print(TUtest[\"ACT Composite Grouped\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "86e05385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(TUtest[\"ACT Composite\"].isna().sum()) #Nulls are gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "fed72350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2678\n"
     ]
    }
   ],
   "source": [
    "#Column47 ACT English\n",
    "\n",
    "#Check NAs \n",
    "print(TUtest[\"ACT English\"].isna().sum())\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtest.drop(\"ACT English\", axis = 'columns', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "5310257a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2678\n"
     ]
    }
   ],
   "source": [
    "#Column48 ACT Reading\n",
    "print(TUtest[\"ACT Reading\"].isna().sum()) # returned 5205 null values with .isna().sum()\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtest.drop(\"ACT Reading\", axis = 'columns', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "87871d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2678\n"
     ]
    }
   ],
   "source": [
    "#Column50 ACT Math\n",
    "print(TUtest[\"ACT Math\"].isna().sum()) #returned 5205 null values with .isna().sum()\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtest.drop(\"ACT Math\", axis = 'columns', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "96383d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2678\n"
     ]
    }
   ],
   "source": [
    "#Column51 ACT Science Reasoning\n",
    "print(TUtest[\"ACT Science Reasoning\"].isna().sum()) #returned 5205 null values with .isna().sum()\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtest.drop(\"ACT Science Reasoning\", axis = 'columns', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "8983501b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5056\n"
     ]
    }
   ],
   "source": [
    "#Column52 ACT Writing\n",
    "print(TUtest[\"ACT Writing\"].isna().sum()) #returned 9830 null values with .isna().sum()\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtest.drop(\"ACT Writing\", axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "906c60c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4959\n"
     ]
    }
   ],
   "source": [
    "#Column53 ACT SAT I CR + M\n",
    "print(TUtest[\"SAT I CR + M\"].isna().sum()) #returned 9610 null values with .isna().sum()\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtest.drop(\"SAT I CR + M\", axis = 'columns', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "acd6ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column54 SAT R Evidence-Based Reading and Writing Section + Math Section\n",
    "# This column is used to generate ATC concordance scores.\n",
    "# No further processing needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "3bef7690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permanent Geomarket\n",
      "TX-06     645\n",
      "TX-16     608\n",
      "TX-13     282\n",
      "TX-15     282\n",
      "TX-14     188\n",
      "         ... \n",
      "NY-04       1\n",
      "INT-BE      1\n",
      "INT-UP      1\n",
      "PA-09       1\n",
      "OH-10       1\n",
      "Name: count, Length: 307, dtype: int64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(TUtest[\"Permanent Geomarket\"].value_counts()) # shows the most frequent geomarket area is TX \n",
    "print(TUtest[\"Permanent Geomarket\"].isna().sum()) # No nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "d113977e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permanent Geomarket\n",
      "TX-06     645\n",
      "TX-16     608\n",
      "TX-13     282\n",
      "TX-15     282\n",
      "TX-14     188\n",
      "         ... \n",
      "NY-04       1\n",
      "INT-BE      1\n",
      "INT-UP      1\n",
      "PA-09       1\n",
      "OH-10       1\n",
      "Name: count, Length: 307, dtype: int64\n",
      "1\n",
      "['TX-18' 'TX-06' 'TX-07' 'TX-11' 'TX-10' 'CA-23' 'TX-13' 'TX-19' 'TX-23'\n",
      " 'TX-20' 'INT-CH' 'TX-14' 'NM-01' 'MD-06' 'CA-11' 'TX-16' 'IL-12' 'TX-17'\n",
      " 'TX-15' 'GA-02' 'TX-24' 'AZ-01' 'TX-12' 'WA-01' 'OR-01' 'CA-07' 'OK-02'\n",
      " 'INT-VM' 'CO-02' 'NC-06' 'CA-20' 'TX-21' 'CA-16' 'MN-01' 'AR-01' 'MA-10'\n",
      " 'TX-22' 'INT-IN' 'NC-07' 'INT-IC' 'VA-02' 'AZ-02' 'FL-02' 'LA-03' 'TX-05'\n",
      " 'NJ-10' 'TX-08' 'CA-13' 'TX-02' 'GA-05' 'TN-03' 'INT-NU' 'NH-01' 'CA-28'\n",
      " 'CA-15' 'CA-03' 'INT-MX' 'NY-28' 'CO-03' 'NC-03' 'TX-01' 'MO-03' 'KS-01'\n",
      " 'INT-HO' 'LA-02' 'TX-04' 'INT-ES' 'FL-01' 'CA-26' 'MD-07' 'CT-02' 'CA-06'\n",
      " 'ID-01' 'PR-01' 'WI-01' 'CA-29' 'TN-04' 'INT-TW' 'VA-05' 'FL-04' 'AL-01'\n",
      " 'US-AE' 'TX-09' 'WI-03' 'NJ-05' 'ID-02' 'KS-02' 'MA-06' 'NY-16' 'WA-02'\n",
      " 'MO-02' 'NJ-08' 'MS-01' 'OK-01' 'IL-11' 'SD-02' 'PA-04' 'INT-PE' 'TX-03'\n",
      " 'CO-01' 'TN-02' 'CT-03' 'INT-JA' 'INT-UK' 'AR-02' 'NV-01' 'VA-06' 'HI-01'\n",
      " 'INT-NO' 'CT-01' 'MD-02' 'IL-08' 'INT-NL' 'LA-01' 'NY-29' 'NJ-11' 'CA-17'\n",
      " 'CA-14' 'IA-02' 'INT-CO' 'CA-09' 'GA-04' 'CA-27' 'NY-18' 'OR-02' 'CA-02'\n",
      " 'PA-13' 'CA-05' 'MA-07' 'KY-02' 'INT-EC' 'INT-AE' 'INT-JO' 'NY-01'\n",
      " 'INT-GH' 'INT-SF' 'PA-02' 'OR-04' 'PA-06' 'VA-08' 'CA-31' 'NY-19' 'CA-18'\n",
      " 'INT-SP' 'NY-21' 'MA-08' 'NY-27' 'NM-02' 'CA-08' 'FL-03' 'INT-KS' 'WA-05'\n",
      " 'INT-HK' 'GA-08' 'INT-GT' 'KY-01' 'INT-EG' 'VT-01' 'MD-05' 'WA-03'\n",
      " 'MS-02' 'RI-02' 'PA-05' 'INT-PK' 'AL-03' 'US-MP' 'FL-06' 'INT-AS'\n",
      " 'INT-NP' 'INT-KZ' 'AL-02' 'CA-10' 'MI-05' 'US-AP' 'IL-07' nan 'GA-03'\n",
      " 'IL-10' 'VA-01' 'IL-09' 'MD-03' 'INT-CS' 'INT-SA' 'INT-JM' 'UT-01'\n",
      " 'CA-12' 'FL-05' 'PA-08' 'INT-TH' 'INT-UY' 'INT-CA' 'PA-09' 'MO-01'\n",
      " 'INT-SN' 'INT-BR' 'WA-06' 'NY-17' 'INT-UP' 'VA-03' 'RI-01' 'WA-04'\n",
      " 'INT-BE' 'NY-23' 'IL-03' 'NY-04' 'INT-NI' 'MA-04' 'INT-PM' 'CT-05'\n",
      " 'NE-02' 'CA-30' 'NC-01' 'GA-01' 'DE-01' 'INT-GR' 'MI-02' 'OH-01' 'CA-04'\n",
      " 'IN-07' 'IA-01' 'MA-09' 'INT-ET' 'INT-RO' 'US-VI' 'IL-01' 'INT-UG'\n",
      " 'TN-01' 'PA-10' 'NH-02' 'INT-TZ' 'OH-09' 'CA-25' 'INT-BL' 'CA-32' 'PA-07'\n",
      " 'DC-01' 'OR-03' 'NV-02' 'NJ-12' 'NC-04' 'SC-03' 'NY-26' 'OR-05' 'NY-24'\n",
      " 'OH-06' 'IN-12' 'CA-19' 'AK-02' 'WI-02' 'SC-04' 'IL-06' 'INT-KU' 'INT-FR'\n",
      " 'CA-24' 'AL-04' 'OH-08' 'IN-03' 'WV-02' 'MN-02' 'CA-33' 'INT-CB' 'PA-12'\n",
      " 'HI-02' 'INT-BH' 'INT-TU' 'MD-01' 'US-GU' 'OH-04' 'IN-01' 'IN-09'\n",
      " 'INT-PO' 'INT-ZI' 'NJ-07' 'INT-GM' 'AK-01' 'INT-MU' 'NY-02' 'NH-03'\n",
      " 'NY-15' 'INT-LE' 'CA-21' 'NJ-06' 'INT-SZ' 'INT-RP' 'MI-06' 'CA-22'\n",
      " 'NY-10' 'INT-ID' 'MA-01' 'CA-01' 'OH-07' 'NC-05' 'INT-MG' 'INT-RS'\n",
      " 'IL-05' 'MA-02' 'MT-02' 'PA-03' 'INT-MO' 'NY-25' 'INT-CI' 'INT-CY'\n",
      " 'ME-03' 'INT-AL' 'INT-DR' 'NJ-03' 'ME-01' 'OH-10']\n"
     ]
    }
   ],
   "source": [
    "# Column55 Permanent Geomarket\n",
    "# First, replace the missing values with the most frequent geo market value.\n",
    "print(TUtest[\"Permanent Geomarket\"].value_counts()) # shows the most frequent geomarket area is TX \n",
    "print(TUtest[\"Permanent Geomarket\"].isna().sum()) # No nulls\n",
    "\n",
    "# Second, group geomarket values into different regions. Refer to the region .csv for grouping.\n",
    "unique_values = TUtest[\"Permanent Geomarket\"].unique()\n",
    "print(unique_values)\n",
    "\n",
    "# Define a single regions dictionary\n",
    "dictRegions = {\n",
    "    'West': ['AK', 'HI', 'WA', 'OR', 'CA', 'ID', 'NV', 'MT', 'WY', 'UT', 'CO', 'AZ', 'NM'],\n",
    "    'Midwest': ['ND', 'SD', 'NE', 'KS', 'MN', 'IA', 'MO', 'WI', 'IL', 'MI', 'IN', 'OH'],\n",
    "    'South': ['TX', 'OK', 'AR', 'LA', 'KY', 'TN', 'MS', 'AL', 'WV', 'MD', 'DE', 'DC', 'VA', 'NC', 'SC', 'GA', 'FL', 'US'],\n",
    "    'Northeast': ['PA', 'NY', 'NJ', 'ME', 'VT', 'NH', 'MA', 'CT', 'RI'],\n",
    "    'International': ['INT', 'PR']\n",
    "}\n",
    "\n",
    "# Function to categorize regions\n",
    "def categorize_region(geomarket):\n",
    "    # Clean the geomarket value (e.g., remove any suffix after '-')\n",
    "    clean_geomarket = geomarket.split('-')[0]\n",
    "    \n",
    "    # Check in the regions dictionary\n",
    "    for region, states in dictRegions.items():\n",
    "        if clean_geomarket in states:\n",
    "            return region\n",
    "            \n",
    "    return \"Unknown\"  # Default value if not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "cf8f9c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permanent Geomarket\n",
      "TX-06     645\n",
      "TX-16     608\n",
      "TX-13     282\n",
      "TX-15     282\n",
      "TX-14     188\n",
      "         ... \n",
      "NY-04       1\n",
      "INT-BE      1\n",
      "INT-UP      1\n",
      "PA-09       1\n",
      "OH-10       1\n",
      "Name: count, Length: 307, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtest[\"Permanent Geomarket\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "98666b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID train-test Entry Term (Application) Permanent Country Sex  \\\n",
      "10000  10001       test                Fall 2019     United States   M   \n",
      "10001  10002       test                Fall 2020     United States   F   \n",
      "10002  10003       test                Fall 2021     United States   F   \n",
      "10003  10004       test                Fall 2017     United States   M   \n",
      "10004  10005       test                Fall 2019     United States   M   \n",
      "...      ...        ...                      ...               ...  ..   \n",
      "15138  15139       test                Fall 2020     United States   F   \n",
      "15139  15140       test                Fall 2019     United States   F   \n",
      "15140  15141       test                Fall 2020     United States   M   \n",
      "15141  15142       test                Fall 2018     United States   F   \n",
      "15142  15143       test                Fall 2019     United States   F   \n",
      "\n",
      "                 Ethnicity                       Race  \\\n",
      "10000      Hispanic/Latino                      White   \n",
      "10001  Non Hispanic/Latino                      White   \n",
      "10002  Non Hispanic/Latino                      White   \n",
      "10003      Hispanic/Latino              Not specified   \n",
      "10004  Non Hispanic/Latino                      White   \n",
      "...                    ...                        ...   \n",
      "15138  Non Hispanic/Latino                      Asian   \n",
      "15139  Non Hispanic/Latino                      Asian   \n",
      "15140  Non Hispanic/Latino  Black or African American   \n",
      "15141  Non Hispanic/Latino                      White   \n",
      "15142  Non Hispanic/Latino                      White   \n",
      "\n",
      "                       Religion Application Source     Decision Plan  ...  \\\n",
      "10000                 Christian         ApplyTexas    Early Action I  ...   \n",
      "10001                 Methodist          CommonApp      Early Action  ...   \n",
      "10002  OtherRelgiousAffiliation          CommonApp      Early Action  ...   \n",
      "10003             Not specified          CommonApp  Regular Decision  ...   \n",
      "10004             Not specified          CommonApp   Early Action II  ...   \n",
      "...                         ...                ...               ...  ...   \n",
      "15138             Not specified          CommonApp  Regular Decision  ...   \n",
      "15139                     Hindu          CommonApp    Early Action I  ...   \n",
      "15140             Not specified          CommonApp      Early Action  ...   \n",
      "15141             Not specified          CommonApp    Early Action I  ...   \n",
      "15142            Roman Catholic          CommonApp    Early Action I  ...   \n",
      "\n",
      "      SAT I Critical Reading SAT I Math SAT I Writing  \\\n",
      "10000                    NaN        NaN           NaN   \n",
      "10001                    NaN        NaN           NaN   \n",
      "10002                    NaN        NaN           NaN   \n",
      "10003                    NaN        NaN           NaN   \n",
      "10004                    NaN        NaN           NaN   \n",
      "...                      ...        ...           ...   \n",
      "15138                    NaN        NaN           NaN   \n",
      "15139                    NaN        NaN           NaN   \n",
      "15140                    NaN        NaN           NaN   \n",
      "15141                    NaN        NaN           NaN   \n",
      "15142                    NaN        NaN           NaN   \n",
      "\n",
      "      SAT R Evidence-Based Reading and Writing Section SAT R Math Section  \\\n",
      "10000                                              NaN                NaN   \n",
      "10001                                              NaN                NaN   \n",
      "10002                                              NaN                NaN   \n",
      "10003                                              NaN                NaN   \n",
      "10004                                            760.0              740.0   \n",
      "...                                                ...                ...   \n",
      "15138                                              NaN                NaN   \n",
      "15139                                              NaN                NaN   \n",
      "15140                                              NaN                NaN   \n",
      "15141                                            770.0              740.0   \n",
      "15142                                            650.0              640.0   \n",
      "\n",
      "      Decision Submit_FirstSource Submit_Inquiry  \\\n",
      "10000        0               33.0            3.0   \n",
      "10001        0               88.0           79.0   \n",
      "10002        0               55.0           55.0   \n",
      "10003        0               -0.0         6096.0   \n",
      "10004        0                6.0            6.0   \n",
      "...        ...                ...            ...   \n",
      "15138        0               97.0         6261.0   \n",
      "15139        0               36.0            9.0   \n",
      "15140        0               18.0         6253.0   \n",
      "15141        0             6145.0            4.0   \n",
      "15142        1               89.0           34.0   \n",
      "\n",
      "      School 1 Top Percent in Class ACT Composite Grouped  \n",
      "10000                     29.870245                  28.0  \n",
      "10001                      8.451642                  32.0  \n",
      "10002                     16.449033                  29.0  \n",
      "10003                      2.247191                  27.0  \n",
      "10004                     11.320755                  34.0  \n",
      "...                             ...                   ...  \n",
      "15138                     16.449033                  29.0  \n",
      "15139                      9.422111                  33.0  \n",
      "15140                     29.870245                  26.0  \n",
      "15141                      1.785714                  34.0  \n",
      "15142                      2.222222                  31.0  \n",
      "\n",
      "[5143 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to create a new column for region categorization\n",
    "TUtest['Permanent Geomarket'] = TUtest['Permanent Geomarket'].astype(str)\n",
    "\n",
    "TUtest['Permanent Geomarket'] = TUtest['Permanent Geomarket'].apply(categorize_region)\n",
    "\n",
    "print(TUtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "950daeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column56 Citizenship Status\n",
    "\n",
    "# This column is used for inter-field checking so keep it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "d397a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column57 Academic Index\n",
    "\n",
    "# This column is used for inter-field checking so keep it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "fcd4192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Intend to Apply for Financial Aid?\n",
      "1.0    3478\n",
      "0.0    1662\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column58 Intend to Apply for Financial Aid?\n",
    "print(TUtest[\"Intend to Apply for Financial Aid?\"].isna().sum()) #return 18 null values\n",
    "print(TUtest[\"Intend to Apply for Financial Aid?\"].value_counts()) # value counts shows two unique values\n",
    "\n",
    "#Handling missing values. Justify your choice.\n",
    "TUtest[\"Intend to Apply for Financial Aid?\"] = \\\n",
    "TUtest[\"Intend to Apply for Financial Aid?\"].apply(lambda x: 1 if pd.isna(x) else x )\n",
    "# I decided to add all missing values to the 1 group (meaning receiving financial aid) because it is by far \n",
    "# the most frequent observation doubling the 0 group (not receiving any financial aid).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "be3b80f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Merit Award\n",
      "P23      557\n",
      "T22      518\n",
      "T23      496\n",
      "P17      461\n",
      "T21      430\n",
      "T25      390\n",
      "M30      306\n",
      "M27      300\n",
      "M26      264\n",
      "M25      206\n",
      "D18      195\n",
      "D20      189\n",
      "M24      156\n",
      "P18       97\n",
      "D12.5     64\n",
      "TTS       42\n",
      "I25       41\n",
      "TT10      40\n",
      "Z0        35\n",
      "I23       34\n",
      "I30       34\n",
      "I22       29\n",
      "TT12      27\n",
      "TT9       25\n",
      "TT125     25\n",
      "I17       21\n",
      "I18       19\n",
      "I21       17\n",
      "I35       15\n",
      "I26       13\n",
      "I27       12\n",
      "I10       12\n",
      "SEM       11\n",
      "I24       10\n",
      "I19        9\n",
      "I20        9\n",
      "X0         7\n",
      "I28        6\n",
      "I12.5      5\n",
      "I40        5\n",
      "I15        4\n",
      "I38        2\n",
      "I33        1\n",
      "I45        1\n",
      "I32        1\n",
      "I9         1\n",
      "I0         1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Merit Award\n",
       "P23                                  557\n",
       "T22                                  518\n",
       "T23                                  496\n",
       "P17                                  461\n",
       "T21                                  430\n",
       "T25                                  390\n",
       "M30                                  306\n",
       "International Student Scholarship    301\n",
       "M27                                  300\n",
       "M26                                  264\n",
       "M25                                  206\n",
       "D18                                  195\n",
       "D20                                  189\n",
       "M24                                  156\n",
       "P18                                   97\n",
       "D12.5                                 64\n",
       "TTS                                   42\n",
       "TT10                                  40\n",
       "Z0                                    35\n",
       "TT12                                  27\n",
       "TT9                                   25\n",
       "TT125                                 25\n",
       "SEM                                   11\n",
       "X0                                     7\n",
       "I0                                     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column59 Merit Award\n",
    "print(TUtest[\"Merit Award\"].isna().sum()) # No null values\n",
    "print(TUtest[\"Merit Award\"].value_counts()) \n",
    "#Refer to the Merit Award Code.csv for grouping. \n",
    "#Recategorize all the levels into fewer levels, Justify your grouping policy in comments\n",
    "\n",
    "International = [\n",
    "    'I10', 'I12','I12.5','I15','I17',\n",
    "    'I18','I19','I20','I21','I24','I25',\n",
    "    'I26','I27','I28','I30','I32','I33',\n",
    "    'I35','I38','I5','I9','I40','I50',\n",
    "    'I22', 'I52', 'I7.5', 'I43', 'I23','I45'\n",
    "]\n",
    "\n",
    "TUtest['Merit Award'] = \\\n",
    "TUtest['Merit Award'].apply(lambda x: 'International Student Scholarship' if x in International else x)\n",
    "TUtest['Merit Award'].value_counts()\n",
    "# Grouped all international financial awards together as there are too many levels of scholarship. \n",
    "# These categories will be much easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "3af8a6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merit Award\n",
       "Domestic Merit-Based Scholarship     4746\n",
       "International Student Scholarship     301\n",
       "TTS                                    42\n",
       "Z0                                     35\n",
       "SEM                                    11\n",
       "X0                                      7\n",
       "I0                                      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DomesticMeritBased = [\n",
    "    'D12.5','D18', 'D20','M24','M30', 'M27','M26',\n",
    "    'M25', 'P17','P23','P18','TT9','T21',\n",
    "    'T23','T22','T25', 'TT10','TT12','TT125'\n",
    "]\n",
    "\n",
    "TUtest['Merit Award'] = \\\n",
    "TUtest['Merit Award'].apply(lambda x: 'Domestic Merit-Based Scholarship' if x in DomesticMeritBased else x)\n",
    "TUtest['Merit Award'].value_counts()\n",
    "# Grouped these into the Domestic Meritbased Scholarships as they are all domestic scholarships that have\n",
    "# different kinds of standards and requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "3a4c9568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merit Award\n",
       "Domestic Merit-Based Scholarship     4746\n",
       "International Student Scholarship     301\n",
       "Full Ride                              60\n",
       "Z0                                     35\n",
       "I0                                      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FullRide = [\n",
    "    'SEM', 'TTS','X0', 'Y0'\n",
    "]\n",
    "\n",
    "TUtest['Merit Award'] = \\\n",
    "TUtest['Merit Award'].apply(lambda x: 'Full Ride' if x in FullRide else x)\n",
    "TUtest['Merit Award'].value_counts()\n",
    "# Tuition exchange is basically a full scholarship so I grouped all of these into a full ride\n",
    "# to show all students who have a full scholarship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "afc66f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merit Award\n",
       "Domestic Merit-Based Scholarship     4746\n",
       "International Student Scholarship     301\n",
       "Full Ride                              60\n",
       "No Merit Scholarship                   36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NoMeritList = [\n",
    "    'Z0', 'I0'\n",
    "]\n",
    "\n",
    "TUtest['Merit Award'] = \\\n",
    "TUtest['Merit Award'].apply(lambda x: 'No Merit Scholarship' if x in NoMeritList else x)\n",
    "TUtest['Merit Award'].value_counts()\n",
    "\n",
    "# Because it is international no merit it makes more sense to say no merit than put them with international.\n",
    "# Both these do not get any merit scholarship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "8579f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column60 SAT Concordance Score (of SAT R)\n",
    "\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtest.drop(\"SAT Concordance Score (of SAT R)\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "8974d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column61 ACT Concordance Score (of SAT R)\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtest.drop(\"ACT Concordance Score (of SAT R)\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "b5bc64d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Column62 ACT Concordance Score (of SAT)\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtest.drop(\"ACT Concordance Score (of SAT)\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "e64b1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column63 Test Optional\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtest.drop(\"Test Optional\", axis = 'columns', inplace = True)\n",
    "# Nulls are now the mean for act and sat so it is not necessary to show test optional anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "5d75eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column64 SAT I Critical Reading\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtest.drop(\"SAT I Critical Reading\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "c0e9237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column65 SAT I Math\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtest.drop(\"SAT I Math\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "a7d1832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column66 SAT I Writing\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtest.drop(\"SAT I Writing\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "805a85d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column67 SAT R Evidence-Based Reading and Writing Section\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtest.drop(\"SAT R Evidence-Based Reading and Writing Section\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "7f84e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column68 SAT R Math Section\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtest.drop(\"SAT R Math Section\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "81dbb0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column69 Decision\n",
    "\n",
    "# This would be your dependent variable in the classification model so keep it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "9b16dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you clean all variables, output the cleaned dataframe to a csv file\n",
    "# the csv file can be found in your current working directory\n",
    "\n",
    "\n",
    "TUtest.to_csv('cleaneddftest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "2cf784a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5143 entries, 10000 to 15142\n",
      "Data columns (total 36 columns):\n",
      " #   Column                                                           Non-Null Count  Dtype  \n",
      "---  ------                                                           --------------  -----  \n",
      " 0   ID                                                               5143 non-null   int64  \n",
      " 1   train-test                                                       5143 non-null   object \n",
      " 2   Entry Term (Application)                                         5143 non-null   object \n",
      " 3   Permanent Country                                                5142 non-null   object \n",
      " 4   Sex                                                              5143 non-null   object \n",
      " 5   Ethnicity                                                        5143 non-null   object \n",
      " 6   Race                                                             5143 non-null   object \n",
      " 7   Religion                                                         5143 non-null   object \n",
      " 8   Application Source                                               5143 non-null   object \n",
      " 9   Decision Plan                                                    5143 non-null   object \n",
      " 10  Legacy                                                           5143 non-null   object \n",
      " 11  Athlete                                                          5143 non-null   object \n",
      " 12  Sport 1 Sport                                                    5143 non-null   object \n",
      " 13  Sport 1 Rating                                                   5143 non-null   object \n",
      " 14  Sport 2 Sport                                                    5143 non-null   object \n",
      " 15  Sport 3 Sport                                                    5143 non-null   object \n",
      " 16  Academic Interest 1                                              5143 non-null   object \n",
      " 17  Academic Interest 2                                              5143 non-null   object \n",
      " 18  First_Source Origin First Source Summary                         5143 non-null   object \n",
      " 19  Total Event Participation                                        5143 non-null   object \n",
      " 20  Count of Campus Visits                                           5143 non-null   object \n",
      " 21  School 1 Class Rank (Numeric)                                    2364 non-null   float64\n",
      " 22  School 1 Class Size (Numeric)                                    2364 non-null   float64\n",
      " 23  School 1 GPA Recalculated                                        5143 non-null   float64\n",
      " 24  ACT Composite                                                    5143 non-null   float64\n",
      " 25  SAT R Evidence-Based Reading and Writing Section + Math Section  2922 non-null   float64\n",
      " 26  Permanent Geomarket                                              5143 non-null   object \n",
      " 27  Citizenship Status                                               5143 non-null   object \n",
      " 28  Academic Index                                                   5143 non-null   float64\n",
      " 29  Intend to Apply for Financial Aid?                               5143 non-null   float64\n",
      " 30  Merit Award                                                      5143 non-null   object \n",
      " 31  Decision                                                         5143 non-null   int64  \n",
      " 32  Submit_FirstSource                                               5143 non-null   float64\n",
      " 33  Submit_Inquiry                                                   5143 non-null   float64\n",
      " 34  School 1 Top Percent in Class                                    5143 non-null   float64\n",
      " 35  ACT Composite Grouped                                            5143 non-null   object \n",
      "dtypes: float64(10), int64(2), object(24)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Compare the your table structure with the screenshot in the submission box\n",
    "# Make sure all primary predictors and target variables do not have any missing values and only have\n",
    "# regualr and correct values.\n",
    "\n",
    "TUtest.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
