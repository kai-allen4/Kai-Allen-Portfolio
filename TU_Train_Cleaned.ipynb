{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trinity Admission Data Preparation <br>\n",
    "\n",
    "\n",
    "The goal of this data preparation project is to ready the data for constructing a classification model to determine whether an accepted applicant will decide to attend the University, based on information collected regarding the University’s recently accepted applicants, ranging in entry term from Fall 2017, Fall 2018, Fall 2019, Fall 2020, and Fall 2021.  Your final data set should be ready for modeling. \n",
    "\n",
    "This script demonstrates how to clean some typical variables for the train dataset and the cleaning requiremens for all variables. \n",
    "\n",
    "The train dataset is a subset of the original dataset, which is used to train the model to understand the relationships between variables. Then the trained model will predict the target variable using predictors in the test dataset.\n",
    "\n",
    "You need to handle all the columns/variables that are not processed in this scirpt following the intrsuctions in the comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>train-test</th>\n",
       "      <th>Entry Term (Application)</th>\n",
       "      <th>Admit Type</th>\n",
       "      <th>Permanent Postal</th>\n",
       "      <th>Permanent Country</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Race</th>\n",
       "      <th>Religion</th>\n",
       "      <th>...</th>\n",
       "      <th>SAT Concordance Score (of SAT R)</th>\n",
       "      <th>ACT Concordance Score (of SAT R)</th>\n",
       "      <th>ACT Concordance Score (of SAT)</th>\n",
       "      <th>Test Optional</th>\n",
       "      <th>SAT I Critical Reading</th>\n",
       "      <th>SAT I Math</th>\n",
       "      <th>SAT I Writing</th>\n",
       "      <th>SAT R Evidence-Based Reading and Writing Section</th>\n",
       "      <th>SAT R Math Section</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Fall 2017</td>\n",
       "      <td>FY</td>\n",
       "      <td>87507-7944</td>\n",
       "      <td>United States</td>\n",
       "      <td>F</td>\n",
       "      <td>Non Hispanic/Latino</td>\n",
       "      <td>White</td>\n",
       "      <td>Roman Catholic</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID train-test Entry Term (Application) Admit Type Permanent Postal  \\\n",
       "0   1      train                Fall 2017         FY       87507-7944   \n",
       "\n",
       "  Permanent Country Sex            Ethnicity   Race        Religion  ...  \\\n",
       "0     United States   F  Non Hispanic/Latino  White  Roman Catholic  ...   \n",
       "\n",
       "  SAT Concordance Score (of SAT R) ACT Concordance Score (of SAT R)  \\\n",
       "0                              NaN                              NaN   \n",
       "\n",
       "  ACT Concordance Score (of SAT) Test Optional SAT I Critical Reading  \\\n",
       "0                            NaN           NaN                    NaN   \n",
       "\n",
       "  SAT I Math SAT I Writing SAT R Evidence-Based Reading and Writing Section  \\\n",
       "0        NaN           NaN                                              NaN   \n",
       "\n",
       "  SAT R Math Section Decision  \n",
       "0                NaN        1  \n",
       "\n",
       "[1 rows x 69 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Read in TU.csv\n",
    "\n",
    "TU = pd.read_csv(\"TU.csv\")\n",
    "# pd.set_option('display.max_columns', None)\n",
    "TU.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'train-test', 'Entry Term (Application)', 'Admit Type',\n",
       "       'Permanent Postal', 'Permanent Country', 'Sex', 'Ethnicity', 'Race',\n",
       "       'Religion', 'First_Source Origin First Source Date', 'Inquiry Date',\n",
       "       'Submitted', 'Application Source', 'Decision Plan',\n",
       "       'Staff Assigned Name', 'Legacy', 'Athlete', 'Sport 1 Sport',\n",
       "       'Sport 1 Rating', 'Sport 2 Sport', 'Sport 2 Rating', 'Sport 3 Sport',\n",
       "       'Sport 3 Rating', 'Academic Interest 1', 'Academic Interest 2',\n",
       "       'First_Source Origin First Source Summary', 'Total Event Participation',\n",
       "       'Count of Campus Visits', 'School #1 Organization Category',\n",
       "       'School 1 Code', 'School 1 Class Rank (Numeric)',\n",
       "       'School 1 Class Size (Numeric)', 'School 1 GPA', 'School 1 GPA Scale',\n",
       "       'School 1 GPA Recalculated', 'School 2 Class Rank (Numeric)',\n",
       "       'School 2 Class Size (Numeric)', 'School 2 GPA', 'School 2 GPA Scale',\n",
       "       'School 2 GPA Recalculated', 'School 3 Class Rank (Numeric)',\n",
       "       'School 3 Class Size (Numeric)', 'School 3 GPA', 'School 3 GPA Scale',\n",
       "       'School 3 GPA Recalculated', 'ACT Composite', 'ACT English',\n",
       "       'ACT Reading', 'ACT Math', 'ACT Science Reasoning', 'ACT Writing',\n",
       "       'SAT I CR + M',\n",
       "       'SAT R Evidence-Based Reading and Writing Section + Math Section',\n",
       "       'Permanent Geomarket', 'Citizenship Status', 'Academic Index',\n",
       "       'Intend to Apply for Financial Aid?', 'Merit Award',\n",
       "       'SAT Concordance Score (of SAT R)', 'ACT Concordance Score (of SAT R)',\n",
       "       'ACT Concordance Score (of SAT)', 'Test Optional',\n",
       "       'SAT I Critical Reading', 'SAT I Math', 'SAT I Writing',\n",
       "       'SAT R Evidence-Based Reading and Writing Section',\n",
       "       'SAT R Math Section', 'Decision'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all columns in one output\n",
    "TU.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataframe into training and test datasets\n",
    "# In this course, you will only work on the variables in the training set\n",
    "# You will need to clean the test set following the methods used in this script, when you work on modeling in later chapter.\n",
    "\n",
    "TUtrain=TU[TU['train-test']=='train']\n",
    "TUtest=TU[TU['train-test']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column1 - ID\n",
    "\n",
    "#Check NAs\n",
    "TUtrain['ID'].isna().sum()\n",
    "#No NA,so no cleaning is required. But ID will be removed in the modeling stage. Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Fall 2017', 'Fall 2019', 'Fall 2020', 'Fall 2021', 'Fall 2018'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column2 - Entry Term Application\n",
    "\n",
    "#Check NAs\n",
    "print(TUtrain['Entry Term (Application)'].isna().sum())\n",
    "#No NA.\n",
    "TUtrain['Entry Term (Application)'].unique()\n",
    "#No irregular categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['FY']\n"
     ]
    }
   ],
   "source": [
    "#Column 3 - Admit Type\n",
    "\n",
    "#Check NAs\n",
    "print(TUtrain['Admit Type'].isna().sum())\n",
    "#No NA.\n",
    "print(TUtrain['Admit Type'].unique())\n",
    "#No irregular categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       FY\n",
      "1       FY\n",
      "2       FY\n",
      "3       FY\n",
      "4       FY\n",
      "        ..\n",
      "9995    FY\n",
      "9996    FY\n",
      "9997    FY\n",
      "9998    FY\n",
      "9999    FY\n",
      "Name: Admit Type, Length: 10000, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'train-test', 'Entry Term (Application)', 'Permanent Postal',\n",
       "       'Permanent Country', 'Sex', 'Ethnicity', 'Race', 'Religion',\n",
       "       'First_Source Origin First Source Date', 'Inquiry Date', 'Submitted',\n",
       "       'Application Source', 'Decision Plan', 'Staff Assigned Name', 'Legacy',\n",
       "       'Athlete', 'Sport 1 Sport', 'Sport 1 Rating', 'Sport 2 Sport',\n",
       "       'Sport 2 Rating', 'Sport 3 Sport', 'Sport 3 Rating',\n",
       "       'Academic Interest 1', 'Academic Interest 2',\n",
       "       'First_Source Origin First Source Summary', 'Total Event Participation',\n",
       "       'Count of Campus Visits', 'School #1 Organization Category',\n",
       "       'School 1 Code', 'School 1 Class Rank (Numeric)',\n",
       "       'School 1 Class Size (Numeric)', 'School 1 GPA', 'School 1 GPA Scale',\n",
       "       'School 1 GPA Recalculated', 'School 2 Class Rank (Numeric)',\n",
       "       'School 2 Class Size (Numeric)', 'School 2 GPA', 'School 2 GPA Scale',\n",
       "       'School 2 GPA Recalculated', 'School 3 Class Rank (Numeric)',\n",
       "       'School 3 Class Size (Numeric)', 'School 3 GPA', 'School 3 GPA Scale',\n",
       "       'School 3 GPA Recalculated', 'ACT Composite', 'ACT English',\n",
       "       'ACT Reading', 'ACT Math', 'ACT Science Reasoning', 'ACT Writing',\n",
       "       'SAT I CR + M',\n",
       "       'SAT R Evidence-Based Reading and Writing Section + Math Section',\n",
       "       'Permanent Geomarket', 'Citizenship Status', 'Academic Index',\n",
       "       'Intend to Apply for Financial Aid?', 'Merit Award',\n",
       "       'SAT Concordance Score (of SAT R)', 'ACT Concordance Score (of SAT R)',\n",
       "       'ACT Concordance Score (of SAT)', 'Test Optional',\n",
       "       'SAT I Critical Reading', 'SAT I Math', 'SAT I Writing',\n",
       "       'SAT R Evidence-Based Reading and Writing Section',\n",
       "       'SAT R Math Section', 'Decision'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since the data set only has first years (i.e.,only one category), \n",
    "# Admit.Type should be removed.\n",
    "print(TUtrain['Admit Type'])\n",
    "TUtrain=TUtrain.drop('Admit Type',axis='columns')\n",
    "TUtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "0       87507-7944\n",
      "1       75082-2652\n",
      "2       77055-6522\n",
      "3       98607-8571\n",
      "4       78681-3451\n",
      "           ...    \n",
      "9995    37122-9228\n",
      "9996    78732-1709\n",
      "9997    77459-7207\n",
      "9998    78015-8370\n",
      "9999           NaN\n",
      "Name: Permanent Postal, Length: 10000, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'train-test', 'Entry Term (Application)', 'Permanent Country',\n",
       "       'Sex', 'Ethnicity', 'Race', 'Religion',\n",
       "       'First_Source Origin First Source Date', 'Inquiry Date', 'Submitted',\n",
       "       'Application Source', 'Decision Plan', 'Staff Assigned Name', 'Legacy',\n",
       "       'Athlete', 'Sport 1 Sport', 'Sport 1 Rating', 'Sport 2 Sport',\n",
       "       'Sport 2 Rating', 'Sport 3 Sport', 'Sport 3 Rating',\n",
       "       'Academic Interest 1', 'Academic Interest 2',\n",
       "       'First_Source Origin First Source Summary', 'Total Event Participation',\n",
       "       'Count of Campus Visits', 'School #1 Organization Category',\n",
       "       'School 1 Code', 'School 1 Class Rank (Numeric)',\n",
       "       'School 1 Class Size (Numeric)', 'School 1 GPA', 'School 1 GPA Scale',\n",
       "       'School 1 GPA Recalculated', 'School 2 Class Rank (Numeric)',\n",
       "       'School 2 Class Size (Numeric)', 'School 2 GPA', 'School 2 GPA Scale',\n",
       "       'School 2 GPA Recalculated', 'School 3 Class Rank (Numeric)',\n",
       "       'School 3 Class Size (Numeric)', 'School 3 GPA', 'School 3 GPA Scale',\n",
       "       'School 3 GPA Recalculated', 'ACT Composite', 'ACT English',\n",
       "       'ACT Reading', 'ACT Math', 'ACT Science Reasoning', 'ACT Writing',\n",
       "       'SAT I CR + M',\n",
       "       'SAT R Evidence-Based Reading and Writing Section + Math Section',\n",
       "       'Permanent Geomarket', 'Citizenship Status', 'Academic Index',\n",
       "       'Intend to Apply for Financial Aid?', 'Merit Award',\n",
       "       'SAT Concordance Score (of SAT R)', 'ACT Concordance Score (of SAT R)',\n",
       "       'ACT Concordance Score (of SAT)', 'Test Optional',\n",
       "       'SAT I Critical Reading', 'SAT I Math', 'SAT I Writing',\n",
       "       'SAT R Evidence-Based Reading and Writing Section',\n",
       "       'SAT R Math Section', 'Decision'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column 4 - Permanent Postal\n",
    "print(TUtrain['Permanent Postal'].isna().sum())\n",
    "#105 NAs.\n",
    "TUtrain['Permanent Postal'].unique()\n",
    "#However, the column \"Permanent.Geomarket\" had already provided needed information\n",
    "#regarding the postal codes of different states. Therefore, this column might be\n",
    "#redundant, and we might just use \"Permanent.Geomarket\"\n",
    "#Therefore, let's remove this column and there is no need to handle the missing values\n",
    "print(TUtrain['Permanent Postal'])\n",
    "TUtrain=TUtrain.drop('Permanent Postal',axis='columns')\n",
    "TUtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['United States', 'Jamaica', 'Costa Rica', 'China', 'Vietnam',\n",
       "       'Nicaragua', 'Spain', 'India', 'Luxembourg', 'Nepal', 'Ecuador',\n",
       "       'Honduras', 'Cameroon', 'Mexico', 'Canada', 'Singapore',\n",
       "       'Bangladesh', 'Pakistan', 'United Arab Emirates', 'Uzbekistan',\n",
       "       'France', 'Thailand', 'Venezuela', 'Hong Kong S.A.R.',\n",
       "       'Switzerland', 'Tanzania', 'Brazil', 'El Salvador', 'Indonesia',\n",
       "       'Mozambique', 'Turkey', 'Czech Republic', 'Taiwan', 'Japan',\n",
       "       'South Korea', 'Colombia', \"Cote D'Ivoire\", 'Jordan', 'Kazakhstan',\n",
       "       'Panama', 'Belgium', 'United Kingdom', 'Nigeria', 'Peru',\n",
       "       'Lebanon', 'Cayman Islands', 'Guatemala', 'Argentina', 'Bolivia',\n",
       "       'Italy', 'Poland', 'Trinidad and Tobago', 'New Zealand',\n",
       "       'Ethiopia', 'Kenya', 'Montenegro', 'Germany', 'Saudi Arabia',\n",
       "       'Philippines', 'Greece', 'Ireland', 'Georgia', 'Belize',\n",
       "       'Netherlands', 'Palestine', 'Bosnia and Herzegovina', 'Cyprus',\n",
       "       'Norway', 'Russia', 'Barbados', 'Kuwait', 'Uruguay', 'Morocco',\n",
       "       'Ghana', 'The Bahamas', 'South Africa', 'Paraguay', 'Cambodia',\n",
       "       'Malaysia', 'Dominica', 'Iran', 'Lithuania'], dtype=object)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column 5 - Permanent Country\n",
    "#0 NA.\n",
    "print(TUtrain['Permanent Country'].isna().sum())\n",
    "#No irregular categories.\n",
    "TUtrain['Permanent Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States' 'Jamaica' 'Costa Rica' 'China' 'Vietnam' 'Nicaragua'\n",
      " 'Spain' 'India' 'UniqueCountry' 'Nepal' 'Ecuador' 'Honduras' 'Mexico'\n",
      " 'Canada' 'Singapore' 'Pakistan' 'United Arab Emirates' 'France'\n",
      " 'Thailand' 'Hong Kong S.A.R.' 'Switzerland' 'Tanzania' 'Brazil'\n",
      " 'El Salvador' 'Indonesia' 'Turkey' 'Taiwan' 'Japan' 'South Korea'\n",
      " 'Colombia' 'Jordan' 'Kazakhstan' 'Panama' 'Belgium' 'United Kingdom'\n",
      " 'Nigeria' 'Peru' 'Lebanon' 'Guatemala' 'Argentina' 'Bolivia' 'Ethiopia'\n",
      " 'Germany' 'Saudi Arabia' 'Philippines' 'Greece' 'Belize' 'Netherlands'\n",
      " 'Cyprus' 'Norway' 'Russia' 'Kuwait' 'Uruguay' 'Morocco' 'Ghana'\n",
      " 'South Africa' 'Cambodia']\n"
     ]
    }
   ],
   "source": [
    "# List of countries that are unique to the train set\n",
    "MissingInTest = [\n",
    "    'Barbados', 'Dominica', 'Palestine', 'Poland', 'Georgia', 'Venezuela', 'Italy', \n",
    "    'Czech Republic', 'Ireland', 'Cayman Islands', 'Cameroon', 'Malaysia', 'Iran', \n",
    "    'The Bahamas', 'New Zealand', 'Bosnia and Herzegovina', 'Paraguay', 'Lithuania', \n",
    "    'Trinidad and Tobago', 'Bangladesh', 'Luxembourg', 'Montenegro', 'Kenya', \n",
    "    \"Cote D'Ivoire\", 'Uzbekistan', 'Mozambique'\n",
    "]\n",
    "\n",
    "# Make all missing coutries into one category\n",
    "TUtrain['Permanent Country'] = TUtrain['Permanent Country'].apply(\n",
    "    lambda x: 'UniqueCountry' if x in MissingInTest else x\n",
    ")\n",
    "\n",
    "print(TUtrain['Permanent Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['F' 'M']\n"
     ]
    }
   ],
   "source": [
    "#Column6 - Sex\n",
    "print(TUtrain['Sex'].isna().sum())\n",
    "#No NA.\n",
    "print(TUtrain['Sex'].unique())\n",
    "#No irregular categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "['Non Hispanic/Latino' 'Hispanic/Latino' nan]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column7 - Ethnicity\n",
    "print(TUtrain['Ethnicity'].isna().sum())\n",
    "#158 NAs.\n",
    "print(TUtrain['Ethnicity'].unique())\n",
    "#No irregular categories.\n",
    "# It is fair to replace NAs with \"Not Specified\" as we do not have other columns for inter-field checking.\n",
    "\n",
    "TUtrain['Ethnicity'].fillna(\"Not specified\",inplace=True)\n",
    "TUtrain['Ethnicity'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n",
      "['White' 'Asian' 'Black or African American' 'Asian, White' nan\n",
      " 'American Indian or Alaska Native, Black or African American, White'\n",
      " 'Black or African American, White'\n",
      " 'Asian, Black or African American, White'\n",
      " 'American Indian or Alaska Native'\n",
      " 'American Indian or Alaska Native, White'\n",
      " 'American Indian or Alaska Native, Asian, White'\n",
      " 'Asian, Black or African American' 'Native Hawaiian or Other Pacific'\n",
      " 'Asian, Native Hawaiian or Other Pacific'\n",
      " 'Native Hawaiian or Other Pacific, White'\n",
      " 'Asian, Native Hawaiian or Other Pacific, White'\n",
      " 'American Indian or Alaska Native, Black or African American'\n",
      " 'American Indian or Alaska Native, Asian'\n",
      " 'Black or African American, Native Hawaiian or Other Pacific'\n",
      " 'American Indian or Alaska Native, Native Hawaiian or Other Pacific'\n",
      " 'American Indian or Alaska Native, Asian, Black or African American, White']\n"
     ]
    }
   ],
   "source": [
    "#Column8 - Race\n",
    "print(TUtrain['Race'].isna().sum())\n",
    "#389 NAs.\n",
    "print(TUtrain['Race'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No irregular categories.\n",
    "#Impute NAs with \"Not specified\", similar to what we do for Ethnicity.\n",
    "TUtrain['Race'].fillna(\"Not specified\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Race\n",
       "White                                                                        6786\n",
       "Asian                                                                        1640\n",
       "Black or African American                                                     505\n",
       "Not specified                                                                 389\n",
       "Asian, White                                                                  300\n",
       "Black or African American, White                                               99\n",
       "American Indian or Alaska Native, White                                        96\n",
       "American Indian or Alaska Native                                               84\n",
       "Asian, Black or African American                                               17\n",
       "Asian, Native Hawaiian or Other Pacific                                        15\n",
       "Asian, Native Hawaiian or Other Pacific, White                                 14\n",
       "Native Hawaiian or Other Pacific, White                                        13\n",
       "Native Hawaiian or Other Pacific                                               12\n",
       "American Indian or Alaska Native, Black or African American, White              9\n",
       "American Indian or Alaska Native, Black or African American                     6\n",
       "Asian, Black or African American, White                                         6\n",
       "American Indian or Alaska Native, Asian, White                                  5\n",
       "American Indian or Alaska Native, Asian                                         1\n",
       "Black or African American, Native Hawaiian or Other Pacific                     1\n",
       "American Indian or Alaska Native, Native Hawaiian or Other Pacific              1\n",
       "American Indian or Alaska Native, Asian, Black or African American, White       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The current classification of Race is too detailed, which leads to very \n",
    "#low frequencies for some categories.Let's take a look at the value frequencies.\n",
    "TUtrain['Race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['White',\n",
       " 'Asian',\n",
       " 'Black or African American',\n",
       " 'Not specified',\n",
       " 'Asian, White',\n",
       " 'Black or African American, White',\n",
       " 'American Indian or Alaska Native, White']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So let's combine some of the categories because a category with a small number of cases won't have \n",
    "#a significant effect on the target variable in the modeling stage.\n",
    "\n",
    "#Generate a race list that would be kept, the rest will be classified as 'others'\n",
    "RaceList = list(TUtrain['Race'].value_counts()[:7].index)\n",
    "RaceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Race\n",
       "White                                      6786\n",
       "Asian                                      1640\n",
       "Black or African American                   505\n",
       "Not specified                               389\n",
       "Asian, White                                300\n",
       "Others                                      185\n",
       "Black or African American, White             99\n",
       "American Indian or Alaska Native, White      96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TUtrain['Race'] = \\\n",
    "TUtrain['Race'].apply(lambda x: 'Others' if x not in RaceList else x)\n",
    "TUtrain['Race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4177\n",
      "['Roman Catholic' nan 'Christian' 'Presbyterian' 'Islam/Muslim' 'Jewish'\n",
      " 'Hindu' 'Baptist' 'Methodist' 'Jain' 'Anglican' 'Lutheran' 'Other'\n",
      " 'Assembly of God' 'Non-Denominational' 'Bible Churches'\n",
      " 'Christian Reformed' 'Unitarian' 'Eastern Orthodox' 'Episcopal'\n",
      " 'United Methodist' 'Church of Christ' 'Pentecostal'\n",
      " 'Lutheran-Missouri Synod' 'Protestant' 'Mormon-Latter Day Saints'\n",
      " 'Buddhism' 'Sikh' 'Church of God' 'Presbyterian Church of America'\n",
      " 'Evangelical' 'Southern Baptist' 'Society of Friends (Quaker)'\n",
      " 'United Church of Christ' \"Jehovah's Witnesses\" 'Mennonite'\n",
      " 'Christian Scientist' 'Jewish Messianic' \"Baha'I\" 'Coptic Church (Egypt)'\n",
      " 'Zoroastrian']\n",
      "Religion\n",
      "Not specified                     4177\n",
      "Roman Catholic                    1821\n",
      "Christian                         1084\n",
      "Baptist                            431\n",
      "Methodist                          416\n",
      "Presbyterian                       293\n",
      "Hindu                              239\n",
      "Jewish                             197\n",
      "Other                              180\n",
      "Anglican                           174\n",
      "Lutheran                           173\n",
      "Islam/Muslim                       162\n",
      "Non-Denominational                 105\n",
      "Church of Christ                    92\n",
      "Buddhism                            72\n",
      "Episcopal                           65\n",
      "Eastern Orthodox                    56\n",
      "Pentecostal                         51\n",
      "Unitarian                           26\n",
      "Protestant                          21\n",
      "Mormon-Latter Day Saints            20\n",
      "Evangelical                         18\n",
      "Sikh                                17\n",
      "Christian Reformed                  15\n",
      "Jain                                12\n",
      "Assembly of God                     10\n",
      "United Church of Christ              9\n",
      "United Methodist                     9\n",
      "Bible Churches                       9\n",
      "Southern Baptist                     8\n",
      "Church of God                        6\n",
      "Christian Scientist                  6\n",
      "Society of Friends (Quaker)          5\n",
      "Presbyterian Church of America       4\n",
      "Lutheran-Missouri Synod              4\n",
      "Jehovah's Witnesses                  3\n",
      "Baha'I                               3\n",
      "Coptic Church (Egypt)                3\n",
      "Mennonite                            2\n",
      "Jewish Messianic                     1\n",
      "Zoroastrian                          1\n",
      "Name: count, dtype: int64\n",
      "Religion\n",
      "Not specified               4177\n",
      "Roman Catholic              1821\n",
      "Christian                   1084\n",
      "OtherRelgiousAffiliation     728\n",
      "Baptist                      431\n",
      "Methodist                    416\n",
      "Presbyterian                 293\n",
      "Hindu                        239\n",
      "Jewish                       197\n",
      "Anglican                     174\n",
      "Lutheran                     173\n",
      "Islam/Muslim                 162\n",
      "Non-Denominational           105\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column 9 - Religion\n",
    "# print # of NAs\n",
    "print(TUtrain['Religion'].isnull().sum()) # 4177 null values\n",
    "\n",
    "# print unique values for Religion\n",
    "print(TUtrain.Religion.unique())\n",
    "\n",
    "#Impute NAs with \"Not specified\", similar to what we do for Race.\n",
    "TUtrain[\"Religion\"] = TUtrain['Religion'].apply(lambda x: \"Not specified\" if pd.isnull(x) else x) #.apply iterates thru the dataframe, in this case replacing the nulls with \"Not Specified\"\n",
    "\n",
    "#The current classification of Race is too detailed, which leads to very \n",
    "#low frequencies for some categories.Print the value frequencies.\n",
    "print(TUtrain[\"Religion\"].value_counts())\n",
    "\n",
    "#Religion has lots of categories, with some categories having a very small number of cases. \n",
    "#Let's combine similar levels into one level( for example:['Bible Churches','Christian Reformed','Christian Scientist','Church of Christ','Church of God'] )\n",
    "TUtrain['Religion'] = TUtrain.Religion.apply(lambda x: \"OtherRelgiousAffiliation\" if x in ['Pentecostal',\n",
    "                                                      'Unitarian','Protestant','Mormon-Latter Day Saints',\n",
    "                                                      'Evangelical','Assembly of God','Bible Churches',\n",
    "                                                      'Christian Reformed', 'Christian Scientist',\n",
    "                                                      'Church of Christ','Church of God', 'Southern Baptist', \n",
    "                                                      'United Methodist', 'United Church of Christ',\n",
    "                                                      'Society of Friends (Quaker)',\n",
    "                                                      'Presbyterian Church of America',\n",
    "                                                      'Lutheran-Missourie Synod',\"Jehovah's Witnesses\",\n",
    "                                                      'Coptic Church (Egypt)','Mennonite','Episcopal',\n",
    "                                                      'Eastern Orthodox','Lutheran-Missouri Synod','Baha',\n",
    "                                                      'Jewish Messianic','Zoroastrian',\"Baha'I\",'Jain','Sikh',\n",
    "                                                      'Buddhism','Other'\n",
    "                                                                                        \n",
    "                                                                                        \n",
    "                                                                                        ] else x)\n",
    "#I combined all small christian denominations below   100 \n",
    "\n",
    "\n",
    "#then combine levels with less than 100 cases into \"Other\" because a level accounting for lower than 1% \n",
    "#of training set is very unlikely to have a significant effect on the target variable.\n",
    "\n",
    "print(TUtrain.Religion.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0      2016-11-18 05:40:00\n",
      "1      2017-01-30 17:24:00\n",
      "2      2019-01-31 12:35:00\n",
      "3      1900-01-01 00:00:00\n",
      "4      2018-02-19 11:11:00\n",
      "               ...        \n",
      "9995   2018-02-16 16:31:00\n",
      "9996   2017-01-30 17:24:00\n",
      "9997   2018-06-12 14:53:00\n",
      "9998   2017-01-30 17:24:00\n",
      "9999   1900-01-01 00:00:00\n",
      "Name: First_Source Origin First Source Date, Length: 10000, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#Column 10 - First_Source Origin First Source Date\n",
    "print(TUtrain['First_Source Origin First Source Date'].isna().sum())\n",
    "#No NAs.\n",
    "\n",
    "#convert to date format\n",
    "TUtrain['First_Source Origin First Source Date'] = pd.to_datetime(\n",
    "    TUtrain['First_Source Origin First Source Date'], errors='coerce').fillna(pd.to_datetime('1900-01-01'))\n",
    "# Display the converted column\n",
    "print(TUtrain['First_Source Origin First Source Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       2017-02-13 19:25:00\n",
       "1           Did not Inquire\n",
       "2           Did not Inquire\n",
       "3       2016-10-18 15:49:00\n",
       "4           Did not Inquire\n",
       "               ...         \n",
       "9995        Did not Inquire\n",
       "9996    2019-01-01 17:55:00\n",
       "9997    2018-10-05 11:29:00\n",
       "9998    2018-02-20 15:03:00\n",
       "9999        Did not Inquire\n",
       "Name: Inquiry Date, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column11 - Inquiry Date\n",
    "print(TUtrain['Inquiry Date'].isna().sum())\n",
    "#3181 NAs.\n",
    "\n",
    "#convert to date format\n",
    "TUtrain['Inquiry Date']= pd.to_datetime(TUtrain['Inquiry Date'], errors='coerce')\n",
    "\n",
    "# Filling NaNs with a statement saying they did not inquire abount trinity admissions\n",
    "TUtrain['Inquiry Date'].fillna(\"Did not Inquire\", inplace=True)\n",
    "TUtrain['Inquiry Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Column 12 - Submitted\n",
    "print(TUtrain['Submitted'].isna().sum())\n",
    "#No NAs.\n",
    "\n",
    "#convert to date format\n",
    "TUtrain['Submitted'] = pd.to_datetime(TUtrain['Submitted'], errors='ignore').fillna(pd.to_datetime('1900-01-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column10-12\n",
    "# After viewing Column10-12, it would be interesting to see\n",
    "# whether the differences between submission date and First_Source date,\n",
    "# and the differences between submission date and inquiry date, affect the response.\n",
    "# So let's calculate the time difference between submission date and first_source date.\n",
    "\n",
    "# Convert 'Submitted' and 'First_Source Origin First Source Date' to datetime, setting any missing values to '1900-01-01'\n",
    "TUtrain['Submitted'] = pd.to_datetime(TUtrain['Submitted'], errors='coerce').fillna(pd.to_datetime('1900-01-01'))\n",
    "TUtrain['First_Source Origin First Source Date'] = pd.to_datetime(TUtrain['First_Source Origin First Source Date'], errors='coerce').fillna(pd.to_datetime('1900-01-01'))\n",
    "\n",
    "# Convert 'Inquiry Date' to datetime, setting any missing values to a placeholder date\n",
    "# Add an indicator column to mark rows with no inquiry\n",
    "TUtrain['Inquiry Date'] = pd.to_datetime(TUtrain['Inquiry Date'], errors='coerce').fillna(pd.to_datetime('1900-01-01'))\n",
    "TUtrain['Inquiry Status'] = TUtrain['Inquiry Date'].apply(lambda x: \"Did not Inquire\" if x == pd.to_datetime('1900-01-01') else \"Inquired\")\n",
    "\n",
    "# Calculate the time difference in weeks between 'Submitted' and 'First_Source Origin First Source Date'\n",
    "TUtrain['Submit_FirstSource'] = (TUtrain['Submitted'] - TUtrain['First_Source Origin First Source Date']).dt.days / 7\n",
    "\n",
    "# Calculate the time difference in weeks between 'Submitted' and 'Inquiry Date'\n",
    "TUtrain['Submit_Inquiry'] = (TUtrain['Submitted'] - TUtrain['Inquiry Date']).dt.days / 7\n",
    "\n",
    "# Optionally, round the calculated week differences to whole numbers\n",
    "TUtrain['Submit_FirstSource'] = TUtrain['Submit_FirstSource'].round(0)\n",
    "TUtrain['Submit_Inquiry'] = TUtrain['Submit_Inquiry'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are NAs in Inquiry.Date,\n",
    "#thus leading to NAs in Submit_Inquiry.\n",
    "#Impute NAs in Submit_Inquiry with median values.\n",
    "\n",
    "TUtrain['Submit_Inquiry'].fillna(TUtrain['Submit_Inquiry'].median(),inplace=True)\n",
    "TUtrain['Submit_Inquiry'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Column10-12 after you created new variables above.  \n",
    "TUtrain.drop('First_Source Origin First Source Date', axis='columns', inplace=True)\n",
    "TUtrain.drop('Inquiry Date', axis='columns', inplace=True)\n",
    "TUtrain.drop('Submitted', axis='columns', inplace=True)\n",
    "TUtrain.drop(\"Inquiry Status\", axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['CommonApp' 'ApplyTexas' 'Coalition' 'Select Scholar']\n"
     ]
    }
   ],
   "source": [
    "#Column13 - Application.Source\n",
    "print( TUtrain['Application Source'].isna().sum())\n",
    "#No NAs.\n",
    "print(TUtrain['Application Source'].unique())\n",
    "#No irregular categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['Early Action II' 'Early Action I' 'Early Action' 'Regular Decision'\n",
      " 'Early Decision I' 'Early Decision II']\n"
     ]
    }
   ],
   "source": [
    "#Column14 - Decision.Plan\n",
    "print(TUtrain['Decision Plan'].isna().sum())\n",
    "#No NAs.\n",
    "print(TUtrain['Decision Plan'].unique())\n",
    "#No irregular categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column15 - Staff.Assigned.Name\n",
    "#Based on variable description, this variable might not be useful and provide\n",
    "#insightful information in the modeling.\n",
    "#Also, some staffs already left Trinity.\n",
    "#So remove this variable\n",
    "TUtrain.drop(['Staff Assigned Name'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999\n",
      "[nan 'Legacy' 'Legacy, Opt Out' 'Fine Arts, Legacy' 'Athlete, Legacy'\n",
      " 'Fine Arts, Legacy, VIP' 'Legacy, VIP' 'Athlete, Legacy, VIP'\n",
      " 'Athlete, Legacy, Opt Out' 'Legacy, Opt Out, VIP'\n",
      " 'Fine Arts, Legacy, Opt Out' 'Athlete, Legacy, Opt Out, VIP'\n",
      " 'Athlete, Fine Arts, Legacy' 'Fine Arts, Legacy, Opt Out, VIP'\n",
      " 'Athlete, Fine Arts, Legacy, VIP'\n",
      " 'Athlete, Fine Arts, Legacy, Opt Out, VIP']\n"
     ]
    }
   ],
   "source": [
    "#Column16 - Legacy\n",
    "print(TUtrain['Legacy'].isna().sum())\n",
    "#No NAs.\n",
    "print(TUtrain['Legacy'].unique())\n",
    "#No irregular categories.\n",
    "#Impute NAs with \"No Legacy\"\n",
    "TUtrain['Legacy'].fillna(\"No Legacy\",inplace=True)\n",
    "TUtrain['Legacy'].isna().sum()\n",
    "\n",
    "#Legacy has many options, leading some options to having only a small number of cases.\n",
    "#Let's group all the options into 3 categories ('Legacy',\"No Legacy\", \"Legacy, Opt Out\") \n",
    "#so that each category has the chance to affect the response variable.\n",
    "TUtrain['Legacy']=\\\n",
    "TUtrain['Legacy'].apply(lambda x: 'Legacy, Opt Out' if x not in ['Legacy','No Legacy'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8683\n",
      "Athlete\n",
      "Athlete                                     831\n",
      "Athlete, Opt Out                            338\n",
      "Athlete, Legacy                              58\n",
      "Athlete, Legacy, Opt Out                     30\n",
      "Athlete, VIP                                 17\n",
      "Athlete, Fine Arts                           15\n",
      "Athlete, Legacy, VIP                         11\n",
      "Athlete, Legacy, Opt Out, VIP                 8\n",
      "Athlete, Opt Out, VIP                         4\n",
      "Athlete, Fine Arts, Opt Out                   2\n",
      "Athlete, Fine Arts, Legacy                    1\n",
      "Athlete, Fine Arts, Legacy, VIP               1\n",
      "Athlete, Fine Arts, Legacy, Opt Out, VIP      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column17 - Athlete\n",
    "# print # NAs.\n",
    "print(TUtrain['Athlete'].isnull().sum()) #checking for NAs / sum, 8683 null values\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtrain['Athlete'].value_counts()) #unique value counts returning amount of groups\n",
    "\n",
    "#Impute NAs with \"Non-Athlete\"\n",
    "TUtrain['Athlete'] = TUtrain.Athlete.apply(lambda x: \"Non-Athlete\" if pd.isnull(x) else x) \n",
    "#.apply() lambda x returning \"Non-Athlete\" for any null value \n",
    "\n",
    "#Similar to Legacy, Athlete has many categories with a few cases.\n",
    "#Group all options into three categories: \n",
    "#Athlete, Non-Athlete, and Athlete, Opt Out.\n",
    "\n",
    "TUtrain['Athlete'] = \\\n",
    "TUtrain.Athlete.apply(lambda x: \"Athlete, Opt Out\" if x in [\"Athlete, Opt Out\", \"Athlete, Legacy, Opt Out\", \"Athlete, Legacy, Opt Out, VIP\",\"Athlete, Opt Out, VIP\",\"Athlete, Fine Arts, Opt Out\",\"Athlete, Fine Arts, Legacy, Opt Out, VIP\"] else x) \n",
    "#grouping variables into one group called Athlete Opt Out\n",
    "# Done by checking if x is in the specified list\n",
    "\n",
    "TUtrain['Athlete'] = \\\n",
    "TUtrain.Athlete.apply(lambda x: \"Athlete\" if x not in [\"Non-Athlete\",\"Athlete, Opt Out\"] else x) \n",
    "#this is grouping items into an Athlete group if they are NOT in these non athlete or opt out groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athlete\n",
      "Non-Athlete         8683\n",
      "Athlete              934\n",
      "Athlete, Opt Out     383\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtrain['Athlete'].value_counts()) \n",
    "# Just checking to see the cleaning was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8683\n",
      "Sport 1 Sport\n",
      "Football               329\n",
      "Baseball               109\n",
      "Cross Country Men       97\n",
      "Soccer Men              95\n",
      "Track Women             82\n",
      "Track Men               81\n",
      "Basketball Men          81\n",
      "Cross Country Women     68\n",
      "Swimming Men            66\n",
      "Soccer Women            60\n",
      "Swimming Women          51\n",
      "Tennis Men              35\n",
      "Tennis Women            31\n",
      "Softball                29\n",
      "Volleyball              26\n",
      "Basketball Women        21\n",
      "Golf Women              19\n",
      "Golf Men                15\n",
      "Diving Women            14\n",
      "Diving Men               8\n",
      "Name: count, dtype: int64\n",
      "Sport 1 Sport\n",
      "No Sport         8683\n",
      "Football          329\n",
      "Cross Country     165\n",
      "Track             163\n",
      "Soccer            155\n",
      "Swimming          117\n",
      "Baseball          109\n",
      "Basketball        102\n",
      "Tennis             66\n",
      "Golf               34\n",
      "Softball           29\n",
      "Volleyball         26\n",
      "Diving             22\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print NAs\n",
    "print(TUtrain['Sport 1 Sport'].isnull().sum())  # 8683 null values\n",
    "\n",
    "# Print unique value counts\n",
    "print(TUtrain['Sport 1 Sport'].value_counts())  # Displays the unique sport counts\n",
    "\n",
    "# Impute NAs with \"No Sport\"\n",
    "TUtrain['Sport 1 Sport'] = TUtrain['Sport 1 Sport'].fillna(\"No Sport\")\n",
    "\n",
    "# Remove gender-specific suffixes from sport names (e.g., \"Men\", \"Women\")\n",
    "# Create a mapping to remove gender-based distinctions\n",
    "gender_removal_map = {\n",
    "    \"Football Men\": \"Football\", \n",
    "    \"Football Women\": \"Football\",\n",
    "    \"Baseball Men\": \"Baseball\", \n",
    "    \"Baseball Women\": \"Baseball\",\n",
    "    \"Cross Country Men\": \"Cross Country\", \n",
    "    \"Cross Country Women\": \"Cross Country\",\n",
    "    \"Soccer Men\": \"Soccer\", \n",
    "    \"Soccer Women\": \"Soccer\",\n",
    "    \"Track Men\": \"Track\", \n",
    "    \"Track Women\": \"Track\",\n",
    "    \"Basketball Men\": \"Basketball\", \n",
    "    \"Basketball Women\": \"Basketball\",\n",
    "    \"Swimming Men\": \"Swimming\", \n",
    "    \"Swimming Women\": \"Swimming\",\n",
    "    \"Tennis Men\": \"Tennis\", \n",
    "    \"Tennis Women\": \"Tennis\",\n",
    "    \"Golf Men\": \"Golf\", \n",
    "    \"Golf Women\": \"Golf\",\n",
    "    \"Diving Men\": \"Diving\", \n",
    "    \"Diving Women\": \"Diving\",\n",
    "    \"Softball\": \"Softball\",\n",
    "    \"Volleyball\": \"Volleyball\"\n",
    "}\n",
    "\n",
    "# Apply the gender_removal_map to group the sports\n",
    "TUtrain['Sport 1 Sport'] = TUtrain['Sport 1 Sport'].map(gender_removal_map).fillna(TUtrain['Sport 1 Sport'])\n",
    "\n",
    "# Now the 'Sport 1 Sport' column should only contain the sport names without gender distinctions\n",
    "print(TUtrain['Sport 1 Sport'].value_counts())  # Check updated value counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sport 1 Sport\n",
      "No Sport         8683\n",
      "Football          329\n",
      "Cross Country     165\n",
      "Track             163\n",
      "Soccer            155\n",
      "Swimming          117\n",
      "Baseball          109\n",
      "Basketball        102\n",
      "Tennis             66\n",
      "Golf               34\n",
      "Softball           29\n",
      "Volleyball         26\n",
      "Diving             22\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column18 - Sport 1 Sport\n",
    "\n",
    "# print # NAs.\n",
    "print(TUtrain['Sport 1 Sport'].isnull().sum()) #8683 null values\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtrain['Sport 1 Sport'].value_counts()) \n",
    "# value counts shows there are 20 different groups, 2 of which have over 100 observations\n",
    "\n",
    "#Impute NAs with \"No Sport\"\n",
    "TUtrain['Sport 1 Sport'] = TUtrain['Sport 1 Sport'].apply(lambda x: \"No Sport\" if pd.isnull(x) else x) \n",
    "\n",
    "#Group sport men and sport women into one group\n",
    "#so that each group has sufficient cases to have an impact on the response.\n",
    "TUtrain['Sport 1 Sport'] = TUtrain['Sport 1 Sport'].apply(lambda x: \"Sport\" if x in \n",
    "                                                          [\"Football\", \"Baseball\", \"Cross Country Men\", \n",
    "                                                           \"Soccer Men\", \"Track Men\", \"Basketball Men\", \n",
    "                                                           \"Swimming Men\", \"Tennis Men\", \"Golf Men\", \n",
    "                                                           \"Diving Men\", \"Track Women\",\"Cross Country Women\",\n",
    "                                                           \"Soccer Women\",\"Swimming Women\",\"Tennis Women\",\n",
    "                                                           \"Softball\",\"Volleyball\",\"Basketball Women\",\n",
    "                                                           \"Golf Women\",\"Diving Women\"] else x ) \n",
    "# Making it into two easily defined groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sport 1 Sport\n",
      "No Sport         8683\n",
      "Sport             493\n",
      "Cross Country     165\n",
      "Track             163\n",
      "Soccer            155\n",
      "Swimming          117\n",
      "Basketball        102\n",
      "Tennis             66\n",
      "Golf               34\n",
      "Diving             22\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtrain['Sport 1 Sport'].value_counts()) \n",
    "# Checking to see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8683\n",
      "Sport 1 Rating\n",
      "Blue Chip    551\n",
      "Varsity      439\n",
      "Franchise    327\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column19 - Sport 1 Rating\n",
    "# print # NAs.\n",
    "print(TUtrain['Sport 1 Rating'].isnull().sum()) # 8683 null values\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtrain['Sport 1 Rating'].value_counts()) # found 3 different groups all 250 observations of each other\n",
    "\n",
    "#Impute NAs with \"No Sport\"\n",
    "TUtrain['Sport 1 Rating'] = TUtrain[\"Sport 1 Rating\"].apply(lambda x: \"No Sport\" if pd.isna(x) else x)\n",
    "# Just as before, I used the .apply function to replace any null values found thru pd.isna() function, \n",
    "# in this case with the value \"No Sport\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9583\n",
      "Sport 2 Sport\n",
      "Track & Field          125\n",
      "Basketball              54\n",
      "Soccer                  43\n",
      "Baseball                40\n",
      "Football                29\n",
      "Cross Country           23\n",
      "Swimming                23\n",
      "Volleyball              15\n",
      "Tennis                  14\n",
      "Track Men               13\n",
      "Golf                     9\n",
      "Diving                   6\n",
      "Softball                 5\n",
      "Track Women              4\n",
      "Basketball Men           3\n",
      "Soccer Women             3\n",
      "Cross Country Women      3\n",
      "Tennis Women             2\n",
      "Cross Country Men        2\n",
      "Soccer Men               1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column20 - Sport 2 Sport\n",
    "\n",
    "# print # NAs.\n",
    "print(TUtrain['Sport 2 Sport'].isnull().sum()) #found 9583 null values using .isnull().sum()\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtrain['Sport 2 Sport'].value_counts()) \n",
    "# value counts shows 20 different unique groups where only 1 group has over 125 observations\n",
    "\n",
    "#impute NAs with \"No 2ndSport\".\n",
    "TUtrain['Sport 2 Sport'] = TUtrain[\"Sport 2 Sport\"].apply(lambda x: \"No 2ndSport\" if pd.isna(x) else x) \n",
    "#used the .apply function to replace any null values found thru pd.isna() function with the string \"No 2ndSport\"\n",
    "\n",
    "#The number of cases for each sport type is very small (< about 1% of the data set).\n",
    "#It's better to group all options into 2 categories: 2ndSport vs. No 2ndSport.\n",
    "TUtrain['Sport 2 Sport'] = TUtrain[\"Sport 2 Sport\"].apply(lambda x: \"2nd Sport\" if x not in [\"No 2ndSport\"] else x) \n",
    "#grouped  anything that was not found in \"No 2ndSport\" into a new group called \"2nd Sport\" using .apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sport 2 Sport\n",
      "No 2ndSport    9583\n",
      "2nd Sport       417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtrain['Sport 2 Sport'].value_counts()) \n",
    "# Verifying code worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9957\n",
      "[nan 'Blue Chip' 'Varsity' 'Franchise']\n"
     ]
    }
   ],
   "source": [
    "#Column21 - Sport 2 Rating\n",
    "print(TUtrain['Sport 2 Rating'].isna().sum())\n",
    "#9957 NAs.\n",
    "print(TUtrain['Sport 2 Rating'].unique())\n",
    "#Only 43 out of 10000 observations are rated, which is less than 0.5% of the data set!\n",
    "#Sport.2.Rating will not have much impact on the target.\n",
    "#Remove it in the modeling stage.\n",
    "\n",
    "TUtrain.drop('Sport 2 Rating',axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9838\n",
      "Sport 3 Sport\n",
      "Basketball       40\n",
      "Track & Field    29\n",
      "Swimming         15\n",
      "Cross Country    15\n",
      "Soccer           14\n",
      "Baseball         13\n",
      "Football         12\n",
      "Tennis           12\n",
      "Volleyball        6\n",
      "Golf              3\n",
      "Softball          2\n",
      "Track Men         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column22 - Sport 3 Sport\n",
    "\n",
    "# print # NAs.\n",
    "print(TUtrain['Sport 3 Sport'].isna().sum()) #9838 null values found with .isna().sum()\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtrain['Sport 3 Sport'].value_counts())#value counts found 12 different unique values all having under 41 observations\n",
    "\n",
    "#impute NAs with \"No 3rdSport\".\n",
    "TUtrain['Sport 3 Sport'] = TUtrain[\"Sport 3 Sport\"].apply(lambda x: \"No 3rdSport\" if pd.isna(x) else x) \n",
    "#used the .apply function to replace any null values found thru pd.isna() function with the string \"No 3rdSport\"\n",
    "\n",
    "#The number of cases for each sport type is very small (< 0.5% of the data set).\n",
    "#It's better to group all options into 2 categories: 3rdSport vs. No 3rdSport.\n",
    "TUtrain['Sport 3 Sport'] = TUtrain[\"Sport 3 Sport\"].apply(lambda x: \"3rdSport\" if x not in [\"No 3rdSport\"] else x) \n",
    "# Same technique as before but the replacing value is 3rdSport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sport 3 Sport\n",
      "No 3rdSport    9838\n",
      "3rdSport        162\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtrain['Sport 3 Sport'].value_counts())#value counts found 12 different unique values all having under 41 observations\n",
    "# Verifying the code worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998\n",
      "[nan 'Varsity']\n"
     ]
    }
   ],
   "source": [
    "#Column23 - Sport.3.Rating\n",
    "\n",
    "print(TUtrain['Sport 3 Rating'].isna().sum())\n",
    "#9998 NAs.\n",
    "print(TUtrain['Sport 3 Rating'].unique())\n",
    "#No questionable category.\n",
    "#Only 2 out of 10000 observations are rated, which will not provide much insightful\n",
    "#information. Therefore,remove this column\n",
    "TUtrain.drop('Sport 3 Rating',axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['Biology' 'Engineering Science' 'Psychology' 'Neuroscience'\n",
      " 'Computer Science' 'English' 'Mathematics' 'Education' 'Music'\n",
      " 'Undecided' 'Business' 'Geosciences' 'Pre-Law' 'Biochemistry' 'Finance'\n",
      " 'Pre-Medical' 'Political Science' 'Business - Communication Management'\n",
      " 'Economics' 'Business - Accounting' 'Entrepreneurship' 'Sociology'\n",
      " 'Environmental Studies' 'Chemistry' 'Mathematical Finance'\n",
      " 'Business - Sport Management' 'History' 'International Studies'\n",
      " 'Biochemistry & Molecular Biology' 'Business - Management'\n",
      " 'Communication' 'Anthropology' 'Business - Marketing' 'Linguistics'\n",
      " 'Philosophy' 'Business - International Business'\n",
      " 'Business Analytics & Technology' 'Art' 'French'\n",
      " 'Business - Management Information Systems' 'Physics' 'Urban Studies'\n",
      " 'Chinese' 'Nursing' 'Business Legal Studies' 'Human Communication'\n",
      " 'Comparative Literature' 'Creative Writing'\n",
      " 'Ancient Mediterranean Studies' 'Art History' 'Architectural Studies'\n",
      " 'Film Studies' 'Theatre' 'Music Education' 'Pre-Dental' 'Religion'\n",
      " 'Classical Languages' 'Applied Chemistry' 'Music Composition'\n",
      " 'Architecture' 'Choral Music' 'New Media' 'Astronomy' 'Pharmacy'\n",
      " 'African American Studies' 'East Asian Studies' nan 'Latin'\n",
      " 'Cognitive Science' \"Women's & Gender Studies\" 'Pre-Veterinary' 'Spanish'\n",
      " 'Instrumental Music' 'German' 'Russian' 'Biomathematics' 'Agriculture'\n",
      " 'Foreign Languages' 'Art and Art History']\n"
     ]
    }
   ],
   "source": [
    "#Column24 - Academic Interest 1\n",
    "print(TUtrain['Academic Interest 1'].isna().sum())\n",
    "#1 NAs.\n",
    "print(TUtrain['Academic Interest 1'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2624 nan nan\n",
      "3869 nan Business - Management\n",
      "6370 nan Computer Science\n",
      "7877 nan Business - Management Information Systems\n"
     ]
    }
   ],
   "source": [
    "# Step1: Most of the NAs for Academic.Interest.1 have a value for Academic.Interest.2\n",
    "#We may assign the corresponding values in Academic.Interest.2 \n",
    "#to NAs in Academic.Interest.1 if Academic.Interest.2 has a value.\n",
    "\n",
    "# When update values in a subset of dataframes, \n",
    "# Try using .loc[row_indexer,col_indexer] = value instead to avoid chained indexing issue\n",
    "\n",
    "for i,row in TUtrain.iterrows():\n",
    "    if pd.isna(row['Academic Interest 1']):\n",
    "        print(i,row['Academic Interest 1'],row['Academic Interest 2'])\n",
    "        TUtrain.loc[i,'Academic Interest 1']=TUtrain.loc[i,'Academic Interest 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Biology', 'Engineering Science', 'Psychology', 'Neuroscience',\n",
       "       'Computer Science', 'English', 'Mathematics', 'Education', 'Music',\n",
       "       'Undecided', 'Business', 'Geosciences', 'Pre-Law', 'Biochemistry',\n",
       "       'Finance', 'Pre-Medical', 'Political Science',\n",
       "       'Business - Communication Management', 'Economics',\n",
       "       'Business - Accounting', 'Entrepreneurship', 'Sociology',\n",
       "       'Environmental Studies', 'Chemistry', 'Mathematical Finance',\n",
       "       'Business - Sport Management', 'History', 'International Studies',\n",
       "       'Biochemistry & Molecular Biology', 'Business - Management',\n",
       "       'Communication', 'Anthropology', 'Business - Marketing',\n",
       "       'Linguistics', 'Philosophy', 'Business - International Business',\n",
       "       'Business Analytics & Technology', 'Art', 'French',\n",
       "       'Business - Management Information Systems', 'Physics',\n",
       "       'Urban Studies', 'Chinese', 'Nursing', 'Business Legal Studies',\n",
       "       'Human Communication', 'Comparative Literature',\n",
       "       'Creative Writing', 'Ancient Mediterranean Studies', 'Art History',\n",
       "       'Architectural Studies', 'Film Studies', 'Theatre',\n",
       "       'Music Education', 'Pre-Dental', 'Religion', 'Classical Languages',\n",
       "       'Applied Chemistry', 'Music Composition', 'Architecture',\n",
       "       'Choral Music', 'New Media', 'Astronomy', 'Pharmacy',\n",
       "       'African American Studies', 'East Asian Studies', 'Latin',\n",
       "       'Cognitive Science', \"Women's & Gender Studies\", 'Pre-Veterinary',\n",
       "       'Spanish', 'Instrumental Music', 'German', 'Russian',\n",
       "       'Biomathematics', 'Agriculture', 'Foreign Languages',\n",
       "       'Art and Art History'], dtype=object)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step2:For the remaining NAs in Academic.Interest.1, assign Undecided.\n",
    "TUtrain['Academic Interest 1'].fillna('Undecided',inplace=True)\n",
    "TUtrain['Academic Interest 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Academic Interest 1\n",
       "Pre-Medical                            1064\n",
       "Biology                                 881\n",
       "Business                                871\n",
       "Engineering Science                     850\n",
       "Others                                  811\n",
       "Computer Science                        597\n",
       "Psychology                              542\n",
       "Political Science                       425\n",
       "Undecided                               412\n",
       "Neuroscience                            382\n",
       "Biochemistry & Molecular Biology        290\n",
       "Economics                               244\n",
       "Business - Management                   209\n",
       "International Studies                   208\n",
       "Biochemistry                            203\n",
       "Business - Marketing                    192\n",
       "Business - Accounting                   186\n",
       "Mathematics                             180\n",
       "English                                 177\n",
       "Chemistry                               171\n",
       "Environmental Studies                   168\n",
       "Pre-Law                                 163\n",
       "Business - International Business       144\n",
       "Physics                                 144\n",
       "History                                 142\n",
       "Communication                           116\n",
       "Education                               115\n",
       "Business - Communication Management     113\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Step3:Group Business related options into \"Business\".\n",
    "TUtrain['Academic Interest 1'] = \\\n",
    "TUtrain['Academic Interest 1'].apply(lambda x: 'Business' if x in['Finance','Entrepreneurship'] else x)\n",
    "\n",
    "#Group options with a low number of cases (< 100 cases) into \"Others\".\n",
    "Majorlist=list(TUtrain['Academic Interest 1'].value_counts()[:27].index)\n",
    "TUtrain['Academic Interest 1'] = \\\n",
    "TUtrain['Academic Interest 1'].apply(lambda x: 'Others' if x not in Majorlist else x)\n",
    "TUtrain['Academic Interest 1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "#Column25 - Academic.Interest.2#Column25 - Academic.Interest.2\n",
    "\n",
    "#Check NAs\n",
    "print(  TUtrain['Academic Interest 2'].isna().sum())\n",
    "#94 NAs.\n",
    "\n",
    "#Replace repeated academic interests with Undecided, \n",
    "#then make NAs Undecided\n",
    "TUtrain['Academic Interest 2'].fillna('Undecided')\n",
    "\n",
    "#Group Business related options into \"Business\".\n",
    "TUtrain['Academic Interest 2'] = \\\n",
    "TUtrain['Academic Interest 2'].apply(lambda x: 'Business' if x in['Finance','Entrepreneurship'] else x)\n",
    "\n",
    "\n",
    "#Group options with a low number of cases (< 100 cases) into \"Others\".\n",
    "Majorlist=list(TUtrain['Academic Interest 2'].value_counts()[:27].index)\n",
    "TUtrain['Academic Interest 2']= \\\n",
    "TUtrain['Academic Interest 2'].apply(lambda x: 'Others' if x not in Majorlist else x)\n",
    "TUtrain['Academic Interest 2'].value_counts()\n",
    "\n",
    "# Additional line to replace 'Spanish' with 'Others' \n",
    "# (this is because Spanish is missing, necessary step for modeling)\n",
    "TUtrain['Academic Interest 2'] = TUtrain['Academic Interest 2'].apply(\n",
    "    lambda x: 'Others' if x == 'Spanish' else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Academic Interest 2\n",
       "Others                               1729\n",
       "Business                              813\n",
       "Biology                               770\n",
       "Pre-Medical                           555\n",
       "Psychology                            520\n",
       "Biochemistry & Molecular Biology      395\n",
       "Political Science                     395\n",
       "Engineering Science                   362\n",
       "Business - Management                 345\n",
       "Economics                             341\n",
       "Biochemistry                          340\n",
       "Undecided                             317\n",
       "Neuroscience                          315\n",
       "Computer Science                      304\n",
       "Mathematics                           294\n",
       "Chemistry                             244\n",
       "Business - Marketing                  242\n",
       "Pre-Law                               233\n",
       "Physics                               195\n",
       "International Studies                 190\n",
       "Environmental Studies                 188\n",
       "English                               176\n",
       "Business - International Business     167\n",
       "Sociology                             154\n",
       "History                               152\n",
       "Education                             133\n",
       "Business - Accounting                 131\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TUtrain['Academic Interest 2'].value_counts()\n",
    "# Checking code worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "First_Source Origin First Source Summary\n",
      "CBINQ    4664\n",
      "OAPP     1014\n",
      "PSAT      506\n",
      "SRCH      484\n",
      "VST       437\n",
      "CF        365\n",
      "WEBTU     333\n",
      "CAPIQ     307\n",
      "CAP       280\n",
      "ACT       197\n",
      "HSV       164\n",
      "ATH       148\n",
      "TIF       135\n",
      "SIB       126\n",
      "SATR      124\n",
      "YUVST     119\n",
      "OEVNT      98\n",
      "ATHWB      70\n",
      "NHI        51\n",
      "HOBS       50\n",
      "OTH        45\n",
      "NICHE      35\n",
      "APPTX      31\n",
      "GRP        28\n",
      "DOC        26\n",
      "TVINT      21\n",
      "EM         18\n",
      "ALUM       17\n",
      "SAT        15\n",
      "CHEGG      15\n",
      "TVOTH      15\n",
      "WEBCA      15\n",
      "ACTPL      12\n",
      "CLNIQ       7\n",
      "REF         5\n",
      "AP          5\n",
      "MPC         4\n",
      "TFL         3\n",
      "MAIL        2\n",
      "CLNAP       2\n",
      "DBT         1\n",
      "RCPT        1\n",
      "ATS         1\n",
      "EXPL        1\n",
      "LVCHT       1\n",
      "HIGH        1\n",
      "TEL         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column26 - First_Source Origin First Source Summary\n",
    "\n",
    "# print # NAs.\n",
    "print(TUtrain[\"First_Source Origin First Source Summary\"].isnull().sum()) \n",
    "# No nulls\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtrain[\"First_Source Origin First Source Summary\"].value_counts()) \n",
    "\n",
    "#Similar to Academic.Interest.2, group options with a low number of cases (< 100) into \"Other Sources\".\n",
    "TUtrain['First_Source Origin First Source Summary']= \\\n",
    "TUtrain['First_Source Origin First Source Summary'].apply(lambda x: 'Other Sources' if x not in [\"CBINQ\",\"OAPP\",\"PSAT\",\"SRCH\",\"VST\",\"CF\",\"WEBTU\",\"CAPIQ\",\"CAP\",\"ACT\",\"HSV\",\"ATH\",\"TIF\",\"SIB\",\"SATR\",\"YUVST\"] else x) \n",
    "# Same as before but for other sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First_Source Origin First Source Summary\n",
      "CBINQ            4664\n",
      "OAPP             1014\n",
      "Other Sources     597\n",
      "PSAT              506\n",
      "SRCH              484\n",
      "VST               437\n",
      "CF                365\n",
      "WEBTU             333\n",
      "CAPIQ             307\n",
      "CAP               280\n",
      "ACT               197\n",
      "HSV               164\n",
      "ATH               148\n",
      "TIF               135\n",
      "SIB               126\n",
      "SATR              124\n",
      "YUVST             119\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtrain[\"First_Source Origin First Source Summary\"].value_counts()) \n",
    "# Seeing code worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0 1 2 4 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, '2 or more'], dtype=object)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column27 - Total Event Participation\n",
    "print(TUtrain['Total Event Participation'].isna().sum())\n",
    "#No NAs.\n",
    "print(TUtrain['Total Event Participation'].unique())\n",
    "\n",
    "#3, 4, 5 combined accounts for < 1% of the data set.\n",
    "#Compared to the number of cases in 0, 1, and 2, the number of cases\n",
    "#in 3, 4, and 5 won't be very useful in predicting the response.\n",
    "#So group 3, 4, and 5 into \"2 or more\".\n",
    "\n",
    "TUtrain['Total Event Participation']=\\\n",
    "TUtrain['Total Event Participation'].apply(lambda x: '2 or more' if x in[3,4,5] else x)\n",
    "TUtrain['Total Event Participation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Count of Campus Visits\n",
      "0    7172\n",
      "1    2221\n",
      "2     410\n",
      "3     124\n",
      "4      54\n",
      "5      13\n",
      "6       5\n",
      "8       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column28 - Count of Campus Visits\n",
    "TUtrain[\"Count of Campus Visits\"] = TUtrain[\"Count of Campus Visits\"].astype(str) \n",
    "# I turned the column into string values considering there were a low amount of groups in the column \n",
    "# and the grouping instructions in the next few lines. \n",
    "\n",
    "# print # NAs.\n",
    "print(TUtrain[\"Count of Campus Visits\"].isnull().sum()) \n",
    "# No nulls\n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtrain[\"Count of Campus Visits\"].value_counts()) \n",
    "\n",
    "# group 5, 6, and 8 into '4 or more'.\n",
    "TUtrain[\"Count of Campus Visits\"] = \\\n",
    "TUtrain[\"Count of Campus Visits\"].apply(lambda x: '4 or more' if x in [\"4\",\"5\", \"6\", \"8\"] else x) \n",
    "#combined groups 4 - 8 into one group called \"4 or more\" using .apply function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Campus Visits\n",
      "0            7172\n",
      "1            2221\n",
      "2             410\n",
      "3             124\n",
      "4 or more      73\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(TUtrain[\"Count of Campus Visits\"].value_counts()) \n",
    "# Checking code ran correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "School #1 Organization Category\n",
      "High School    9967\n",
      "College           8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column29 - School #1 Organization Category\n",
    "print(TUtrain['School #1 Organization Category'].isna().sum())\n",
    "#25  NAs.\n",
    "print(TUtrain['School #1 Organization Category'].value_counts())\n",
    "#Only 8 cases belong to College but 9967 cases belong to High School.\n",
    "#Remove this variable.\n",
    "TUtrain.drop('School #1 Organization Category', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7842\n",
      "[    nan 441750. 390324. ...  53114. 446425.  51635.]\n"
     ]
    }
   ],
   "source": [
    "#Column30 - School 1 Code\n",
    "print(TUtrain['School 1 Code'].isna().sum())\n",
    "#7842 NAs.\n",
    "print(TUtrain['School 1 Code'].unique())\n",
    "#School Code will not matter much to produce insightful information.\n",
    "#Additionally, there are 7842 missing values.\n",
    "#so remove this column in the modeling stage.\n",
    "TUtrain.drop('School 1 Code', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5357\n"
     ]
    }
   ],
   "source": [
    "#Column31 - School 1 Class Rank (Numeric)\n",
    "print(TU.loc[TU['train-test']=='train','School 1 Class Rank (Numeric)'].isna().sum())\n",
    "#5357 NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5357"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column32 - School 1 Class Size (Numeric)\n",
    "\n",
    "print(TUtrain['School 1 Class Size (Numeric)'].isna().sum())\n",
    "\n",
    "#5357 NAs.\n",
    "#Percentage rank can more accurately reflect a student's academic performance than numeric rank. \n",
    "\n",
    "#Create a New Column - School 1 Top Percent in Class\n",
    "\n",
    "TUtrain['School 1 Top Percent in Class'] =\\\n",
    "100 *(TUtrain['School 1 Class Rank (Numeric)']/TUtrain['School 1 Class Size (Numeric)'])\n",
    "\n",
    "TUtrain['School 1 Top Percent in Class'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527\n",
      "Academic Index\n",
      "3.0    3133\n",
      "1.0    2534\n",
      "2.0    2349\n",
      "4.0    1235\n",
      "5.0     222\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3., 2., 4., 1., 5.])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Impute the 5357 NAs based on Academic.Index column. \n",
    "\n",
    "# #Since we need to handle NAs in School 1 Top Percent in Class\n",
    "# according to Academic.Index, first let's see whether Academic Index needs to be cleaned.\n",
    "print(TUtrain['Academic Index'].isna().sum())\n",
    "#829 NAs.\n",
    "print(TUtrain['Academic Index'].value_counts())\n",
    "#No questionable level.\n",
    "#Impute 829 NAs with the most common level.\n",
    "TUtrain['Academic Index'].fillna(3,inplace=True)\n",
    "TUtrain['Academic Index'].unique()\n",
    "#No missing values in Academic Index now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Academic Index\n",
       "1.0     4.614411\n",
       "2.0     8.554908\n",
       "3.0    16.109453\n",
       "4.0    28.837494\n",
       "5.0    33.106967\n",
       "Name: School 1 Top Percent in Class, dtype: float64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate school 1 top percent in class for each academic index group\n",
    "grouped=TUtrain.groupby('Academic Index')\n",
    "grouped\n",
    "average=grouped.mean('School 1 Top Percent in Class')\n",
    "average['School 1 Top Percent in Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Impute missing values in 'School 1 Top Percent in Class' based on Academic Index group average\n",
    "for i,row in TUtrain.iterrows():\n",
    "\n",
    "    if (row['Academic Index']== 1.0) & (pd.isna(row['School 1 Top Percent in Class'])):\n",
    "        TUtrain.loc[i,'School 1 Top Percent in Class']= average['School 1 Top Percent in Class'][1.0]\n",
    "    elif (row['Academic Index']== 2.0) & (pd.isna(row['School 1 Top Percent in Class'])):\n",
    "            TUtrain.loc[i,'School 1 Top Percent in Class']= average['School 1 Top Percent in Class'][2.0]\n",
    "    elif (row['Academic Index']== 3.0) & (pd.isna(row['School 1 Top Percent in Class'])):\n",
    "            TUtrain.loc[i,'School 1 Top Percent in Class']= average['School 1 Top Percent in Class'][3.0]\n",
    "    elif (row['Academic Index']== 4.0) & (pd.isna(row['School 1 Top Percent in Class'])):\n",
    "            TUtrain.loc[i,'School 1 Top Percent in Class']= average['School 1 Top Percent in Class'][4.0]\n",
    "    elif (row['Academic Index']== 5.0) & (pd.isna(row['School 1 Top Percent in Class'])):\n",
    "            TUtrain.loc[i,'School 1 Top Percent in Class']= average['School 1 Top Percent in Class'][5.0]\n",
    "print(TUtrain['Academic Index'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column33 - School 1 GPA\n",
    "\n",
    "#Remove this variable in the modeling stage\n",
    "#because School.1.GPA.Recalculated is more accurate.\n",
    "\n",
    "TUtrain.drop('School 1 GPA', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column34 - School 1 GPA Scale\n",
    "#Remove this variable in the modeling stage as it is irrelevant.\n",
    "\n",
    "TUtrain.drop('School 1 GPA Scale', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.9276662923406366"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column35 - School 1 GPA Recalculated\n",
    "\n",
    "#Check NAs\n",
    "\n",
    "print(TUtrain['School 1 GPA Recalculated'].isna().sum())\n",
    "#0 NAs.\n",
    "\n",
    "TUtrain['School 1 GPA Recalculated'].skew()\n",
    "#Check skewness\n",
    "\n",
    "# if the skewness score is below -1 or above 1, the variable is high skewed\n",
    "#if the skewness score is positive, it means it is right tail skew\n",
    "# if the skewness score is negative, it means it is left tail skew\n",
    "#Since it is moderately skewed, and it is understandable for the left skewness as \n",
    "#a lot of students got into Trinity with a high GPA (almost 4.0), it is unnecessary to do transformation.\n",
    "# Some modeling methods requires variables following a normal distribution, therefore you need to transform the skewed data\n",
    "# before inputting it into the model, such as liner regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Column36 - School 2 Class Rank (Numeric)\n",
    "#Check NAs\n",
    "print(TUtrain['School 2 Class Rank (Numeric)'].isna().sum()) # 10000 null values \n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtrain.drop('School 2 Class Rank (Numeric)', axis='columns', inplace=True) \n",
    "#Dropping column as all cases are blank so we do not need the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Column37 - School 2 Class Size (Numeric)\n",
    "\n",
    "#Check NAs\n",
    "print(TUtrain['School 2 Class Size (Numeric)'].isna().sum())# 10000 null values \n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtrain.drop('School 2 Class Size (Numeric)', axis='columns', inplace=True)\n",
    "# Same as the last one, all cases are blank. We do not need this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Column38 - School 2 GPA\n",
    "\n",
    "#Check NAs\n",
    "print(TUtrain['School 2 GPA'].isna().sum())# 10000 null values \n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtrain.drop('School 2 GPA', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Column39 - School 2 GPA Scale\n",
    "#Check NAs\n",
    "print(TUtrain['School 2 GPA Scale'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtrain.drop('School 2 GPA Scale', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Column40 - School 2 GPA Recalculated\n",
    "#Check NAs\n",
    "print(TUtrain['School 2 GPA Recalculated'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtrain.drop('School 2 GPA Recalculated', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Column41 - School 3 Class Rank (Numeric)\n",
    "#Check NAs\n",
    "print(TUtrain['School 3 Class Rank (Numeric)'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtrain.drop('School 3 Class Rank (Numeric)', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Column42 - School 3 Class Size (Numeric)\n",
    "#Check NAs\n",
    "print(TUtrain['School 3 Class Size (Numeric)'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtrain.drop('School 3 Class Size (Numeric)', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Column43 - School 3 GPA\n",
    "#Check NAs\n",
    "print(TUtrain['School 3 GPA'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtrain.drop('School 3 GPA', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Column44 - School 3 GPA Scale\n",
    "#Check NAs\n",
    "print(TUtrain['School 3 GPA Scale'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtrain.drop('School 3 GPA Scale', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Column45 - School 3 GPA Recalculated\n",
    "#Check NAs\n",
    "print(TUtrain['School 3 GPA Recalculated'].isna().sum())# 10000 null values\n",
    "\n",
    "#Should we keep or remove this variable. Justify your decision in comments.\n",
    "TUtrain.drop('School 3 GPA Recalculated', axis='columns', inplace=True)\n",
    "# Same as before, dropping column as we don't need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4945\n",
      "ACT Composite\n",
      "32.0    621\n",
      "31.0    606\n",
      "33.0    584\n",
      "30.0    562\n",
      "34.0    522\n",
      "29.0    468\n",
      "28.0    415\n",
      "35.0    366\n",
      "27.0    326\n",
      "26.0    207\n",
      "25.0    138\n",
      "36.0     86\n",
      "24.0     78\n",
      "23.0     44\n",
      "22.0     20\n",
      "20.0      5\n",
      "21.0      4\n",
      "19.0      1\n",
      "15.0      1\n",
      "17.0      1\n",
      "Name: count, dtype: int64\n",
      "1169\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Column46 ACT Composite\n",
    "\n",
    "# print # NAs.\n",
    "print(TUtrain[\"ACT Composite\"].isna().sum())  # 4945 null values \n",
    "\n",
    "# print unique value counts.\n",
    "print(TUtrain[\"ACT Composite\"].value_counts()) \n",
    "\n",
    "# Replace missing ACT scores with SAT Concordance scores. \n",
    "# Convert 'SAT R Evidence-Based Reading and Writing Section + Math Section scores' into ACT based on the ACT-SAT concordance table pdf;\n",
    "\n",
    "sat_to_act = {\n",
    "    range(1570, 1601): 36,  # dictionary which corresponds to ACT concordance table\n",
    "    range(1530, 1561): 35,\n",
    "    range(1490, 1521): 34,\n",
    "    range(1450, 1481): 33,\n",
    "    range(1420, 1441): 32,\n",
    "    range(1390, 1411): 31,\n",
    "    range(1360, 1381): 30,\n",
    "    range(1330, 1351): 29,\n",
    "    range(1300, 1321): 28,\n",
    "    range(1260, 1291): 27, \n",
    "    range(1230, 1251): 26,\n",
    "    range(1200, 1221): 25,\n",
    "    range(1160, 1191): 24,\n",
    "    range(1130, 1151): 23,\n",
    "    range(1100, 1121): 22,\n",
    "    range(1060, 1091): 21,\n",
    "    range(1030, 1051): 20,\n",
    "    range(990, 1021): 19,\n",
    "    range(960, 981): 18,\n",
    "    range(920, 951): 17,\n",
    "    range(880, 911): 16,\n",
    "    range(830, 871): 15,\n",
    "    range(780, 821): 14,\n",
    "    range(730, 771): 13,\n",
    "    range(690, 721): 12,\n",
    "    range(650, 681): 11,\n",
    "    range(620, 641): 10,\n",
    "    range(590, 611): 9\n",
    "}\n",
    "\n",
    "def calcACT(sat): \n",
    "    if pd.isna(sat):  # Ensure no error for missing SAT values\n",
    "        return None\n",
    "    for score_range in sat_to_act.keys(): #Loops over SAT ranges dictionary, checks if score is in range. \n",
    "        if sat in score_range: # If score in range, \n",
    "            return sat_to_act[score_range] #return corresponding ACT score.\n",
    "    return None  # If SAT score doesn't fit in any range, return None\n",
    "\n",
    "# Apply the function to fill missing ACT scores using SAT values\n",
    "TUtrain[\"ACT Composite\"] = TUtrain.apply(\n",
    "    lambda row: calcACT(row['SAT R Evidence-Based Reading and Writing Section + Math Section']) \n",
    "    if pd.isnull(row['ACT Composite']) else row['ACT Composite'], axis=1\n",
    ")\n",
    "\n",
    "# Check again for any missing ACT scores\n",
    "print(TUtrain[\"ACT Composite\"].isna().sum())  # Check how many NAs are left\n",
    "\n",
    "# Replace any remaining missing ACT scores with the mean of the ACT Composite\n",
    "TUtrain[\"ACT Composite\"] = TUtrain[\"ACT Composite\"].apply(\n",
    "    lambda x: TUtrain[\"ACT Composite\"].mean() if pd.isnull(x) else x\n",
    ").round()\n",
    "\n",
    "# Final check\n",
    "print(TUtrain[\"ACT Composite\"].isna().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT Composite Grouped\n",
      "30.0          2161\n",
      "33.0           991\n",
      "31.0           953\n",
      "32.0           936\n",
      "29.0           876\n",
      "34.0           872\n",
      "28.0           814\n",
      "27.0           658\n",
      "35.0           613\n",
      "26.0           395\n",
      "25.0           275\n",
      "24.0           173\n",
      "36.0           162\n",
      "23.0            72\n",
      "22.0            30\n",
      "ACTBelow21      19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group ACT scores with fewer than 10 occurrences into one category, \n",
    "# I can see that all the values below 21 ACT score have less than 10 observations so that is what I will\n",
    "# call the category\n",
    "\n",
    "# Check the current value counts for ACT Composite\n",
    "act_counts = TUtrain[\"ACT Composite\"].value_counts()\n",
    "\n",
    "# Create a new column to categorize ACT scores\n",
    "def group_rare_scores(act_score):\n",
    "    if act_counts.get(act_score, 0) < 10:  # If the score appears fewer than 10 times\n",
    "        return 'ACTBelow21'  # Group them into Below 21\n",
    "    else:\n",
    "        return act_score  # Otherwise, keep the original score\n",
    "\n",
    "# Apply the function to create the new grouped categories\n",
    "TUtrain[\"ACT Composite Grouped\"] = TUtrain[\"ACT Composite\"].apply(group_rare_scores)\n",
    "\n",
    "# Check the distribution of the new categories\n",
    "print(TUtrain[\"ACT Composite Grouped\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(TUtrain[\"ACT Composite\"].isna().sum()) #Nulls are gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5205\n"
     ]
    }
   ],
   "source": [
    "#Column47 ACT English\n",
    "\n",
    "#Check NAs \n",
    "print(TUtrain[\"ACT English\"].isna().sum())\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtrain.drop(\"ACT English\", axis = 'columns', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5205\n"
     ]
    }
   ],
   "source": [
    "#Column48 ACT Reading\n",
    "print(TUtrain[\"ACT Reading\"].isna().sum()) # returned 5205 null values with .isna().sum()\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtrain.drop(\"ACT Reading\", axis = 'columns', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5205\n"
     ]
    }
   ],
   "source": [
    "#Column50 ACT Math\n",
    "print(TUtrain[\"ACT Math\"].isna().sum()) #returned 5205 null values with .isna().sum()\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtrain.drop(\"ACT Math\", axis = 'columns', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5205\n"
     ]
    }
   ],
   "source": [
    "#Column51 ACT Science Reasoning\n",
    "print(TUtrain[\"ACT Science Reasoning\"].isna().sum()) #returned 5205 null values with .isna().sum()\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtrain.drop(\"ACT Science Reasoning\", axis = 'columns', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9830\n"
     ]
    }
   ],
   "source": [
    "#Column52 ACT Writing\n",
    "print(TUtrain[\"ACT Writing\"].isna().sum()) #returned 9830 null values with .isna().sum()\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtrain.drop(\"ACT Writing\", axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9610\n"
     ]
    }
   ],
   "source": [
    "#Column53 ACT SAT I CR + M\n",
    "print(TUtrain[\"SAT I CR + M\"].isna().sum()) #returned 9610 null values with .isna().sum()\n",
    "\n",
    "# Since ACT Composite is already a good indicator for ACT scores generally,scores on each section will not matter much to make analyses.\n",
    "#Remove this variable.\n",
    "TUtrain.drop(\"SAT I CR + M\", axis = 'columns', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column54 SAT R Evidence-Based Reading and Writing Section + Math Section\n",
    "# This column is used to generate ATC concordance scores.\n",
    "# No further processing needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permanent Geomarket\n",
      "TX-06     1308\n",
      "TX-16     1175\n",
      "TX-15      596\n",
      "TX-13      533\n",
      "TX-23      343\n",
      "          ... \n",
      "INT-PL       1\n",
      "MI-06        1\n",
      "IN-01        1\n",
      "US-MP        1\n",
      "NY-18        1\n",
      "Name: count, Length: 362, dtype: int64\n",
      "0\n",
      "['NM-01' 'TX-22' 'TX-15' 'WA-05' 'TX-06' 'TX-19' 'LA-01' 'PA-06' 'CO-02'\n",
      " 'TX-16' 'WA-01' 'UT-01' 'TX-14' 'MA-10' 'TN-03' 'TX-13' 'FL-05' 'TX-07'\n",
      " 'US-AE' 'MA-08' 'TX-20' 'TX-24' 'WV-02' 'TX-23' 'INT-JM' 'TX-10' 'GA-02'\n",
      " 'FL-02' 'AL-03' 'CA-08' 'AZ-01' 'IL-12' 'INT-CS' 'INT-CH' 'INT-VM'\n",
      " 'DE-02' 'TX-03' 'TX-18' 'IL-11' 'OK-02' 'IL-01' 'CA-10' 'INT-NU' 'NV-01'\n",
      " 'CA-16' 'INT-SP' 'TX-01' 'FL-04' 'NM-02' 'NC-03' 'TX-08' 'KY-02' 'TX-02'\n",
      " 'MO-02' 'NJ-06' 'TX-17' 'MO-03' 'INT-IN' 'TX-11' 'INT-LU' 'CT-03'\n",
      " 'INT-NP' 'INT-EC' 'OR-02' 'CA-14' 'FL-01' 'CA-05' 'VA-03' 'MA-07'\n",
      " 'INT-HO' 'NC-06' 'INT-CM' 'INT-MX' 'NE-02' 'TX-05' 'TN-04' 'PA-02'\n",
      " 'TX-12' 'INT-CA' 'OR-03' 'TX-21' 'NY-27' 'NC-07' 'CA-28' 'NY-15' 'MD-06'\n",
      " 'OH-01' 'OR-04' 'TX-04' 'MD-03' 'HI-01' 'LA-02' 'MN-01' 'INT-SN' 'TX-09'\n",
      " 'LA-03' 'INT-BG' 'CT-04' 'OK-01' 'AZ-02' 'CA-29' 'CA-33' 'MD-02' 'CA-07'\n",
      " 'INT-PK' 'ID-01' 'NH-03' 'ME-01' 'RI-01' 'CA-09' 'INT-AE' 'IL-08' 'OH-09'\n",
      " 'WA-02' 'MI-02' 'OR-01' 'INT-UZ' 'MA-04' 'WA-04' 'CA-11' 'NJ-01' 'VT-01'\n",
      " 'INT-FR' 'CA-13' 'NJ-08' 'WY-01' 'CA-20' 'MS-01' 'IA-01' 'CO-01' 'CO-03'\n",
      " 'NY-10' 'MO-01' 'INT-TH' 'CA-27' 'NJ-07' 'KS-01' 'IL-09' 'OH-04' 'TN-02'\n",
      " 'US-VI' 'CA-24' 'NY-09' 'NY-22' 'NJ-12' 'INT-VE' 'OR-06' 'INT-HK' 'CA-04'\n",
      " 'NH-02' 'INT-SZ' 'INT-TZ' 'CA-02' 'INT-BR' 'WI-02' 'IL-04' 'IL-07'\n",
      " 'CA-31' 'CA-26' 'CA-01' 'CA-30' 'KY-01' 'CA-06' 'INT-ES' 'FL-03' 'CA-23'\n",
      " 'GA-07' 'OH-08' 'CA-12' 'AR-02' 'NY-08' 'KS-02' 'INT-ID' 'NC-01' 'GA-05'\n",
      " 'INT-MZ' 'MI-01' 'GA-03' 'MI-05' 'VA-01' 'ND-01' 'MD-04' 'MI-04' 'INT-TU'\n",
      " 'AR-01' 'GA-06' 'MA-11' 'VA-05' 'OH-07' 'PA-11' 'INT-EZ' 'INT-TW'\n",
      " 'INT-JA' 'INT-KS' 'FL-06' 'SD-02' 'CA-21' 'CA-03' 'NJ-10' 'VA-02' 'VA-08'\n",
      " 'SC-02' 'VA-09' 'SC-05' 'CA-18' 'AK-01' 'TN-01' 'NY-24' 'INT-CO' 'AL-01'\n",
      " 'OH-06' 'MD-05' 'IN-07' 'NJ-04' 'INT-IV' 'PA-05' 'INT-JO' 'INT-KZ'\n",
      " 'AZ-03' 'NY-29' 'MS-02' 'NY-04' 'INT-PM' 'NY-30' 'INT-BE' 'CA-17'\n",
      " 'INT-UK' 'INT-NI' 'OH-05' 'INT-PE' 'INT-LE' 'MD-07' 'INT-CJ' 'NC-05'\n",
      " 'INT-GT' 'IL-05' 'DC-01' 'NE-03' 'IL-06' 'IL-10' 'CT-02' 'CA-32' 'PA-10'\n",
      " 'INT-AR' 'WA-06' 'PA-07' 'IN-09' 'US-GU' 'INT-BL' 'CT-05' 'WI-01' 'MI-07'\n",
      " 'CT-01' 'PA-04' 'MA-09' 'IA-02' 'CA-34' 'INT-IT' 'NJ-02' 'CA-19' 'NJ-11'\n",
      " 'SD-01' 'NY-20' 'MA-01' 'WY-02' 'NE-01' 'WA-03' 'US-MP' 'IN-01' 'MI-06'\n",
      " 'CA-25' 'GA-08' 'NV-02' 'VA-06' 'IL-13' 'AL-02' 'NY-16' 'GA-01' 'INT-PL'\n",
      " 'PA-12' 'ME-02' 'NY-02' 'NH-04' 'INT-TD' 'INT-NZ' 'IL-03' 'MT-02' 'NY-12'\n",
      " 'INT-ET' 'SC-04' 'INT-KE' 'MD-01' 'NY-23' 'OR-05' 'PA-03' 'INT-MJ'\n",
      " 'INT-GM' 'VA-10' 'INT-SA' 'PA-08' 'NY-17' 'FL-07' 'MA-05' 'MN-02'\n",
      " 'INT-RP' 'IN-11' 'INT-GR' 'NH-01' 'NY-21' 'NY-05' 'CA-15' 'NJ-05' 'MA-03'\n",
      " 'IN-06' 'MA-06' 'INT-EI' 'NY-14' 'INT-GG' 'DE-01' 'INT-BH' 'INT-NL'\n",
      " 'HI-02' 'INT-WE' 'MT-01' 'INT-BK' 'VT-03' 'INT-CY' 'PA-13' 'INT-NO'\n",
      " 'INT-RS' 'NY-06' 'OH-02' 'IN-10' 'INT-BB' 'US-AP' 'NC-04' 'CA-22' 'NY-19'\n",
      " 'NJ-03' 'INT-KU' 'INT-UY' 'RI-02' 'INT-MO' 'INT-GH' 'AL-04' 'NY-25'\n",
      " 'SC-03' 'INT-BF' 'PR-01' 'AK-02' 'INT-SF' 'INT-PA' 'INT-CB' 'INT-MY'\n",
      " 'WV-01' 'INT-DO' 'NY-13' 'INT-IR' 'INT-LH' 'PA-01' 'ND-02' 'NY-18']\n",
      "         ID train-test Entry Term (Application) Permanent Country Sex  \\\n",
      "0         1      train                Fall 2017     United States   F   \n",
      "1         2      train                Fall 2019     United States   M   \n",
      "2         3      train                Fall 2020     United States   F   \n",
      "3         4      train                Fall 2017     United States   F   \n",
      "4         5      train                Fall 2019     United States   M   \n",
      "...     ...        ...                      ...               ...  ..   \n",
      "9995   9996      train                Fall 2019     United States   M   \n",
      "9996   9997      train                Fall 2019     United States   M   \n",
      "9997   9998      train                Fall 2020     United States   F   \n",
      "9998   9999      train                Fall 2019     United States   F   \n",
      "9999  10000      train                Fall 2019     UniqueCountry   M   \n",
      "\n",
      "                Ethnicity                              Race  \\\n",
      "0     Non Hispanic/Latino                             White   \n",
      "1     Non Hispanic/Latino                             White   \n",
      "2         Hispanic/Latino                             White   \n",
      "3     Non Hispanic/Latino                             Asian   \n",
      "4     Non Hispanic/Latino                             White   \n",
      "...                   ...                               ...   \n",
      "9995  Non Hispanic/Latino  Black or African American, White   \n",
      "9996  Non Hispanic/Latino                             White   \n",
      "9997      Hispanic/Latino                             White   \n",
      "9998      Hispanic/Latino                            Others   \n",
      "9999  Non Hispanic/Latino                     Not specified   \n",
      "\n",
      "                      Religion Application Source     Decision Plan  ...  \\\n",
      "0               Roman Catholic          CommonApp   Early Action II  ...   \n",
      "1                Not specified          CommonApp    Early Action I  ...   \n",
      "2                    Christian         ApplyTexas      Early Action  ...   \n",
      "3                Not specified          CommonApp    Early Action I  ...   \n",
      "4                    Christian          CommonApp  Regular Decision  ...   \n",
      "...                        ...                ...               ...  ...   \n",
      "9995             Not specified          CommonApp    Early Action I  ...   \n",
      "9996             Not specified          CommonApp   Early Action II  ...   \n",
      "9997  OtherRelgiousAffiliation         ApplyTexas      Early Action  ...   \n",
      "9998                 Christian         ApplyTexas    Early Action I  ...   \n",
      "9999            Roman Catholic          CommonApp   Early Action II  ...   \n",
      "\n",
      "     SAT I Critical Reading SAT I Math SAT I Writing  \\\n",
      "0                       NaN        NaN           NaN   \n",
      "1                       NaN        NaN           NaN   \n",
      "2                       NaN        NaN           NaN   \n",
      "3                     750.0      770.0         700.0   \n",
      "4                       NaN        NaN           NaN   \n",
      "...                     ...        ...           ...   \n",
      "9995                    NaN        NaN           NaN   \n",
      "9996                    NaN        NaN           NaN   \n",
      "9997                    NaN        NaN           NaN   \n",
      "9998                    NaN        NaN           NaN   \n",
      "9999                    NaN        NaN           NaN   \n",
      "\n",
      "     SAT R Evidence-Based Reading and Writing Section SAT R Math Section  \\\n",
      "0                                                 NaN                NaN   \n",
      "1                                               660.0              720.0   \n",
      "2                                                 NaN                NaN   \n",
      "3                                                 NaN                NaN   \n",
      "4                                               650.0              700.0   \n",
      "...                                               ...                ...   \n",
      "9995                                              NaN                NaN   \n",
      "9996                                            690.0              790.0   \n",
      "9997                                            640.0              700.0   \n",
      "9998                                            710.0              690.0   \n",
      "9999                                            720.0              740.0   \n",
      "\n",
      "     Decision Submit_FirstSource Submit_Inquiry School 1 Top Percent in Class  \\\n",
      "0           1               -0.0          -13.0                     10.094637   \n",
      "1           0               89.0         6198.0                     13.878470   \n",
      "2           1               38.0         6251.0                     28.837494   \n",
      "3           0             6096.0            2.0                      4.112150   \n",
      "4           0               54.0         6218.0                     18.601583   \n",
      "...       ...                ...            ...                           ...   \n",
      "9995        0               37.0         6200.0                     28.837494   \n",
      "9996        0              102.0            2.0                     12.006319   \n",
      "9997        0               71.0           55.0                     11.041991   \n",
      "9998        0               79.0           24.0                      1.349073   \n",
      "9999        0             6209.0         6209.0                     16.109453   \n",
      "\n",
      "     ACT Composite Grouped  \n",
      "0                     30.0  \n",
      "1                     30.0  \n",
      "2                     29.0  \n",
      "3                     35.0  \n",
      "4                     29.0  \n",
      "...                    ...  \n",
      "9995                  30.0  \n",
      "9996                  33.0  \n",
      "9997                  27.0  \n",
      "9998                  29.0  \n",
      "9999                  33.0  \n",
      "\n",
      "[10000 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# Column55 Permanent Geomarket\n",
    "# First, replace the missing values with the most frequent geo market value.\n",
    "print(TUtrain[\"Permanent Geomarket\"].value_counts()) # shows the most frequent geomarket area is TX \n",
    "print(TUtrain[\"Permanent Geomarket\"].isna().sum()) # No nulls\n",
    "\n",
    "# Second, group geomarket values into different regions. Refer to the region .csv for grouping.\n",
    "unique_values = TUtrain[\"Permanent Geomarket\"].unique()\n",
    "print(unique_values)\n",
    "\n",
    "# Define a single regions dictionary\n",
    "dictRegions = {\n",
    "    'West': ['AK', 'HI', 'WA', 'OR', 'CA', 'ID', 'NV', 'MT', 'WY', 'UT', 'CO', 'AZ', 'NM'],\n",
    "    'Midwest': ['ND', 'SD', 'NE', 'KS', 'MN', 'IA', 'MO', 'WI', 'IL', 'MI', 'IN', 'OH'],\n",
    "    'South': ['TX', 'OK', 'AR', 'LA', 'KY', 'TN', 'MS', 'AL', 'WV', 'MD', 'DE', 'DC', 'VA', 'NC', 'SC', 'GA', 'FL', 'US'],\n",
    "    'Northeast': ['PA', 'NY', 'NJ', 'ME', 'VT', 'NH', 'MA', 'CT', 'RI'],\n",
    "    'International': ['INT', 'PR']\n",
    "}\n",
    "\n",
    "# Function to categorize regions\n",
    "def categorize_region(geomarket):\n",
    "    # Clean the geomarket value (e.g., remove any suffix after '-')\n",
    "    clean_geomarket = geomarket.split('-')[0]\n",
    "    \n",
    "    # Check in the regions dictionary\n",
    "    for region, states in dictRegions.items():\n",
    "        if clean_geomarket in states:\n",
    "            return region\n",
    "            \n",
    "    return \"Unknown\"  # Default value if not found\n",
    "\n",
    "# Apply the function to create a new column for region categorization\n",
    "TUtrain['Permanent Geomarket'] = TUtrain['Permanent Geomarket'].apply(categorize_region)\n",
    "\n",
    "print(TUtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['West' 'South' 'Northeast' 'International' 'Midwest']\n"
     ]
    }
   ],
   "source": [
    "unique_values = TUtrain[\"Permanent Geomarket\"].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column56 Citizenship Status\n",
    "\n",
    "# This column is used for inter-field checking so keep it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column57 Academic Index\n",
    "\n",
    "# This column is used for inter-field checking so keep it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Intend to Apply for Financial Aid?\n",
      "1.0    6744\n",
      "0.0    3238\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Column58 Intend to Apply for Financial Aid?\n",
    "print(TUtrain[\"Intend to Apply for Financial Aid?\"].isna().sum()) #return 18 null values\n",
    "print(TUtrain[\"Intend to Apply for Financial Aid?\"].value_counts()) # value counts shows two unique values\n",
    "\n",
    "#Handling missing values. Justify your choice.\n",
    "TUtrain[\"Intend to Apply for Financial Aid?\"] = \\\n",
    "TUtrain[\"Intend to Apply for Financial Aid?\"].apply(lambda x: 1 if pd.isna(x) else x )\n",
    "# I decided to add all missing values to the 1 group (meaning receiving financial aid) because it is by far \n",
    "# the most frequent observation doubling the 0 group (not receiving any financial aid).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Merit Award\n",
      "P23      1131\n",
      "T23       981\n",
      "P17       903\n",
      "T22       887\n",
      "T21       848\n",
      "T25       762\n",
      "M30       596\n",
      "M27       590\n",
      "M26       547\n",
      "M25       383\n",
      "D18       377\n",
      "D20       370\n",
      "M24       334\n",
      "P18       199\n",
      "D12.5     139\n",
      "Z0         94\n",
      "TT10       76\n",
      "TTS        71\n",
      "I23        65\n",
      "I25        62\n",
      "I30        53\n",
      "TT9        52\n",
      "TT12       51\n",
      "TT125      44\n",
      "I18        43\n",
      "I26        31\n",
      "I22        30\n",
      "I17        28\n",
      "I21        27\n",
      "I35        26\n",
      "X0         23\n",
      "I27        22\n",
      "I24        22\n",
      "I15        21\n",
      "I20        21\n",
      "SEM        15\n",
      "I10        14\n",
      "I12.5      12\n",
      "I19         9\n",
      "I28         8\n",
      "I0          8\n",
      "I32         7\n",
      "I40         4\n",
      "I9          4\n",
      "I50         2\n",
      "I38         2\n",
      "Y0          1\n",
      "I5          1\n",
      "I52         1\n",
      "I12         1\n",
      "I7.5        1\n",
      "I43         1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Merit Award\n",
       "P23                                  1131\n",
       "T23                                   981\n",
       "P17                                   903\n",
       "T22                                   887\n",
       "T21                                   848\n",
       "T25                                   762\n",
       "M30                                   596\n",
       "M27                                   590\n",
       "M26                                   547\n",
       "International Student Scholarship     518\n",
       "M25                                   383\n",
       "D18                                   377\n",
       "D20                                   370\n",
       "M24                                   334\n",
       "P18                                   199\n",
       "D12.5                                 139\n",
       "Z0                                     94\n",
       "TT10                                   76\n",
       "TTS                                    71\n",
       "TT9                                    52\n",
       "TT12                                   51\n",
       "TT125                                  44\n",
       "X0                                     23\n",
       "SEM                                    15\n",
       "I0                                      8\n",
       "Y0                                      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column59 Merit Award\n",
    "print(TUtrain[\"Merit Award\"].isna().sum()) # No null values\n",
    "print(TUtrain[\"Merit Award\"].value_counts()) \n",
    "#Refer to the Merit Award Code.csv for grouping. \n",
    "#Recategorize all the levels into fewer levels, Justify your grouping policy in comments\n",
    "\n",
    "International = [\n",
    "    'I10', 'I12','I12.5','I15','I17',\n",
    "    'I18','I19','I20','I21','I24','I25',\n",
    "    'I26','I27','I28','I30','I32','I33',\n",
    "    'I35','I38','I5','I9','I40','I50',\n",
    "    'I22', 'I52', 'I7.5', 'I43', 'I23','I45'\n",
    "]\n",
    "\n",
    "TUtrain['Merit Award'] = \\\n",
    "TUtrain['Merit Award'].apply(lambda x: 'International Student Scholarship' if x in International else x)\n",
    "TUtrain['Merit Award'].value_counts()\n",
    "# Grouped all international financial awards together as there are too many levels of scholarship. \n",
    "# These categories will be much easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merit Award\n",
       "Domestic Merit-Based Scholarship     9270\n",
       "International Student Scholarship     518\n",
       "Z0                                     94\n",
       "TTS                                    71\n",
       "X0                                     23\n",
       "SEM                                    15\n",
       "I0                                      8\n",
       "Y0                                      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DomesticMeritBased = [\n",
    "    'D12.5','D18', 'D20','M24','M30', 'M27','M26',\n",
    "    'M25', 'P17','P23','P18','TT9','T21',\n",
    "    'T23','T22','T25', 'TT10','TT12','TT125'\n",
    "]\n",
    "\n",
    "TUtrain['Merit Award'] = \\\n",
    "TUtrain['Merit Award'].apply(lambda x: 'Domestic Merit-Based Scholarship' if x in DomesticMeritBased else x)\n",
    "TUtrain['Merit Award'].value_counts()\n",
    "# Grouped these into the Domestic Meritbased Scholarships as they are all domestic scholarships that have\n",
    "# different kinds of standards and requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merit Award\n",
       "Domestic Merit-Based Scholarship     9270\n",
       "International Student Scholarship     518\n",
       "Full Ride                             110\n",
       "Z0                                     94\n",
       "I0                                      8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FullRide = [\n",
    "    'SEM', 'TTS','X0', 'Y0'\n",
    "]\n",
    "\n",
    "TUtrain['Merit Award'] = \\\n",
    "TUtrain['Merit Award'].apply(lambda x: 'Full Ride' if x in FullRide else x)\n",
    "TUtrain['Merit Award'].value_counts()\n",
    "# Tuition exchange is basically a full scholarship so I grouped all of these into a full ride\n",
    "# to show all students who have a full scholarship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merit Award\n",
       "Domestic Merit-Based Scholarship     9270\n",
       "International Student Scholarship     518\n",
       "Full Ride                             110\n",
       "No Merit Scholarship                  102\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NoMeritList = [\n",
    "    'Z0', 'I0'\n",
    "]\n",
    "\n",
    "TUtrain['Merit Award'] = \\\n",
    "TUtrain['Merit Award'].apply(lambda x: 'No Merit Scholarship' if x in NoMeritList else x)\n",
    "TUtrain['Merit Award'].value_counts()\n",
    "\n",
    "# Because it is international no merit it makes more sense to say no merit than put them with international.\n",
    "# Both these do not get any merit scholarship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column60 SAT Concordance Score (of SAT R)\n",
    "\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtrain.drop(\"SAT Concordance Score (of SAT R)\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column61 ACT Concordance Score (of SAT R)\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtrain.drop(\"ACT Concordance Score (of SAT R)\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Column62 ACT Concordance Score (of SAT)\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtrain.drop(\"ACT Concordance Score (of SAT)\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column63 Test Optional\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtrain.drop(\"Test Optional\", axis = 'columns', inplace = True)\n",
    "# Nulls are now the mean for act and sat so it is not necessary to show test optional anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column64 SAT I Critical Reading\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtrain.drop(\"SAT I Critical Reading\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column65 SAT I Math\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtrain.drop(\"SAT I Math\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column66 SAT I Writing\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtrain.drop(\"SAT I Writing\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column67 SAT R Evidence-Based Reading and Writing Section\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtrain.drop(\"SAT R Evidence-Based Reading and Writing Section\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column68 SAT R Math Section\n",
    "#Remove this variable.Justify why you remove it.\n",
    "TUtrain.drop(\"SAT R Math Section\", axis = 'columns', inplace = True)\n",
    "# Because we have our ACT composite column and were able to transfer the SAT scores into the relative\n",
    "# ACT score, this column is redundent and therefore needs to be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column69 Decision\n",
    "\n",
    "# This would be your dependent variable in the classification model so keep it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you clean all variables, output the cleaned dataframe to a csv file\n",
    "# the csv file can be found in your current working directory\n",
    "\n",
    "\n",
    "TUtrain.to_csv('cleaneddftrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 0 to 9999\n",
      "Data columns (total 36 columns):\n",
      " #   Column                                                           Non-Null Count  Dtype  \n",
      "---  ------                                                           --------------  -----  \n",
      " 0   ID                                                               10000 non-null  int64  \n",
      " 1   train-test                                                       10000 non-null  object \n",
      " 2   Entry Term (Application)                                         10000 non-null  object \n",
      " 3   Permanent Country                                                10000 non-null  object \n",
      " 4   Sex                                                              10000 non-null  object \n",
      " 5   Ethnicity                                                        10000 non-null  object \n",
      " 6   Race                                                             10000 non-null  object \n",
      " 7   Religion                                                         10000 non-null  object \n",
      " 8   Application Source                                               10000 non-null  object \n",
      " 9   Decision Plan                                                    10000 non-null  object \n",
      " 10  Legacy                                                           10000 non-null  object \n",
      " 11  Athlete                                                          10000 non-null  object \n",
      " 12  Sport 1 Sport                                                    10000 non-null  object \n",
      " 13  Sport 1 Rating                                                   10000 non-null  object \n",
      " 14  Sport 2 Sport                                                    10000 non-null  object \n",
      " 15  Sport 3 Sport                                                    10000 non-null  object \n",
      " 16  Academic Interest 1                                              10000 non-null  object \n",
      " 17  Academic Interest 2                                              10000 non-null  object \n",
      " 18  First_Source Origin First Source Summary                         10000 non-null  object \n",
      " 19  Total Event Participation                                        10000 non-null  object \n",
      " 20  Count of Campus Visits                                           10000 non-null  object \n",
      " 21  School 1 Class Rank (Numeric)                                    4643 non-null   float64\n",
      " 22  School 1 Class Size (Numeric)                                    4643 non-null   float64\n",
      " 23  School 1 GPA Recalculated                                        10000 non-null  float64\n",
      " 24  ACT Composite                                                    10000 non-null  float64\n",
      " 25  SAT R Evidence-Based Reading and Writing Section + Math Section  5510 non-null   float64\n",
      " 26  Permanent Geomarket                                              10000 non-null  object \n",
      " 27  Citizenship Status                                               10000 non-null  object \n",
      " 28  Academic Index                                                   10000 non-null  float64\n",
      " 29  Intend to Apply for Financial Aid?                               10000 non-null  float64\n",
      " 30  Merit Award                                                      10000 non-null  object \n",
      " 31  Decision                                                         10000 non-null  int64  \n",
      " 32  Submit_FirstSource                                               10000 non-null  float64\n",
      " 33  Submit_Inquiry                                                   10000 non-null  float64\n",
      " 34  School 1 Top Percent in Class                                    10000 non-null  float64\n",
      " 35  ACT Composite Grouped                                            10000 non-null  object \n",
      "dtypes: float64(10), int64(2), object(24)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Compare the your table structure with the screenshot in the submission box\n",
    "# Make sure all primary predictors and target variables do not have any missing values and only have\n",
    "# regualr and correct values.\n",
    "\n",
    "TUtrain.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
